{"meta":{"title":"Dekel'Blog","subtitle":"用脚步丈量世界，用心感受多元文化","description":"一个关于如何在快节奏的现代生活中，通过微小的改变和持续的自我探索，实现内心平静与个人成长的空间。","author":"Dekel","url":"https://Dekelkai.github.io","root":"/"},"pages":[{"title":"友链","date":"2025-09-30T11:23:30.000Z","updated":"2025-10-02T06:32:30.950Z","comments":true,"path":"link/index.html","permalink":"https://dekelkai.github.io/link/index.html","excerpt":"","text":""},{"title":"说说","date":"2025-10-01T09:19:33.000Z","updated":"2025-10-02T06:20:57.283Z","comments":true,"path":"shuoshuo/index.html","permalink":"https://dekelkai.github.io/shuoshuo/index.html","excerpt":"","text":""},{"title":"tags","date":"2025-09-30T11:14:37.000Z","updated":"2025-09-30T11:22:57.751Z","comments":true,"path":"tags/index.html","permalink":"https://dekelkai.github.io/tags/index.html","excerpt":"","text":""},{"title":"about","date":"2025-10-02T06:11:59.000Z","updated":"2025-10-02T06:13:58.077Z","comments":true,"path":"about/index.html","permalink":"https://dekelkai.github.io/about/index.html","excerpt":"","text":""}],"posts":[{"title":"随想-在消费者视角，如何看待和应对恶意差评和水军好评","slug":"随想-在消费者视角，如何看待和应对恶意差评和水军好评","date":"2025-11-14T06:30:29.000Z","updated":"2025-11-14T06:47:09.194Z","comments":true,"path":"2025/11/14/随想-在消费者视角，如何看待和应对恶意差评和水军好评/","permalink":"https://dekelkai.github.io/2025/11/14/%E9%9A%8F%E6%83%B3-%E5%9C%A8%E6%B6%88%E8%B4%B9%E8%80%85%E8%A7%86%E8%A7%92%EF%BC%8C%E5%A6%82%E4%BD%95%E7%9C%8B%E5%BE%85%E5%92%8C%E5%BA%94%E5%AF%B9%E6%81%B6%E6%84%8F%E5%B7%AE%E8%AF%84%E5%92%8C%E6%B0%B4%E5%86%9B%E5%A5%BD%E8%AF%84/","excerpt":"","text":"从消费者视角，如何识别“恶意差评”和“水军好评”？｜一篇真正能帮你做决策的指南 最近在挑一把电脑椅，本人被评论区虐得生不如死： 好评说“坐着像云朵”，差评说“坐一个小时腰断了”； 好评夸“稳固结实”，差评却控诉“螺丝拧不上”。 这种两极化评价在电商平台再常见不过，尤其是一些小品牌商品。 让人怀疑人生： 到底哪个是真的？到底能不能买？ 其实，评论区从来不是纯粹的“真实消费者意见”，而是以下力量的混合体： 真实体验 情绪性差评 水军式好评 恶意竞争的攻击 不同用户预期差异 所以我们消费者需要的不是“找到绝对真相”，而是从噪声里筛出有效信号。 一、为什么评论区总是两极分化？ 这是因为三种力量在评论区混在一起： ① 正常好评（占多数，但描述很少） “挺好”“不错”“朋友推荐买的” ——这些对你判断没有帮助。 ② 水军好评（占不小比例） 文案整齐、角度一致、灯光统一、语气过度正面。 你一看就知道更像是精心制作的广告，而不是用户体验。 ③ 恶意差评（最具迷惑性） “垃圾东西别买！” “骗钱的！” “后悔一辈子！” 特点是：情绪强，但没有证据。 于是——矛盾的局面就诞生了。 二、怎么判断评价的真实程度？（超实用） 消费者不是侦探，但完全可以做到不被套路骗。 1. 差评是否有“证据”？（第一判断指标） 真实差评一般包含： 实物图 细节描述 使用场景（身高体重、坐多久、在哪用） 恶意差评一般： 只有一句话 不给图 不讲原因 重点在骂人不是商品 这种差评可以直接过滤。 2. 看“中评”，它比好评和差评更真实 中评用户最客观，会： 说优点 说缺点 附图但不过度 中评通常是评价区里最值得参考的区域。 3. 看差评的“聚焦点” 如果差评集中在同一个问题： 坐垫硬 味道重 安装麻烦 布料掉毛 那大概率是真的。 但如果差评互相矛盾（一个说太软，一个说太硬），说明： 差评大部分是主观感受差异，而不是产品本身质量有问题。 4. 看买家账号特征 以下账号最可疑： 等级 0 或 1 注册时间很短 购物记录少 多店铺连续差评 不回复客服 这类账号的可信度最低。 5. 看店铺是否回应差评 认真店铺会： 分析问题 提供补件或换货 给出明确解决方案 完全不回应差评的小店，风险反而更高。 三、消费者如何降低踩雷风险？（真正的建议） ① 小件商品：直接小额试水 无需纠结，看半天不如买一个回来试。 小金额的东西，用实际体验判断最快。 ② 大件商品：重点看售后承诺 例如椅子、桌子这类产品，最重要的是： 是否包退换货 是否有运费险 零部件是否可补寄 安装是否简单 质保是否明确 关键不是“没有问题”，而是“出现问题店家愿不愿意解决”。 ③ 不盲信“品牌名气” 有些小品牌本身就是大厂代工，不比大牌差。 只是因为体量小，更容易被恶意差评攻击。 判断重点不是品牌大不大，而是： 是否负责 是否透明 是否愿意解决问题 ④ 去多平台交叉验证 你可以同时看： 淘宝评论（结构、差评聚焦点） 小红书（真实使用图） B站（测评） 知乎（深度讨论） 如果四个平台意见相近，可信度最高。 四、结语：消费者不需要完美判断，只需要稳一点 评论区永远不会回到“完全真实”的时代。 水军会存在，恶意竞争会存在，情绪化表达也会存在。 但你要记住： 评论是参考，不是答案。 情绪是噪声，细节才是真实。 我们无法阻止评价体系的混乱， 但我们可以让自己的判断体系更加稳定，不被轻易带偏。","categories":[],"tags":[],"author":"Dekel"},{"title":"记第二次 Win11+Ubuntu24.04 双系统安装","slug":"Win11-Ubuntu24-04双系统安装","date":"2025-11-08T09:32:52.000Z","updated":"2025-11-08T13:25:06.736Z","comments":true,"path":"2025/11/08/Win11-Ubuntu24-04双系统安装/","permalink":"https://dekelkai.github.io/2025/11/08/Win11-Ubuntu24-04%E5%8F%8C%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/","excerpt":"","text":"","categories":[],"tags":[],"author":"Dekel"},{"title":"komari轻量级服务器监控面板","slug":"komari轻量级服务器监控配置","date":"2025-10-25T14:36:22.000Z","updated":"2025-11-01T10:49:27.826Z","comments":true,"path":"2025/10/25/komari轻量级服务器监控配置/","permalink":"https://dekelkai.github.io/2025/10/25/komari%E8%BD%BB%E9%87%8F%E7%BA%A7%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9B%91%E6%8E%A7%E9%85%8D%E7%BD%AE/","excerpt":"","text":"komari安装 使用一键安装脚本 适用于使用了 systemd 的发行版（Ubuntu、Debian...）。 123curl -fsSL https://raw.githubusercontent.com/komari-monitor/komari/main/install-komari.sh -o install-komari.shchmod +x install-komari.shsudo ./install-komari.sh docker部署 创建数据目录： 1mkdir -p ./data 运行 Docker 容器： 12345docker run -d \\ -p 25774:25774 \\ -v $(pwd)/data:/app/data \\ --name komari \\ ghcr.io/komari-monitor/komari:latest 查看默认账号和密码： 1docker logs komari 在浏览器中访问 http://&lt;your_server_ip&gt;:25774。 Nginx配置 由于我配置了xray做代理，这里直接将回落放在komari上 安装 1sudo apt update &amp;&amp; sudo apt install nginx 完成后，Nginx 已经自动运行。此时打开 Windows 上的浏览器并输入 http://your-ip:80，若看到下图的界面就说明 Nginx 已经正常在运行了。 检查配置结构 123456# 查看 Nginx 版本和配置目录nginx -vls -la /etc/nginx/# 查看配置目录结构ls -la /etc/nginx/conf.d/ 创建 Komari 站点配置 创建一个并编辑一个配置文件 /etc/nginx/sites-available/your-name.conf: 1sudo nano /etc/nginx/sites-available/your-name.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445server { listen 80; server_name 二级域名.一级域名.com; return 301 https://$server_name$request_uri;}server { # Nginx 监听 自定义 端口，等待 Xray 转发的纯 HTTP 流量 listen 127.0.0.1:自定义端口; server_name 二级域名.一级域名.com; location / { # 核心修改：反向代理到 Komari Monitor 的端口 proxy_pass http://127.0.0.1:Komari-Port; # 增加超时和头部设置，确保代理稳定 proxy_connect_timeout 5s; proxy_read_timeout 10s; proxy_send_timeout 10s; proxy_set_header Connection \"\"; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto https; # 明确告知后端是 HTTPS } add_header Strict-Transport-Security \"max-age=31536000; includeSubDomains\" always;}# 默认 server（未知 SNI fallback）保持不变，继续服务静态文件server { listen 127.0.0.1:自定义端口 default_server; server_name _; root /home/your_username/www/webpage; # 仍然作为默认页面 location / { try_files $uri $uri/ =404; }} 创建一个软链接将配置启用 1sudo ln -s /etc/nginx/sites-available/your-name.conf /etc/nginx/sites-enabled/your-name.conf 验证与重启 测试配置： 1sudo nginx -t # 应显示 \"successful ok\" 重启 Nginx： 12sudo systemctl restart nginxsudo systemctl status nginx","categories":[],"tags":[],"author":"Dekel"},{"title":"火星无人机绝对定位-On-board Absolute Localization Based on Orbital Imagery for a Future Mars Science Helicopter","slug":"火星无人机绝对定位-On-board-Absolute-Localization-Based-on-Orbital-Imagery-for-a-Future-Mars-Science-Helicopter","date":"2025-10-18T12:43:27.000Z","updated":"2025-10-18T12:51:25.594Z","comments":true,"path":"2025/10/18/火星无人机绝对定位-On-board-Absolute-Localization-Based-on-Orbital-Imagery-for-a-Future-Mars-Science-Helicopter/","permalink":"https://dekelkai.github.io/2025/10/18/%E7%81%AB%E6%98%9F%E6%97%A0%E4%BA%BA%E6%9C%BA%E7%BB%9D%E5%AF%B9%E5%AE%9A%E4%BD%8D-On-board-Absolute-Localization-Based-on-Orbital-Imagery-for-a-Future-Mars-Science-Helicopter/","excerpt":"","text":"要在火星上进行更长距离的飞行（10km），更高的地形差。 1、无GPS的自主导航 相对定位：实时可靠估计飞行器自身位置（Position）姿态（attitude）。 绝对定位：将相对位姿与全局坐标系关联计算。 利用环绕火星的轨道飞行器的相机拍摄的高分辨率图像作为全局参照。 2、图像匹配技术路线 全图像对其 将小照片放在大照片上移动比较，进行打分，得分高的就是匹配位置。 优点：利用了所有像素信息，在平坦地形上能较好工作，计算简单。 缺点：复杂地形下不可用。 光度特征描述符 先找出两个图像中的特征点，分析特征点周围的像素信息，编码为描述符。对比描述符的相似性。 SIFT，尺度不变特征变换。 优点：适用于3D地形，视觉尺度变化不敏感，计算成本适中。 假设特征点周围是平的，不受地形影响。 尺度和视觉变化不敏感。 计算成本适中。 缺点：光照敏感，依赖纹理 像素的亮度信息计算描述符，当光照剧烈变化时，同一地点的特征描述会受到影响。 在纹理稀疏的区域无法找到足够特征点。 几何特征描述符 关注特征点与周围其他特征点的位置关系（几何信息）。 优点：对光照有鲁棒性 忽略了亮度信息，只看几何结构。 缺点：依赖路标点的可重复性 要求查询图像和地图图像中都能稳定检测到相同的特征点集合。 基于学习的方法 利用深度学习提取特征 优点：利用全局信息 缺点：当时性能未超越SIFT、需要大量数据 3、需求：视觉定位与地图匹配 两种预先制作好的地图： 正射影像（geo-referenced ortho-image，一张无畸变的、带有精确地理坐标的“照片地图”） 数字高程图（DEM，一张包含地形高度信息的“3D地图”） a，数字高程图；b，正射地图 流程 飞行器使用机载相机拍摄实时图像。通过基于特征的配准过程处理图像。寻找实时图像点与预制图特征点的对应关系。 实时图与预制图 尺度、视角、光照、地形变化 找到一种不变性描述符，能在上述剧烈变化下保持稳定，从而让算法能够识别特征点。 匹配技术：2D-2D 与 3D-3D 2D-2D 匹配：直接将一张二维的实时图像与一张二维地图图像进行匹配。普适性强，在完全平坦、缺乏立体特征的区域（例如平原）也能工作。 3D-3D匹配：飞行器通过传感器实时构建局部三维地图模型，与预存的全局三维图进行匹配。依赖地形起伏，在平坦地区会失效。 选择2D-2D。 4、系统架构 地图创建-地面工作 输入：正射影像（精确二维地图），数字高程图（DEM，包含地形的三维图） 处理：在正射图像上识别出特征点。对每一个特征点，计算描述符；通过二维图上的坐标确定DEM上对应点的高度，计算精确三维位置。 输出：地图数据库，记录了每个地标描述符和精确的三维坐标，配备在直升机上。 地图匹配-实时工作 直升机拍摄实时地图-查询地图（query image） 状态估计器，初步位置猜测，缩小搜索范围。 提取query image的特征，与地图库中进行比对，获取多个候选点。 异常匹配值剔除。（RANSAC） perspective-n-points (PnP)算法 精确定位。 输出绝对位姿。可以用来校正 Range-VIO 的累积误差，确保长时间飞行的导航精度。 机载状态估计器（Range-VIO） 独立导航系统，相对定位。 视觉：连续图像特征点估算运动 惯性：IMU提供加速度和角速度 测距：高度计测量离地距离 作用：提供高频连续的姿位估计，会漂移。额外提供了“位姿先验”，辅助绝对定位。 5、地图数据库创建 从巨大的正射图中提取有用不冗余的特征点构成数据库。 1. 分块处理 无法一次性加载整个正射地图。 将地图切割为多块小的瓦片（tiles）。 四周重叠切割，保证边界的特征点被提取。 2. 独立提取特征 特征提取算法对每个瓦片中提取预定数量特征点。 3. 特征筛选 问题：可能出现特征点扎堆。 方案：在提取后的特征点上覆盖一层更精细的网络。强制规定小网格中只保留N个最好的特征点。 4. 聚合与存储 去重：合并重复提取的特征点。（边界重叠） 存储两个信息：描述符，三维坐标。 6、地图匹配 流程 机载相机拍摄图像，特征检测得到特征描述符。 （image-to-map），拍摄图像依次在大地图上按顺序匹配。 map-to-image：利用机载状态估计器（Range-VIO）得到先验位姿。在大地图中得到一个粗略位置小范围，在这个小范围里面找无人机位置。 获取先验：从状态估计器获取姿态 { R, t }（朝向，位置） ，姿态+协方差。 重投影：姿态先验 +姿态不确定性 ⇒地图库关键点 。将可能的地图关键点投影到实时地图2D地图 上。投影函数： 重投影不确定性：姿态先验不确定性通过一阶误差传播得到2D平面点重投影的不确定性 ： 其中分别表示俯仰，偏航和横滚方向。 搜索窗口：对可见关键点，根据重投影不确定性 在query map定义一个搜索窗口。 特征匹配，每个特征窗口执行描述符匹配 SIFT提取实时图像的特征。 地图关键点A对应搜索窗口内， K-D 树找出所有在窗口的图像特征点，与地图关键点计算距离。 选择最佳匹配项，描述符距离最小的作为匹配项。 剔除外点： 比率测试（地图关键点A，窗口匹配最佳B，次佳C），最佳与次佳比值 如果很大（两个点接近，匹配点不唯一），则这个匹配点就不可靠。如果窗口内特征点少于10，从紧邻外部区域借一些特征。保留比值最低的前200个匹配。 RANSAC+PnP，3D-2D点的几何空间匹配，选取几个匹配得到一个变换，其他匹配对这个变换进行测试（投票），迭代取的样本，得分最高的一组被选择。 非线性优化，理由RANSAC找到的内点进行精调，放入非线性最小二乘优化器，使总投影误差最小。 输出一个校准的高精度全局位姿。 点数少于10就匹配失败。 优化：查找表，区域关键点首次计算窗口后，存储结果一个，后续落入该区域的相似计算直接读取该窗口结果。 7、实验（定位成功率） 定位成功率=估计位置误差小于给定误差边界的帧数所占的百分比 合成数据集 AirSim生成，虚幻引擎4作为渲染后端，两种地图源： 杰泽罗，毅力号着陆点，裁剪过的高分辨率成像设备正射影像和对应的数字高程图DEM。 峡谷，虚幻引擎市场中的带纹理三维模型，使用正射投影模型进行渲染。 尺寸： 杰泽罗地图（正射影像和DEM）像素分辨率：1m/像素 峡谷地图：0.3m/像素 分别1000张查询图像，尺寸512 * 512 像素。视场角90°。 不同视角变换的鲁棒性，每个地图有3个不同数据集 飞机高度，相机视角，机头方向 数据集 变量 验证能力 数据集1 飞行高度 特征描述符的尺度不变性 数据集2 俯仰角[-45°，+45°] 视角不变性 数据集3 相机偏航角（飞机打转） 旋转不变性 特征提取模型测试 在两种场景，各三个数据集上进行了测试。 模型 SIFT SURF ORB SuperPoint（CVPR2018） superpoint不具备尺度不变性。 SuperPoint的找特征点的能力好，但是没有尺度不变性。 光照变化测试 由于风向等因素，早晨飞行环境最佳，但1HIRISE图像在下午拍摄 同一视点在不同太阳视角下的图像。 不同太阳视角下累计定位成功率。 穷举与先验对比 实际场景实验 实验场地 JPL附近一个公园，在12-100米的不同高度进行地图数据采集，得到25cm/像素的正射图和DEM。 区域范围600*500m，下午3:37拍摄，以此创建了地图数据库。 实验无人机 机载导航相机——该相机与“机智号”火星直升机所使用的型号相同。 真值系统，打在了RTK-GPS模块，提供精确定位。 实验设计 多高度飞行，12m到100米多个高度测试，尺度变化 多时段飞行，中午12:49到下午4:11（地图制作时间3:37），光照角度变化。 ！引导系统（位姿先验） Range-VIO算法，相对定位（VIO）+ 绝对定位（地图匹配） ！坐标转换 地图坐标系（数据库） GPS坐标系 xVIO坐标系 GPS→Map：通过地理信息系统GIS变换（UTM） xVIO→Map：无人机先飞，记录GPS轨迹与xVIO轨迹，对齐反推旋转角度。 LRF限制 测高仪LRF有效量程20m。xVIO依赖这个高度。 位姿先验会受损，在高空（35,50,100m）无法使用引导式匹配（ 有界搜索）。 基于限制的评估方案 所有高度都不引导，统一使用最困难的穷举匹配。 在12米和20米，进行一次额外引导实验。位姿引导有多大提升。 左：成功/总拍摄帧 右：成功/返回了结果的 ！！！性能指标（工程可实现性） 在Intel i7-9700k单核上，单张查询图像的定位平均耗时0.3秒。 可以在snapdragon 855处理器上部署。 ！！！• 在80米这个高度，无人机实时拍摄的照片，其地面分辨率（每个像素代表多大的地面面积）与预先制作的地图的分辨率完全相同（都是25厘米/像素）。 尺度变化极限 参考基准——在80米高空飞行时，无人机拍下的照片分辨率（25厘米/像素）与地图的分辨率完全一样。这是最理想的1:1尺度，匹配效果最好。 边界——1）12米超低空，无人机拍摄细节丰富，地图（25cm/像素）相比模糊，尺度差别大，超过了SIFT极限；2）20米高度，4倍尺度差异，识别率不稳定；3）20米以上，进入了舒适区，2m误差精度极高 位姿先验真实用处 带先验和穷举搜索对比 在20m位置，能够提升成功率，位姿先验使算法在困难情况下提高精度 火星着陆测试 “毅力号”火星车（Mars 2020 mission）在“七分钟”着陆过程中，其着陆器相机（Lander Vision System Camera, LCAM）向下拍摄的一系列连续图像。 图1是什么 没有位姿先验 使用穷举匹配 只在着陆附近区域搜索。 成功高度范围：7KM — 110米，巨大尺度不变性 高空定位能力 未来 在低空飞行和高差地形上光照变化情况下的匹配方法 将全局参考直接整合到状态估计器","categories":[{"name":"mars","slug":"mars","permalink":"https://dekelkai.github.io/categories/mars/"}],"tags":[{"name":"Mars","slug":"Mars","permalink":"https://dekelkai.github.io/tags/Mars/"},{"name":"CV","slug":"CV","permalink":"https://dekelkai.github.io/tags/CV/"}],"author":"Dekel"},{"title":"机智号 Vision-Based Navigation for the NASA Mars Helicopt","slug":"机智号-Vision-Based-Navigation-for-the-NASA-Mars-Helicopt","date":"2025-10-17T09:35:26.000Z","updated":"2025-10-17T10:06:34.670Z","comments":true,"path":"2025/10/17/机智号-Vision-Based-Navigation-for-the-NASA-Mars-Helicopt/","permalink":"https://dekelkai.github.io/2025/10/17/%E6%9C%BA%E6%99%BA%E5%8F%B7-Vision-Based-Navigation-for-the-NASA-Mars-Helicopt/","excerpt":"","text":"introduction 💡 目前的火星探测依赖于轨道飞行器和火星车，前者在高空分辨率有限，后者速度慢且受地形限制 直升机的主要优势： 快速机动性：能快速跨越广阔距离，不受地形障碍影响。 高分辨率成像：能在数米至数十米的低空提供详细的火星表面图像。 💡 火星直升机的关键设计特点和技术规格 物理尺寸与重量：高约80厘米，重1.8公斤。 旋翼设计：拥有两个直径1.21米的共轴反转旋翼。其旋翼尺寸相对于其重量来说非常大，这是为了适应火星密度仅为地球1-2%的稀薄大气。 核心部件：机身是一个立方形的“温暖电子设备箱”，内部装有航空电子设备、电池和传感器，并具备隔热和加热功能以抵御火星夜间的严寒。 能源系统： 电池：能够支持超过90秒的飞行，并为非飞行状态下的设备运作和夜间保温提供电力。 太阳能板：安装在直升机顶部，负责在飞行间隙为电池充电。 电子控制模块（EMC）上的导航传感器 上部传感器： IMU（惯性测量单元），测量三轴的加速度和角速率。（博世（Bosch）BMI-160） nclinometer (倾角仪)，用于飞行前的校准和初始化，以测量横滚和俯仰姿态。（muRata SCA100T-D02） 下部传感器： Lidar Altimeter (激光雷达高度计)，测量到地面的距离。（佳明（Garmin）Lidar-Lite-V3） 备用IMU。 Mono Camera (单色相机)，向下看的、分辨率为640x480的相机，用于拍摄地面图像。（Omnivision OV7251全局快门传感器） 特殊指向的传感器： Nadir Pointed Camera and Altimeter，相机拍摄的是正下方的图像，高度计测量的也是垂直距离。 三大核心硬件，FPGA、NAV PROCESSOR（NP）、FLIGHT COMPUTER（FC）。 视觉数据处理： Camera → Vision Processing → State Estimator 惯性与传感器数据处理： IMU (加速度计 + 陀螺仪), 高度计, 倾角仪 → FPGA → FC（NF） FPGA处理多源高频的同步数据读写。 FC（NF） IMU积分修正（coning、sculling）误差。 降采样到500Hz。 偏差修正。 时间对齐。 故障处理。 上下层数据融合 (NF data + Vision Processing data) → State Estimator → with timestamp 反馈输出 → 异步控件 → FC(更新自己的状态+坐标系转换) → → Controller 核心模块（MAVeN） 接收两个部分传来的数据，vision process + FLIGHT COMPUTER（NF）。 Navigation Algorithm 💡 传统导航方法的局限性 预先绘制地图：No。现有的火星地图由轨道器绘制，分辨率太低，没法绘制准确高精度高细节的火星地图。 SLAM算法：No。SLAM实时创建地图并进行定位，维度大，计算量大，火星无人机携带资源有限。 🔑 选择的替代方案：基于速度测量 (Velocimetry)： 核心思想：通过对比连续的图像来计算飞行器的相对位置的移动。 优点：简单，滤波器阶数低，计算负担小，适合实时计算。 缺点：存在位置漂移，且误差会随时间累积。文中提到火星无人机的飞行时间短，累计误差可接受。 ⏰ MAVeN（基于视觉导航的最小增强状态算法, Minimal Augmented state algorithm for Vision-based Navigation）： 工作原理：类似SLAM，但避免了将大量特征点加入状态向量，保持较低的计算复杂度。使用21状态的扩展卡尔曼滤波器（EKF）来实现完整的六自由度姿态估计。 关键前提：需要一个关于地形的“分面形状模型”。 应用中简化：由于火星没有现成的高精度地形模型，MAVeN算法做了一个重要简化：假设地面是完全平坦的。这一简化是可行的，因为直升机计划在坡度非常平缓（1-3度）的区域飞行。 辅助设备：弥补简化模型的不足并确保安全，额外增加了一个高度计（Nadir Pointed Camera and Altimeter），用于直接测量离地高度。 💡 算法描述 21维扩展卡尔曼滤波。 状态 符号 含义 备注 Search state Search state 的位置 (position, 3-dim) 系统在搜索状态下的空间位置 Search state Search state 的速度 (velocity, 3-dim) 系统在搜索状态下的速度 Search state Search state 的姿态 (attitude quaternion, 3-dim) 用四元数表示方向，4 元素但只算 3 个自由度 Bias terms 加速度计的偏置 (accelerometer bias, 3-dim) 用于修正加速度计测量误差 Bias terms 陀螺仪的偏置 (gyro bias, 3-dim) 用于修正陀螺仪测量误差 Base state Base state 的位置 (position, 3-dim) 从 Search state 在某个时间点克隆得到 Base state Base state 的姿态 (attitude quaternion, 3-dim) 同上，克隆得到，保持不随时间演化 Search state (搜索状态) 就是系统在“当前时刻”的位置、速度和姿态，EKF（扩展卡尔曼滤波）在更新时依赖它。 Base state (基准状态) 它其实是 Search state 的克隆，在特定时间点 把当时的 保存下来，作为基准，用来和后续图像对齐。 用于多时刻图像匹配（两个时刻的图像一起处理时，Base state 提供了之前的状态来做关联）。 Biases () 用来修正传感器的系统误差，因为加速度计和陀螺仪都会有零偏（drift）。 四元数 代表姿态（方向/旋转）。虽然写成 4 维向量，但 EKF 里只算作 3 个自由度。 也可以等价地用方向余弦矩阵 (DCOS matrix) 表示。 Base state 在克隆之后，Base state 被当作静止保存： 不随时间演化，在创建时刻从 Search state 复制过来。 总结：Search state 是实时估计的状态（位置、速度、姿态 + 传感器偏置），而 Base state 是某一时刻克隆的“冻结”状态，用于图像配准。 1、确定基准图像； 2、算法在基准图像的基础上给出一些检测点，假设特征点位于同一平面，通过几何投影计算出特征点的三维坐标，作为伪地标。 3、飞行器移动下一帧作为搜索图像； 4、在搜索图像中寻找并匹配基准图像中的伪地标，得到m个匹配点； 5、根据当前几何关系计算观测方程，然后进行EKF更新； 6、越往后特征点m越少，说明飞行器和环境变化大，放弃当前基准图像，将下一张新图作为基准图像。 💡 稳定悬停属性 在静止悬停条件下会进入一种奇异状态，从而产生无效的测量信息。 方法A：变成完全SLAM (用持久化特征扩充状态) 方法B：模式切换 (悬停检测与切换估计器) A、B都会导致系统变得庞大复杂。 MAVeN 算法中的公式 基础设定与相机模型 坐标系 (Frames): 我们设定了一个固定的世界地图 () 和一个跟着相机移动的自身视角 ()。算法中的基础帧()和搜索帧()只是在两个不同时刻对这个自身视角(Camera)的“快照”。 位姿 (Pose): 用位置 () 描述相机在世界地图的哪里，用姿态 () 描述相机的镜头朝向哪里。 投影 (Projection): 相机把三维空间中的视线向量 拍成二维照片点 ，数学上通过除以深度来实现“近大远小”，其公式为： 反投影 (Un-projection): 从二维照片点 ，我们能反推出一个单位长度的三维方向向量 ，但无法知道距离。其公式为： 其中 备注：系统能识别“静止状态”，从而冻结参考帧，保持稳定性。 同时优化 base frame点，在状态向量中有x。 🫥 视觉处理（Vision Processor） 特征检测 特征跟踪 异常剔除 触发新特征 特征检测 模型：改进FAST角点检测 将图像划分为3*3网格。 每个网格独立检测 根据角点分数择优选择 选择了最高分点后抑制周围点（避免扎堆） 特征跟踪 模型：KLT (Kanade-Lucas-Tomasi) 跟踪器 假设在一个小窗口内，特征点的像素模板不变，通过梯度下降来寻找这个模板在下一帧图像中的最佳匹配位置。 为了提高鲁棒性和效率做的优化： 图像金字塔 (Image Pyramid) 在不同分辨率的图像上进行跟踪，这使得算法能够处理更大的运动。 陀螺仪辅助去旋转 (Gyro Derotation) 这是应对高速旋转的关键！在运行KLT之前，算法会先使用IMU的陀螺仪数据来预测由于旋转导致的图像位移，并对特征点的初始搜索位置进行补偿。这大大缩小了KLT的搜索范围，使其在高达80度/秒的角速度下依然能稳定工作。 异常值剔除 剔除KLT跟踪过程中错误的匹配点。 方法：基于单应性矩阵的RANSAC算法 抽取一小部分特征点 计算两帧图像之间平面变换“单应性矩阵” 计算其他匹配点有多少符合这个变换 迭代矩阵，找到被“主流”匹配点支持的最佳变换 剔除不符合最佳变换的匹配点 影子会被识别为异常值。会倾向于保留同一平面的点，符合平面假设。 绿色的短线段描绘了留下的匹配点的运动轨迹。 触发新bese frame 无法再找到到足够多的匹配点 数量阈值：经过RANSAC剔除后剩余特征点少于40个。 分布阈值：在3*3方格中超过3个方格没有特征点。 时间阈值：对同一组特征点连续跟踪超过10帧。 由于帧率是30Hz，这相当于大约0.33秒。这个限制是为了避免在非平坦地形上跟踪太久导致误差累积。 计算性能 骁龙801处理器的单个核心上处理时间 Base Frame处理 (特征检测)、Search Frame处理 (特征跟踪+RANSAC) Vision Processor 处理细节 视觉处理流程必须在33ms完成，达到30Hz的帧率 FAST阈值选择 高阈值特征点少质量高，低阈值反之。为确保在纹理稀疏的火星表面总能找到足够多的特征点，团队选择了固定使用一个较低的FAST检测阈值3，限制最大数量,结合网格选取，点应该是大致均匀分布在图像上。 COTS硬件的利弊 骁龙处理器是项目成功的关键，但其发热降频、非实时系统和闭源驱动也带来了巨大的开发挑战，许多参数只能通过繁琐的试错来优化。 自动曝光控制（对KLT） 为了让KLT跟踪器稳定工作，软件在自动调整曝光时，严格限制了相邻帧之间的曝光变化量，以避免亮度突变导致跟踪失败。 应对图像锐化 骁龙处理器内部的图像信号处理器（ISP）为手机拍照优化的自适应锐化功能，对计算机视觉算法有害，但因无法关闭，团队只能忍受其负面影响并完成了所有测试和飞行。选择性地启用了ISP硬件的一个功能——暗角补偿 (radiometric darkening compensation)，这有助于KLT在图像中心和边缘之间更好地跟踪特征。 IMU惯性测量单元、扩展卡尔曼滤波推导，状态预测和图像处理的关联和区别。","categories":[],"tags":[],"author":"Dekel"},{"title":"理解卡尔曼滤波","slug":"卡尔曼滤波","date":"2025-10-03T09:03:26.000Z","updated":"2025-10-03T09:40:00.254Z","comments":true,"path":"2025/10/03/卡尔曼滤波/","permalink":"https://dekelkai.github.io/2025/10/03/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2/","excerpt":"","text":"卡尔曼滤波学习笔记（预测+更新） 前言 卡尔曼滤波（Kalman Filter, KF）是一种递归估计方法，用于在噪声环境下对系统状态进行最优估计。核心思想是 预测 + 更新，通过不断迭代提高状态估计精度。 系统模型回顾 线性系统模型： 符号 含义 系统状态向量（位置、速度等） 状态转移矩阵 控制输入矩阵 控制输入 过程噪声 观测向量 观测矩阵（状态 → 观测空间） 观测噪声 阶段一：预测阶段（Prediction） 预测阶段的目标是 根据系统模型预测下一时刻状态及不确定性。 1. 状态预测 ：预测的状态 ：上一时刻更新后的状态估计 ：控制输入对状态的影响 直观理解：用物理模型（状态转移）预测未来位置、速度等。 2. 协方差预测 ：预测状态协方差 ：预测协方差随状态转移变化 ：过程噪声协方差（增加不确定性） 直观理解：预测不仅预测状态，还预测“对状态的不确定性”。 阶段一核心点 输出： 预测状态 预测协方差 预测阶段只依赖系统模型，不依赖观测数据。 阶段二：观测更新阶段（Update / Correction） 更新阶段的目标是 利用观测数据修正预测，提高状态估计精度。 1. 卡尔曼增益 ：卡尔曼增益 ：观测总协方差（预测+噪声） ：把观测信息从观测空间映射回状态空间 核心意义：决定对观测与预测的权重 - 观测可信 → K大 → 更新更多依赖观测 - 观测不可靠 → K小 → 更新更依赖预测 2. 状态更新 ：创新（观测残差） K 调整残差的大小和方向，使状态向观测靠近 输出：更新后的状态估计 直观理解：把观测信息“回传”到状态空间，同时考虑状态间的相关性（P矩阵）。 3. 协方差更新 更新后的协方差减小（状态更确定） 对角线元素减小 → 每个状态分量的不确定性下降 非对角元素 → 状态间相关性更新 阶段二核心点 核心公式：卡尔曼增益、状态更新、协方差更新 功能：根据观测修正预测，减少不确定性 几何意义：状态椭球体缩小，向观测靠近 两阶段总结 阶段 目标 核心公式 输出 预测 根据系统模型预测状态与不确定性 , 预测状态 , 预测协方差 更新 利用观测修正预测，提高精度 , , 更新状态 , 更新协方差 直观理解 状态与观测空间 ：状态 → 观测空间 ：观测空间 → 状态空间 协方差 vs 信息矩阵 大 → 不确定性大 → 更新时更依赖观测 大 → 确信度高 → 权重高 卡尔曼增益的直观意义 观测噪声大 → 信任观测少 → 小 状态预测不确定性大 → 信任观测多 → 大 几何类比 协方差矩阵 就像状态分布的椭圆 投影 → 椭圆投影到观测空间 → 残差反向拉回状态空间，按协方差分配更新 结语 卡尔曼滤波的核心就是 最优线性估计 两阶段循环执行：预测 → 更新 → 下一时刻预测 → 更新…… 理解矩阵维度、投影和回传关系是理解卡尔曼滤波公式的关键","categories":[{"name":"学习","slug":"学习","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://dekelkai.github.io/tags/%E7%AE%97%E6%B3%95/"}],"author":"Dekel"},{"title":"前端框架的路由组件（router）的作用","slug":"前端框架的路由组件（router）的作用","date":"2025-09-30T09:47:57.000Z","updated":"2025-10-02T08:50:46.687Z","comments":true,"path":"2025/09/30/前端框架的路由组件（router）的作用/","permalink":"https://dekelkai.github.io/2025/09/30/%E5%89%8D%E7%AB%AF%E6%A1%86%E6%9E%B6%E7%9A%84%E8%B7%AF%E7%94%B1%E7%BB%84%E4%BB%B6%EF%BC%88router%EF%BC%89%E7%9A%84%E4%BD%9C%E7%94%A8/","excerpt":"","text":"这段代码是一个典型的基于 Backbone.js 框架的前端路由（Routing）示例。它定义了应用程序如何根据浏览器地址栏中的 URL 片段（Hash） 来执行不同的功能，而无需重新加载整个页面。 123456789101112131415161718192021222324252627282930313233343536373839404142434445// backbone.js代码：(function() {window.App = { Models: {}, Collections: {}, Views: {}, Router: {}};App.Router = Backbone.Router.extend({ routes: { '': 'index', 'show/:id': 'show', 'download/*random': 'download', 'search/:query': 'search', '*other': 'default' }, index: function() { $(document.body).append(\"调用了 Index 路由&lt;br&gt;\"); }, show: function(id) { $(document.body).append(\"调用了 Show 路由，id 等于 \" + id + \"&lt;br&gt;\"); }, download: function(random) { $(document.body).append(\"调用了 Download 路由，参数等于 \" + random + \"&lt;br&gt;\"); }, search: function(query) { $(document.body).append(\"调用了 Search 路由，参数等于 \" + query + \"&lt;br&gt;\"); }, default: function(other) { $(document.body).append(\"你访问的 \" + other + \" 路由未定义&lt;br&gt;\"); }});new App.Router();Backbone.history.start();})(); 1️⃣ 自执行函数包装 (function() { ... })(); 123(function() { // 代码块})(); 这是一个自执行匿名函数，避免全局变量污染。 所有变量都在这个函数作用域里，不会直接挂在 window 上（除了明确放进去的，如 App）。 2️⃣ 创建全局 App 命名空间 123456window.App = { Models: {}, Collections: {}, Views: {}, Router: {}}; Backbone 的经典做法：把模型、集合、视图和路由器都集中在一个对象下。 避免全局污染，同时清晰组织代码结构。 3️⃣ 定义路由器 App.Router 12345678910App.Router = Backbone.Router.extend({ routes: { '': 'index', 'show/:id': 'show', 'download/*random': 'download', 'search/:query': 'search', '*other': 'default' }, ...}); 路由定义规则： '' → 空路径时调用 index 方法（首页）。 show/:id → URL 形如 #show/123 时，id 是 123。 download/*random → * 捕获剩余路径，例如 #download/path/to/file，random = path/to/file。 search/:query → 例如 #search/abc，query = abc。 *other → 捕获所有未定义路由，作为“404”处理。 4️⃣ 路由对应的函数 123456789101112131415index: function() { $(document.body).append(\"调用了 Index 路由&lt;br&gt;\");},show: function(id) { $(document.body).append(\"调用了 Show 路由，id 等于 \" + id + \"&lt;br&gt;\");},download: function(random) { $(document.body).append(\"调用了 Download 路由，参数等于 \" + random + \"&lt;br&gt;\");},search: function(query) { $(document.body).append(\"调用了 Search 路由，参数等于 \" + query + \"&lt;br&gt;\");},default: function(other) { $(document.body).append(\"你访问的 \" + other + \" 路由未定义&lt;br&gt;\");} 这些方法会在 URL 哈希改变时被调用。 比如你访问 http://localhost/#show/5： 路由器匹配 show/:id 调用 show(5) 方法 页面会追加 \"调用了 Show 路由，id 等于 5&lt;br&gt;\" 5️⃣ 启动路由 12new App.Router();Backbone.history.start(); new App.Router() → 创建路由器实例。 Backbone.history.start() → 启动 Backbone 的哈希监听： 监听 URL 哈希变化（#xxx） URL 变化时调用对应路由函数 支持浏览器前进后退 6️⃣ 整体流程 页面加载 → 创建路由器。 用户访问 URL（如 #search/hello）或点击链接。 Backbone 解析哈希 → 找到匹配路由。 调用对应方法 → 页面上追加提示。 💡 补充说明 :param 是单个占位符，*param 可以匹配路径中的 /。 这是一个前端单页面路由（SPA），不刷新页面。 $(document.body).append(...) 是为了演示，实际项目通常用视图更新 DOM。","categories":[{"name":"学习","slug":"学习","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"前端","slug":"学习/前端","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"React","slug":"React","permalink":"https://dekelkai.github.io/tags/React/"}],"author":"Tang Xiangkai"},{"title":"论文-Strong Baseline: Multi-UAV Tracking via YOLOv12 with BoT-SORT-ReID","slug":"论文-Strong-Baseline-Multi-UAV-Tracking-via-YOLOv12-with-BoT-SORT-ReID","date":"2025-09-17T08:51:13.000Z","updated":"2025-09-17T10:27:39.811Z","comments":true,"path":"2025/09/17/论文-Strong-Baseline-Multi-UAV-Tracking-via-YOLOv12-with-BoT-SORT-ReID/","permalink":"https://dekelkai.github.io/2025/09/17/%E8%AE%BA%E6%96%87-Strong-Baseline-Multi-UAV-Tracking-via-YOLOv12-with-BoT-SORT-ReID/","excerpt":"","text":"提出的方法以及数据集的缺陷 基于热红外视频的多无人机跟踪任务 该论文方法与 YOLOv5[18]和 DeepSORT[40]管道进行对比。使用了YOLOv12探测器和BoT-SORT-ReID pipline。此外还采用了一些方法提高了多无人机的跟踪性能。 图 (a)显示了来自 MOT 训练集的不同背景的热红外帧，而图 1 (b)突出了一些小缺陷，如注释错误、冗余、缺失标签和低质量帧，这些缺陷在数据集中占的比例可以忽略不计，在训练过程中可以安全地忽略。(反无人机比赛数据集) 普遍采用的提升方法 现有改进主要集中在 时间建模、实时优化、统一框架、检测后处理 上述四个方面，而作者的工作在此基础上结合最先进的检测器与跟踪器，在热红外多无人机跟踪上创造了新 benchmark，并指引后续研究。 详细方法 1、问题陈述 尽可能准确地跟踪无人机，评价指标： 提供初始位置的MOT任务。 2、数据 track3 YOLOv12 + BoT-SORT YOLOv12 简单在线实时多目标跟踪技巧优化 BoT-SORT：卡尔曼滤波+运动相机补偿 稳定动态条件下的跟踪 https://github.com/NirAharon/BoT-SORT","categories":[{"name":"论文","slug":"论文","permalink":"https://dekelkai.github.io/categories/%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"学习","slug":"学习","permalink":"https://dekelkai.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"目标跟踪","slug":"目标跟踪","permalink":"https://dekelkai.github.io/tags/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/"},{"name":"无人机","slug":"无人机","permalink":"https://dekelkai.github.io/tags/%E6%97%A0%E4%BA%BA%E6%9C%BA/"},{"name":"YOLO","slug":"YOLO","permalink":"https://dekelkai.github.io/tags/YOLO/"}],"author":"Tang Xiangkai"},{"title":"强化学习（三.1）贝尔曼最优策略和公式推导","slug":"强化学习（三-1）贝尔曼最优策略和公式推导","date":"2025-09-10T14:55:37.000Z","updated":"2025-09-10T15:14:32.589Z","comments":true,"path":"2025/09/10/强化学习（三-1）贝尔曼最优策略和公式推导/","permalink":"https://dekelkai.github.io/2025/09/10/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%89-1%EF%BC%89%E8%B4%9D%E5%B0%94%E6%9B%BC%E6%9C%80%E4%BC%98%E7%AD%96%E7%95%A5%E5%92%8C%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/","excerpt":"","text":"强化学习中的策略优化推导 在强化学习（Reinforcement Learning, RL）中，状态值函数的定义经常涉及一个关于策略 的最优化问题。本文将结合数学推导，解释如何从 Bellman 方程推导出最优策略的形式，并说明为什么最优策略是 贪心策略（greedy policy）。 1. 从 Bellman 方程出发 我们考虑状态值函数（假设已知一个固定的下一步值函数 ）： 其中： ：策略，在状态 下选择动作 的概率； ：奖励的条件分布； ：环境转移概率。 约束条件是： 2. 引入动作值函数 将括号内的部分记作动作值函数 ： 于是值函数可以写成更简洁的形式： 3. 问题转化为线性优化 到这里，我们得到的优化问题是： 约束条件： 这其实就是一个经典的线性规划问题：在概率分布（simplex 单纯形）上对线性目标函数取最大值。 4. 极值的几何直观 线性函数在单纯形上的最优解一定出现在某个极点（vertex）。单纯形的极点就是“所有概率质量集中在一个动作上”，亦即： 对某个 因此，最优解就是选择使 达到最大值的动作。 5. 得出最终结果 于是可以直接得到： 最优策略的形式为： 如果存在多个并列最大的动作，则在这些动作之间任意分配概率（例如平均分配）也能获得相同的最优值。 6. 小结 策略优化问题本质上是一个线性优化问题； 线性目标在概率单纯形上的最优解落在极点； 因此，给定 的情况下，最优策略是在最大 对应的动作上取 1 的确定性贪心策略。","categories":[{"name":"学习","slug":"学习","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"RL","slug":"RL","permalink":"https://dekelkai.github.io/tags/RL/"},{"name":"reinforce learning","slug":"reinforce-learning","permalink":"https://dekelkai.github.io/tags/reinforce-learning/"}],"author":"Tang Xiangkai"},{"title":"强化学习（二）状态值与贝尔曼方程","slug":"强化学习（二）状态值与贝尔曼方程","date":"2025-09-09T07:59:00.000Z","updated":"2025-09-30T09:43:50.439Z","comments":true,"path":"2025/09/09/强化学习（二）状态值与贝尔曼方程/","permalink":"https://dekelkai.github.io/2025/09/09/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%BA%8C%EF%BC%89%E7%8A%B6%E6%80%81%E5%80%BC%E4%B8%8E%E8%B4%9D%E5%B0%94%E6%9B%BC%E6%96%B9%E7%A8%8B/","excerpt":"","text":"1. 回报（Return） 在 RL 中，智能体和环境交互，每一步都会得到一个奖励 。智能体追求的目标并不是单个奖励，而是从某个时刻开始累积到未来的回报(Return)： 这里 是折扣因子(discounted rate)，用来平衡「眼前奖励」和「长期奖励」。 由于环境具有不确定性， 是一个随机变量，我们通常关心的是它的期望值。 2. 状态值函数 (State Value Function) 在策略下，状态值函数定义为： 表示从状态 出发，按照策略 行动，未来累积的回报期望值。 3. 动作值函数 (Action Value Function) 类似地，动作值函数定义为： 表示在状态 ，执行动作 ，然后遵循策略 后能获得的期望回报。与状态值不同，动作值额外考虑了动作的选择，因此信息更细致。 状态值函数与动作值函数的关系： 即：状态值等于动作值的加权平均。 4. 贝尔曼期望方程 状态值满足一个递推关系： 其中： ：在状态 下的期望奖励 ：在策略 下从状态 转移到 的概率 换句话说，状态值 = 即时奖励 + 折扣后的未来价值。 同样，动作值也有贝尔曼形式： 其中： 第一项是执行动作 后获得的期望奖励； 第二项是未来可能到达的状态价值的加权平均； 因此，动作值体现了即时奖励与未来状态值的结合。 5. 矩阵向量形式 如果我们把所有状态的值函数写成向量，就能得到： 其中： ：所有状态值组成的向量 ：期望奖励向量 ：状态转移矩阵 解析解： 但在大规模环境中，直接求逆不可行，所以需要数值解法。 6. 数值解：迭代方法 数值解最常见的是迭代策略评估： 迭代步骤： 初始化 不断迭代更新直到收敛 这种方法的直观解释是：逐步逼近真实价值，每一步都让估计更接近真实的回报。 7. 状态值与动作值的关系总结 状态值：评价「处于某状态的好坏」 动作值：评价「在某状态执行某动作的好坏」 状态值是动作值的加权平均，而动作值又依赖于奖励与未来状态值 贝尔曼方程就是这种递推关系的数学形式","categories":[{"name":"reinforce learning","slug":"reinforce-learning","permalink":"https://dekelkai.github.io/categories/reinforce-learning/"}],"tags":[{"name":"reinforce learning","slug":"reinforce-learning","permalink":"https://dekelkai.github.io/tags/reinforce-learning/"}],"author":"Dekel"},{"title":"强化学习（一）Basic Concepts","slug":"强化学习（一）Basic Concepts","date":"2025-09-04T16:07:41.000Z","updated":"2025-09-30T05:36:41.796Z","comments":true,"path":"2025/09/05/强化学习（一）Basic Concepts/","permalink":"https://dekelkai.github.io/2025/09/05/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89Basic%20Concepts/","excerpt":"","text":"Set • State: the set of states S • Action: the set of actions A(s) is associated for state s ∈ S. • Reward: the set of rewards R(s, a). Probability distribution • State transition probability ​ at state s, taking action a, the probability to transit s to state s' : • Reward probability: ​ at state s, taking action a, the probability to get reward r : Policy at state s, the probability to choose action a is Markov property(memoryless property)","categories":[{"name":"RL","slug":"RL","permalink":"https://dekelkai.github.io/categories/RL/"}],"tags":[{"name":"RL","slug":"RL","permalink":"https://dekelkai.github.io/tags/RL/"}],"author":"Dekel"},{"title":"毕业设计-自适应和互信息最大化无人机实时追踪蒸馏模型","slug":"毕业设计-自适应和互信息最大化无人机实时追踪蒸馏模型","date":"2025-02-20T11:31:12.000Z","updated":"2025-09-17T08:35:45.770Z","comments":true,"path":"2025/02/20/毕业设计-自适应和互信息最大化无人机实时追踪蒸馏模型/","permalink":"https://dekelkai.github.io/2025/02/20/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1-%E8%87%AA%E9%80%82%E5%BA%94%E5%92%8C%E4%BA%92%E4%BF%A1%E6%81%AF%E6%9C%80%E5%A4%A7%E5%8C%96%E6%97%A0%E4%BA%BA%E6%9C%BA%E5%AE%9E%E6%97%B6%E8%BF%BD%E8%B8%AA%E8%92%B8%E9%A6%8F%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"1. 输入处理 输入： 模板图像 ，通常是初始帧或前一帧，尺寸较小，聚焦于目标物体。 搜索图像 ，当前帧中需要搜索的区域，尺寸较大，覆盖目标可能的移动范围。 分块： 和 分为 大小的块，数量分别为： 线性投影： 每个小图像块通过线性层映射为维度 的嵌入向量。 位置编码： 使用可学习的位置编码，保留空间信息。 2. 激活模块 (AM) 2.1 基本定义 考虑第 层 ，tokens 的总数记为 ，嵌入向量的维度记为 。 第 层输出的 tokens 记为 。 第 层 Transformer 块输出的标记切片表示为： 其中 是标准单位向量。 线性层标记为 。 2.2 激活模块公式 激活模块（Activation Module, AM）表示为： 其中： 表示第 层 Transformer 块的激活概率。 为 sigmoid 激活函数：。 2.3 激活规则 设 为激活概率阈值。 若 ，则第 层 Transformer 块被激活。 否则，跳过第 层，直接将第 层的输出 tokens 传递给第 层。 2.4 强制激活与稀疏性 强制激活： 若所有 个 Transformer 块都未被激活，则无法计算模板图像和搜索图像之间的相关性。 因此，设定前 层始终保持激活状态，以确保基础信息的传递。 区块稀疏性损失 ： 若所有输入经过 AM 都使 Transformer 模块激活，会导致效率降低。 引入区块稀疏性损失，鼓励在平均情况下停用更多的 Transformer 块： 其中 为常数，与 共同控制模块的稀疏性。 3. 通过互信息 (MI) 最大化表征视图不变性 (VIR) 3.1 互信息 (MI) 定义 给定两个随机变量 和 ，它们之间的 MI 为： 其中： 是联合概率分布。 是边缘概率分布。 是库尔贝克-莱布勒散度。 3.2 基于 JSD 的 MI 估计 由于现实中无法直接估计 MI，采用基于詹森-香农散度 (JSD) 的 Deep InfoMax MI 估计器： 其中： 是一个神经网络，将输入空间映射到实数空间。 是 softplus 函数。 3.3 视图不变性损失 真实目标定位 token 表示为： 其中 。 给定目标在搜索图像中的真实定位 ，通过线性插值获得对应的 token： 视图不变性损失函数为： 4. 基于知识最大化的多教师知识蒸馏 (MD) 4.1 教师模型与学生模型 教师模型：使用 3 种已有的跟踪模型（AVTrack-DeiT、AVTrack-ViT 和 AVTrack-EVA），提供多样化且高质量的教师模型。 学生模型：选择自相似结构，使用较小的 ViT 主干网（一半 ViT 块），具有模块化和可扩展特性。 4.2 教师输出处理 平均所有教师的预测结果，得到聚合特征表示： 使用温度 对模型输出进行软化处理： 其中 。 4.3 互信息最大化 目标函数为： 在蒸馏训练中，使用 和教师模型的总损失函数的加权和来训练学生模型。 5. 预测头和训练目标 5.1 拐角检测头 对搜索图像的特征进行处理，直接估计目标物体的边界框。 生成 3 个输出： 目标分类分数 ，表示每个位置是目标中心的概率。 局部偏移 ，用于微调目标位置的偏移量。 归一化边界框大小 ，表示边界框的宽度和高度。 根据分类分数的最大值确定目标的粗略位置： 结合局部偏移和边界框大小，最终确定目标的边界框： 5.2 总损失函数 总损失函数为加权焦点损失： 其中： ，。 ，。 在蒸馏阶段，总损失为： 其中 。 核心 动态激活模块：通过稀疏性损失实现按需计算，效率提升约30%。 视图不变性学习：基于MI最大化，增强模型对视角变化的鲁棒性。 多教师蒸馏：轻量化学生模型性能接近教师，计算量减少50%。","categories":[{"name":"实时追踪","slug":"实时追踪","permalink":"https://dekelkai.github.io/categories/%E5%AE%9E%E6%97%B6%E8%BF%BD%E8%B8%AA/"}],"tags":[{"name":"大学","slug":"大学","permalink":"https://dekelkai.github.io/tags/%E5%A4%A7%E5%AD%A6/"}],"author":"Dekel"},{"title":"🥸反向传播中梯度消失和梯度爆炸的原因🥸","slug":"反向传播中梯度消失和梯度爆炸的原因","date":"2025-02-06T15:36:11.000Z","updated":"2025-09-17T08:43:38.805Z","comments":true,"path":"2025/02/06/反向传播中梯度消失和梯度爆炸的原因/","permalink":"https://dekelkai.github.io/2025/02/06/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E4%B8%AD%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E5%92%8C%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E7%9A%84%E5%8E%9F%E5%9B%A0/","excerpt":"","text":"在深度学习中，梯度消失和梯度爆炸是训练深层神经网络时常见的挑战。要真正理解这些问题，必须深入理解反向传播的机制，尤其是梯度是如何通过链式法则逐层传播的。本文通过手推反向传播的数学推导，帮助理解梯度消失和梯度爆炸的根本原因。 在深度学习中，梯度消失和梯度爆炸是训练深层神经网络时常见的挑战。要真正理解这些问题，必须深入理解反向传播的机制，尤其是梯度是如何通过链式法则逐层传播的。本文通过手推反向传播的数学推导，帮助读者理解梯度消失和梯度爆炸的根本原因。 准备工作 在开始反向传播的推导之前，我们需要明确网络的结构和损失函数的定义。假设我们有一个简单的神经网络，包含两个输入、两个隐藏层神经元和两个输出神经元。每个神经元的输出通过sigmoid函数进行激活，损失函数为均方误差。 每个神经元： 其中为sigmoid函数。 损失函数： 反向传播 反向传播是神经网络训练的核心算法，它通过链式法则计算每一层的梯度，并根据梯度更新网络参数。为了理解梯度消失和梯度爆炸问题，我们需要详细推导反向传播的过程。首先，我们从输出层的参数w5开始，逐步推导每一层的梯度。 对参数反向传播: 其中： 故对的偏导为： 对参数进行反向传播 对于加号左部分各偏导： 故： 左部 同理计算可得加号右边部分： 右部 最终得到对的反向传播： 分析 通过手推反向传播的数学推导，我们可以清晰地看到梯度是如何通过链式法则逐层传播的。接下来，我们将分析这些推导结果，探讨梯度消失和梯度爆炸问题的根本原因。 经过手推反向传播的数学推导，我们得到了一个较为复杂的表达式。尽管这只是针对一个简单的网络结构（仅包含一个隐藏层的两个神经元和两个输出神经元）中某个参数更新的计算过程，但其复杂性已经显而易见。为了简化式子，我们将看作，将看作，则上式子结果为： 对于我们只有一个隐藏层两个神经元的网络，就已经得到了如此复杂的式子，且其中的乘法运算比较多，然而我们普遍的神经网络结构为如下图所示： 其中的计算复杂度不敢想象。。。 梯度消失问题 梯度消失问题是深层神经网络训练中的常见挑战之一。它主要表现为在反向传播过程中，梯度随着层数的增加而逐渐变小，最终导致参数更新缓慢甚至停止。为了理解梯度消失问题的根源，我们从激活函数的导数sigmoid入手，分析梯度是如何在传播过程中衰减的。 梯度消失问题的主要原因在于激活函数的导数。以sigmoid函数为例，如下图其导数的最大值为0.25，这意味着在反向传播过程中，梯度会随着层数的增加而不断衰减。具体来说，每一层的梯度都会乘以一个小于1的值，导致梯度在传播过程中逐渐变小，最终接近于零。这种情况下，网络的参数更新会变得非常缓慢，甚至停止更新，导致模型无法有效学习。 为了更直观地理解梯度消失问题，我们可以考虑一个深度神经网络。假设网络有L层，每一层的梯度都会乘以sigmoid函数的导数。由于sigmoid函数的导数小于，经过L次乘法后，梯度会变得非常小。例如，如果每一层的梯度都乘以0.25，那么经过10层后，梯度会变为原来的，几乎可以忽略不计。 梯度爆炸问题 在反向传播过程中，梯度是通过链式法则逐层传播的。每一层的梯度都会乘以该层的权重矩阵。如果这些权重的初始值过大，梯度在传播过程中会不断放大。具体来说，假设某一层的权重矩阵为 W，其值较大，那么在反向传播时，梯度会乘以 W，导致梯度值迅速增大。随着网络层数的增加，这种放大效应会累积，最终导致梯度爆炸。 例如，假设每一层的梯度都乘以一个大于1的因子α，那么在经过 L 层后，梯度会变为原来的 倍。如果 α=2，经过10层后，梯度会放大到 倍。这种指数级的增长会导致梯度值过大，使得参数更新步长过大，模型无法收敛。 解决方案 梯度消失和梯度爆炸问题不仅仅是由于激活函数的导数或权重初始值过大引起的，还与网络的结构、层数以及优化算法的选择密切相关。为了缓解这些问题，可以采用ReLU激活函数、合适的权重初始化方法、梯度裁剪等技术。","categories":[{"name":"Tips","slug":"Tips","permalink":"https://dekelkai.github.io/categories/Tips/"},{"name":"机器学习","slug":"Tips/机器学习","permalink":"https://dekelkai.github.io/categories/Tips/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"学习","slug":"学习","permalink":"https://dekelkai.github.io/tags/%E5%AD%A6%E4%B9%A0/"}],"author":"Dekel"},{"title":"Vision Transformer","slug":"Vision Transformer","date":"2025-01-29T14:14:48.000Z","updated":"2025-09-17T08:44:50.879Z","comments":true,"path":"2025/01/29/Vision Transformer/","permalink":"https://dekelkai.github.io/2025/01/29/Vision%20Transformer/","excerpt":"","text":"VIT模型整体框架✨✨✨ 从整体上来看，VIT模型的结构是很少的，事实上确实如此。如果你明白了我上一篇讲解的Transformer的话，那这篇文章真的就特别简单了，可以说没什么难点。这篇文章作者企图不改变Transformer的结构来实现物体分类任务，我们可以来看一下VIT中的Transformer Encoder 结构，基本是和Transformer中是一样的。注意我这里说的是基本喔，你对比两篇论文中Encoder的结构你会发现，Norm这个结构的位置是有所变化的，至于为什么这样做，作者也没有提及，个人感觉这个改变对结构影响不会很大，感兴趣的可以改变这个结构尝试尝试效果。另外一点是在VIT中没有使用Decoder结构，这里大家需要注意一下。 VIT细节梳理✨✨✨ 首先，想想NLP中的Transformer和CV中的VIT这两个结构输入有什么区别？从变量的类型来看，两者都是一个tensor张量；而从变量的维度来看，NLP中的输入往往是二维的tensor，而CV中往往是一个三维的RGB图像。【都忽略Batch维度】 这种维度的不统一会导致我们不能直接将图片数据喂入到Transformer结构中去，而是需要进行一定的维度转换，即将三维的tensor转换成二维的tensor，这个过程被称为patch_embedding。 那论文中是如何将三维的tensor转化为二维的tensor的呢？如下图所示： 对原图进行卷积，卷积核大小为16163 ,步长为16，padding=0，卷积核个数为768，卷积后，我们会得到特征图，其尺寸为1414768，接着将前两个维度展平，就得到了维度为196*798的tensor。其大致过程如下。 我认为这步使用卷积真的很巧妙，我们得到的196x798的二维向量，其实每一行即1x798都包含了原图中16x16x3大小的patch，这就是卷积的提取特征的功能嘛。【我这样介绍不知道大家会不会有这样的思路——我先用一些CNN模型来对图片提取特征，只要使CNN最后的输出维度为196*768，最后再送入Transformer模型中。其实这就将CNN和Transformer很好的结合在一起了，这种方法是可行的，大家可以自己尝试尝试喔】 现在我们已经得到了196x768维的tensor，我们假设其为x。接下来我们会使用一个维度为1x768维的Class token来和x进行Concat操作，输出结果为197*768维的tensor。这里肯定有人有疑问了，为什么这里会加一个Class token，在上篇讲述的Transformer中可没有这个操作。--小傻瓜--因为这篇文章我们要用来对物体进行分类啊！！！说不定你现在有点怀疑自己了，因为是分类任务所以要加上Class token？这两个还有因果关系不成？一个个问号从你脑海中冒出，百思不得其解。其实啊，这可没什么啥因果关系，只是我们在分类任务中加上Class token可能会效果更好。🌵🌵🌵 如果我们不加Class token，直接将196x768维的tensor输入Encode中，我们的输出同样是196x768，即196个1x768维的向量，这时候我们应该拿哪个向量来当作最后的输出向量进而进行物体分类任务呢？这我们是很难确定的。所以我们干脆在输入Encode前就加上一个1x768维的向量（这个1维向量放在196x768维向量前面），这样在输出时向量的维度就会是197x768，然后我们只需要通过切片的方式获得第一个1x768维向量并将其送入分类头进行分类即可。在代码中这个Class token是一个可学习的向量，初始为全0的1x768维向量。🌱🌱🌱 Class token和x拼接后，输出尺寸变成了197x768，此时我们会加上一个位置编码向量position Embedding，其维度为197x768。关于这部分我在上一篇介绍Transformer中已经很详细的介绍过了，这里不再过多阐述原理。但我们可以看一下如果我们不使用位置编码，那么下面两幅图输出的结果将是一致的，这显然是有违我们直觉的。 接下来我们将经过位置编码的输入喂入encoder网络中，并重复L次encoder结构，encoder的结构如下： 经过L个encoder结构后，输入维度没有发生变换，仍为197x768维，此时我们会通过切片的方式提取出Class token的信息，其维度为1x768。接着会拿这个1x768维的Class token经过MLP Head层。MLP Head层的结构如下： 其中Pre-Logits这部分是可选的，其就是一个全连接层加上一个tanh激活函数，具体我们会在下一篇代码实战部分进行讲解。Linear就用于分类了，输出节点个数为我们任务的类别数。","categories":[{"name":"学习","slug":"学习","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Vision Transformer","slug":"Vision-Transformer","permalink":"https://dekelkai.github.io/tags/Vision-Transformer/"}],"author":"Dekel"},{"title":"Transformer","slug":"Transformer","date":"2025-01-27T14:11:34.000Z","updated":"2025-09-17T08:45:49.800Z","comments":true,"path":"2025/01/27/Transformer/","permalink":"https://dekelkai.github.io/2025/01/27/Transformer/","excerpt":"","text":"编码器层（Encoder Layer） 编码器层的输入首先进入自注意力子层（Self-Attention），该子层的作用在于帮助编码器关注句子中的其他词汇，以便更好地编码某个特定词汇。 随后，自注意力子层的输出将传递给一个前馈神经网络（Feed-Forward Neural Network）。结构完全相同的前馈网络被独立地应用于每个位置。 输入输出对理解数据流非常重要。编码器层的输入形状为 S x D（请参见下面的图表），其中 S 是源句子长度（例如，英语句子），而 D 是嵌入的维度（也是模型维度，论文中取值为 512）。 编码器的输入和输出形状相同。由于编码器层是相互叠加的，因此，我们希望其输出具有与输入相同的维度，以便它可以轻松地流入下一个编码器层。因此，输出也是 S x D 形状。 解码器层（Decoder Layer） 解码器层（decoder layer）也包含前面编码器中提到的两个层，不过区别在于这两个层之间还夹了一个注意力层（Encoder-Decoder Attention）。这个额外的注意力层的作用在于让解码器能够注意到输入句子中与解码任务相关的部分。 在一个已经训练好的Transformer模型中，输入是怎么变为输出的呢？首先我们要知道各种各样的张量（向量）是如何在这些组件之间变化的。 与其他的NLP项目一样，我们首先需要把输入的每个单词通过词嵌入（embedding）转化为对应的向量。 所有编码器层接收一组向量作为输入（论文中的输入向量的维度是512）。最底下的那个编码器层接收的是嵌入向量，之后的编码器层接收的是前一个编码器层的输出。 向量列表的长度这个超参数是我们可以设置的，一般来说是我们训练集中最长的那个句子的长度。 当我们的输入序列经过词嵌入之后得到的向量会依次通过编码器层中的两个层。 注意力机制（Attention） 注意力机制是论文的核心，它在编码器和解码器部分的处理稍有差异。让我们先以编码器部分的注意力层机制为例进行介绍。 上边提到，每个编码器层接受一组向量作为输入。在其内部，输入向量先通过一个自注意力层，再经过一个前馈神经网络层，最后将其将输出给下一个编码器层。 不同位置上的单词都要经过自注意力层的处理，之后都会经过一个完全相同的前馈神经网络。 在这里，我们开始看到 Transformer 的一个关键特点，即每个位置上的单词在编码器层中有各自的流通方向。 在自注意力层中，这些路径之间存在依赖关系。单词和单词之间会有关联，假设一个句子有 50 个单词，那么可以粗略想象成自注意力计算过程中，会构造一个 50 x 50 的关联矩阵。 前馈神经网络（Feed Forward）层中没有这些依赖关系。每个单词独立通过前馈神经网络，单词和单词之间没有关联，因此各种路径可以在流过前馈网络层的时候并行计算。 自注意力（Self-Attention） 现在让我们看一下自注意力机制。 假设我们要翻译下边这句话： ”The animal didn't cross the street because it was too tired” 这里it指的是什么？是street还是animal？人理解起来很容易，但是对算法来讲就不那么容易了。 当模型处理it这个词的时候，自注意力会让it和animal关联起来。 当模型编码每个位置上的单词的时候，自注意力的作用就是：看一看输入句子中其他位置的单词，试图寻找一种对当前单词更好的编码方式。 如果熟悉 RNNs 模型，回想一下 RNN 如何处理当前时间步的隐藏状态：将之前的隐藏状态与当前位置的输入结合起来。在 Transformer 中，自注意力机制也可以将其他相关单词的“理解”融入到我们当前处理的单词中。 当我们在最后一个encoder组建中对it进行编码的时候，注意力机制会更关注The animal，并将其融入到it的编码中。 自注意力的计算（单个） 先画图用向量解释一下自注意力是怎么算的，之后再看一下实际实现中是怎么用矩阵算的。 第一步 对于编码器的每个输入向量x，都会计算三个向量，即query、key和value向量。 这些向量的计算方法是将输入的词嵌入向量与三个权重矩阵相乘。这些权重矩阵是在模型训练阶段通过训练得到的。 什么是 “query”、“key”、“value” 向量？这三个向量是计算注意力时的抽象概念，请继续往下看注意力计算过程。 第二步 计算注意力得分。 假设我们现在在计算输入中第一个单词 Thinking 的自注意力。我们需要使用自注意力给输入句子中的每个单词打分，这个分数决定当我们编码某个位置的单词的时候，应该对其他位置上的单词给予多少关注度。 这个得分是query和key的点乘积得出来的。例如，如果我们处理位置#1的单词的自我注意，第一个分数将是q1和k1的点积。第二个分数是q1和k2的点积。（备注：在使用矩阵处理时，是用 Q 和 K 的转置相乘得到，详见后）。 第三步 将计算获得的注意力分数除以 8。 为什么选 8？是因为key向量的维度是 64，取其平方根，这样让梯度计算的时候更稳定。默认是这么设置的，当然也可以用其他值。 第四步 除 8 之后将结果扔进 softmax 计算，使结果归一化，softmax 之后注意力分数相加等于 1，并且都是正数。 这个 softmax 之后的注意力分数表示 在计算当前位置的时候，其他单词受到的关注度的大小。显然在当前位置的单词肯定有一个高分，但是有时候也会注意到与当前单词相关的其他词汇。 第五步 将每个 value 向量乘以注意力分数。这是为了强化我们想要关注的单词的 value，并尽量抑制其他不相关的单词（通过乘以一个接近于零的数，如 0.001）。这个过程被称为“缩放”或者“加权”，可以使得我们更加关注与目标单词相关的单词。 第六步 将上一步的结果相加，输出本位置的注意力结果。 这就是自注意力的计算。计算得到的向量直接传递给前馈神经网络。但是为了处理的更迅速，实际是用矩阵进行计算的。接下来我们看一下怎么用矩阵计算。 自注意力的计算（矩阵） 第一步是计算 Query、Key 和 Value 矩阵。我们通过将嵌入打包到矩阵 X 中，并将其乘以我们训练的权重矩阵、、来实现这一点。 ​ X矩阵中的每一行对应于输入句子中的一个单词。 ​可再次看到嵌入向量维度（512，图中的 4 个框）和 q/k/v 向量维度（64，图中的 3 个框）的差异 最后，由于我们使用矩阵计算，因此可以将步骤 2 到 6 合并为一个公式，以计算自注意力层的输出。 通过将输入向量 x 与注意力头的权重矩阵相乘，可以得到对应的 query、key 和 value 向量。单个头获取的这三个向量维度是64，比嵌入向量的维度小，8个头的输出连接后变为 512。因此嵌入向量、编码器层的输入输出维度都是512。 对于上图的解释： 假定输入的英文句子是“The quick brown fox“，句子长度 S 为4，参考“编码器层”章节的解释，注意力子层的输入形状为（4 x 512）。 自注意力层使用三个权重矩阵进行初始化——Query（Wq）、Key（Wk）和Value（Wv）。这些权重矩阵的尺寸都是 D x d，在论文中d取值为64，即权重矩阵的尺寸为 512 x 64。在训练模型时，我们将训练这些矩阵的权重。 在第一次计算（图中的Calc 1）中，我们通过将输入（注意：代码实现中是三个不同的输入，编码器层都是X，解码器层不同，见代码中的解释）与各自的Query、Key和Value权重矩阵相乘，计算出Q、K和V矩阵（尺寸为 S x d，示例中为 4 x 64）。 在第二次计算中，参考Attention计算公式，首先将Q和Kᵀ矩阵相乘，得到一个尺寸为 S x S（示例中为 4 x 4）的矩阵，然后将其除以√d的标量。然后对矩阵进行softmax运算，使得每一行的和都为1。这个矩阵可以理解为句子中每个词之间的关联度。 上面 S x S 的矩阵再和V矩阵相乘，得到尺寸为 S x d（示例中为 4 x 64）的矩阵。经过后续的连接操作后，传入下一层。 多头注意力 论文进一步改进了自注意力层，增加了一个机制，也就是多头注意力机制。这样做有两个好处： 第一个好处，它扩展了模型专注于不同位置的能力。 在上面例子里只计算一个自注意力的的例子中，编码“Thinking”的时候，虽然最后 Z1 或多或少包含了其他位置单词的信息，但是它实际编码中还是被“Thinking”单词本身所支配。 如果我们翻译一个句子，比如“The animal didn’t cross the street because it was too tired”，我们会想知道“it”指的是哪个词，这时模型的“多头”注意力机制会起到作用。 第二个好处，它给了注意层多个“表示子空间”。 就是在多头注意力中同时用多个不同的 WV*W**V* 权重矩阵（Transformer 使用8个头部，因此我们最终会得到8个计算结果)，每个权重都是随机初始化的。经过训练每个 WV*W**V* 都能将输入的矩阵投影到不同的表示子空间。 如果我们做和上面相同的自注意力计算，只不过八次使用不同的权重矩阵，我们最后得到八个不同的Z矩阵。 但是这会存在一点问题，多头注意力出来的结果会进入一个前馈神经网络，这个前馈神经网络可不能一下接收8个注意力矩阵，它的输入需要是单个矩阵（矩阵中每个行向量对应一个单词），所以我们需要一种方法把这8个压缩成一个矩阵。 怎么做呢？我们将这些矩阵连接起来，然后将乘以一个附加的权重矩阵 以上就是多头自注意力的全部内容。让我们把多头注意力上述内容 放到一张图里看一下子： 现在我们已经看过什么是多头注意力了，让我们回顾一下之前的一个例子，再看一下编码“it”的时候每个头的关注点都在哪里： 如果我们把所有的头的注意力都可视化一下，就是下图这样，但是看起来事情好像突然又复杂了。 编码器（Encoder） 使用位置编码表示序列的位置 到现在我们还没提到过如何表示输入序列中词汇的位置。 Transformer 在每个输入的嵌入向量中添加了位置向量。这些位置向量遵循某些特定的模式，这有助于模型确定每个单词的位置或不同单词之间的距离。将这些值添加到嵌入矩阵中，一旦它们被投射到Q、K、V中，就可以在计算点积注意力时提供有意义的距离信息。 位置编码向量和嵌入向量的维度是一样的，比如下边都是四个格子： 举个例子，当嵌入向量的长度为4的时候，位置编码长度也是4 一直说位置向量遵循某个模式，这个模式到底是什么。 参考论文：Convolutional Sequence to Sequence Learning 在下面的图中，每一行对应一个位置编码。所以第一行就是我们输入序列中第一个单词的位置编码，之后我们要把它加到词嵌入向量上。 看个可视化的图,这里表示的是一个句子有20个词，词嵌入向量的长度为512。可以看到图像从中间一分为二，因为左半部分是由正弦函数生成的。右半部分由余弦函数生成。然后将它们二者拼接起来，形成了每个位置的位置编码。： 但是需要注意注意一点，上图的可视化是官方Tensor2Tensor库中的实现方法，将sin和cos拼接起来。但是和论文原文写的不一样，论文原文的3.5节写了位置编码的公式，论文不是将两个函数concat起来，而是将sin和cos交替使用。论文中公式的写法可以看这个代码：transformer_positional_encoding_graph，其可视化结果如下： 全连接的前馈网络（Feed-Forward Networks） 除了注意力子层外，我们的编码器和解码器中的每一层都包含一个全连接的前馈网络，该网络被单独且相同地应用于每个位置。这包括两个线性变换，它们之间有ReLU激活函数。 虽然FFN的网络架构在各个位置上都是相同的，但它们在每个位置使用的是不同的权重参数。这可能就是论文作者为了强调这个，加上PositionWise的原因。 另一种描述方法是，这是两个具有1内核大小的卷积。输入和输出的维度是dmodel=512，而内部层的维度是 dff=2048。 子层之间的连接（残差和层归一化） 原始论文 在继续往下讲之前，我们还需再提一下编码器层中的一个细节：每个编码器层中的每个子层（自注意力层、前馈神经网络）都有一个残差连接（图中的Add），之后是做了一个层归一化（layer-normalization）（图中的Normalize）。 将过程中的向量相加和layer-norm可视化如下所示： 当然在解码器子层中也是这样的。 我们现在画一个有两个编码器和解码器的Transformer，那就是下图这样的： 解码器（Decoder） 现在我们已经介绍了编码器的大部分概念，因为Encoder的Decoder差不多，我们基本上也知道了解码器是如何工作的。那让我们直接看看二者是如何协同工作的。 解码器首先处理输入序列，将最后一个编码器层的输出转换为一组注意向量K和V。注意：参考实现中为直接用，见EncoderDecoder.forward，DecoderLayer.forward。 每个解码器层将在“encoder-decoder attention”层中使用编码器传过来的K和V，这有助于解码器将注意力集中在输入序列中的适当位置： 输出步骤会一直重复，直到遇到句子结束符 表明transformer的解码器已完成输出。 每一步的输出都会在下一个时间步喂给给底部解码器，解码器会像编码器一样运算并输出结果（每次往外蹦一个词）。 跟编码器一样，在解码器中我们也为其添加位置编码，以指示每个单词的位置。 解码器中的自注意力层和编码器中的不太一样： 在解码器中，自注意力层只允许关注已输出位置的信息。实现方法是在自注意力层的softmax之前进行mask，将未输出位置的信息设为极小值。 “encoder-decoder attention”层的工作原理和前边的多头自注意力差不多，但是Q、K、V的来源不用，Q是从下层创建的（比如解码器的输入和下层decoder组件的输出），但是其K和V是来自编码器最后一个组件的输出结果。 最后的线性层和softmax层 Decoder输出的是一个浮点型向量（512维），如何把它变成一个词？ 这就是最后一个线性层和softmax要做的事情。 线性层就是一个简单的全连接神经网络，它将解码器生成的向量映射到logits向量中。假设我们的模型词汇表是10000个英语单词，它们是从训练数据集中学习的。那logits向量维数也是10000，每一维对应一个单词的分数。 然后，softmax层将这些分数转化为概率（全部为正值，加起来等于1.0），选择其中概率最大的位置的词汇作为当前时间步的输出。","categories":[{"name":"学习","slug":"学习","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Transformer","slug":"学习/Transformer","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/Transformer/"}],"tags":[{"name":"学习","slug":"学习","permalink":"https://dekelkai.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"Transformer","slug":"Transformer","permalink":"https://dekelkai.github.io/tags/Transformer/"}],"author":"Dekel"},{"title":"爬虫-网页网易云音乐评论抓取","slug":"爬虫学习-网页网易云音乐评论抓取","date":"2025-01-14T16:10:19.000Z","updated":"2025-09-17T08:46:10.761Z","comments":true,"path":"2025/01/15/爬虫学习-网页网易云音乐评论抓取/","permalink":"https://dekelkai.github.io/2025/01/15/%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0-%E7%BD%91%E9%A1%B5%E7%BD%91%E6%98%93%E4%BA%91%E9%9F%B3%E4%B9%90%E8%AF%84%E8%AE%BA%E6%8A%93%E5%8F%96/","excerpt":"","text":"傍晚时分，坐在屋檐下，看着天慢慢地黑下去，心里寂寞而凄凉，感到自己的生命被剥夺了。当时我是个年轻人，但我害怕这样生活下去，衰老下去。在我看来，这是比死亡更可怕的事。 一、准备工作 1. 导入所需的库 1234567import jsonimport randomimport requests# 实现AES加密需要的三个模块from Crypto.Cipher import AES # AES加密from Crypto.Util.Padding import padfrom base64 import b64encode 2. 捕获评论数据包 网站的评论区数据是通过js动态加载的，在XHR中捕获所有数据包，找到评论区数据包。 3. 分析数据包 在标头可以看到是通过post请求发送的数据，载荷中的表单数据能看出params和encSecKey的值是被加密过的。使用正常方式带上者两个发送post请求是肯定得不到评论数据的，因此必须破解加密。 123456# 请求评论的url地址及发送的请求数据，空串为我们后面需要破解然后填入的位置url = \"https://music.163.com/weapi/comment/resource/comments/get?csrf_token=\"data = { 'params': ' ' 'encSecKey': ' ' } 二、逆向评论数据包 1.堆栈分析 在数据包中，数据的加密过程：明文-&gt;加密-&gt;密文，在上面看到的就是密文。于是我们在启动器中跟踪调用栈查找何时是明文何时被加密为密文 2. 首先在栈顶处的代码打上断点 3.观察网页 刷新网页并观察，发现歌词和评论都消失了，说明都是在这之后加载的，而我们的断点是下在一个函数里面的；可以判断该函数会被多次调用，因此我们要让网页继续运行直到是评论包调用了这个函数 4. 继续执行 执行两到三次后出现歌词 5. 继续执行到评论出现 说明在歌词出现后再次调用这个函数评论出现，因此我们要找的评论数据就在歌词出来后的这个断点里；刷新网页重新运行直到歌词出现前 可以看到一个params=XXXXX参数，结合前面载荷中的参数，判断出这很可能是加密后的内容，因此在调用堆栈中向下寻找，看看能不能找到加密前的内容 6. 堆栈向下查找并分析 到下面的地方时，参数进入了e0x中，可以看到还是加密的内容，继续寻找 到这里时看到data的内容发生了明显的变化，可以隐约看到一些信息；在上面t0x.be0x中是加密的状态，由此判定数据是在t0x.be0x中被加密 7. 找到加密函数 在本地堆栈信息中找到data所处的位置 发现里面的信息又来自bVi6c中，找到上面的bVi6c 1234567891011// 加密函数var bVi6c = window.asrsea(JSON.stringify(i0x), bse6Y([\"流泪\", \"强\"]), bse6Y(Qu1x.md), bse6Y([\"爱心\", \"女孩\", \"惊恐\", \"大笑\"]));/*构成：windows.asrsea() 自定义的加密函数JSON.stringify() 将字典转换为json字符串类型bse6Y([\"流泪\", \"强\"]) 自定义的函数对象 bse6Y(Qu1x.md) 自定义的函数对象 bse6Y([\"爱心\", \"女孩\", \"惊恐\", \"大笑\"]) 自定义的函数对象 */ 三、解析加密函数的参数 1. 后三个参数 可以看到在代码中是写死的 我们在控制台尝试执行这三个参数内容 可以看到生成了固定的字符串 123bse6Y([\"流泪\", \"强\"]='010001'bse6Y(Qu1x.md)='00e0b509f6259df8642dbc35662901477df22677ec152b5ff68ace615bb7b725152b3ab17a876aea8a5aa76d2e417629ec4ee341f56135fccf695280104e0312ecbda92557c93870114af6c9d05c4f7f0c3685b7a46bee255932575cce10b424d813cfe4875d3e82047b97ddef52741d546b8e289dc6935b3ece0462db0a22b8e'bse6Y([\"爱心\", \"女孩\", \"惊恐\", \"大笑\"])='0CoJUm6Qyw8W8jud' 2. 解析JSON.stringify中的i0x参数 在加密函数处打上断点，追踪i0x的值 在网络捕获数据包，直到评论区数据包出现 评论数据包出现说明数据已经加密过了，重新执行到评论区数据包出现的前一次执行 可以找到i0x的数据内容 12345678910i0x = { \"csrf_token\": \"c5ab7625a12cbf8010af4c1df61b0f6a\", \"cursor\": \"-1\", \"offset\": \"0\", \"orderType\": \"1\", \"pageNo\": \"1\", \"pageSize\": \"20\", \"rid\": \"R_SO_4_1392772737\", # 每首歌不同的歌曲id \"threadId\": \"R_SO_4_1392772737\", # 每首歌不同进程id } 四、解析加密函数 1var bVi6c = window.asrsea(JSON.stringify(i0x), bse6Y([\"流泪\", \"强\"]), bse6Y(Qu1x.md), bse6Y([\"爱心\", \"女孩\", \"惊恐\", \"大笑\"])); 1. 在代码中搜索加密函数，找到加密函数的位置 2. 分析加密函数 可以看到，d()函数就是加密的主体函数，它分别调用a()、b()、c()函数，最后返回h，而h中就含有encText和encSecKey 123456789101112131415161718# d需要转为json字符串# i0xd = { \"csrf_token\": \"c5ab7625a12cbf8010af4c1df61b0f6a\", \"cursor\": \"-1\", \"offset\": \"0\", \"orderType\": \"1\", \"pageNo\": \"1\", \"pageSize\": \"20\", \"rid\": \"R_SO_4_34723470\", # 不同歌曲id \"threadId\": \"R_SO_4_34723470\", # 不同歌曲id}# bse6Y([\"流泪\", \"强\"])e=\"010001\"# bse6Y(Qu1x.md)f=\"00e0b509f6259df8642dbc35662901477df22677ec152b5ff68ace615bb7b725152b3ab17a876aea8a5aa76d2e417629ec4ee341f56135fccf695280104e0312ecbda92557c93870114af6c9d05c4f7f0c3685b7a46bee255932575cce10b424d813cfe4875d3e82047b97ddef52741d546b8e289dc6935b3ece0462db0a22b8e7\"# bse6Y([\"爱心\", \"女孩\", \"惊恐\", \"大笑\"])g=\"0CoJUm6Qyw8W8jud\" 3. 逐个分析加密函数内的调用 a()函数:用于生成16位随机字符串 12345678# 网站为随机生成，后面我们设置成固定值def a(a): b = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\" c = \"\" for d in range(a): e = random.randint(0, len(b) - 1) c += b[e] return c b()函数:AES加密函数，对a进行加密，密钥为b，初始化向量为0102030405060708，，采用的是CBC模式；用python按照上面的样子直接构建一个相同的AES加密函数 12345678910111213141516# AES-CBC加密def encrypt_aes(text, key, iv): cipher = AES.new(key.encode('utf-8'), AES.MODE_CBC, iv.encode('utf-8')) # 设置密钥和初始化向量 padded_text = pad(text.encode('utf-8'), AES.block_size) # 设置加密文本 ciphertext = cipher.encrypt(padded_text) # 应用加密 return b64encode(ciphertext).decode('utf-8') # 返回字符串# 网站源码的function b(a,b)加密函数def b(a, b): c = b d = '0102030405060708' e = a f = encrypt_aes(e, c, d) return f c()函数:RSA加密，b、c分别最为公钥的指数部分和模数部分，中间的私钥为空。d为创建的密钥对对象，用来对i进行加密。 由于e，f的值都是固定的，c里的设置也是固定的，那么我们其实可以将i也设置为固定的值。 i是个16位随机数，它的作用就是为了让每次加密的结果不同，起混淆的作用，如果我们将它给固定住了也不会影响。 实际流程：c()函数对随机数i进行RSA加密，发送到服务器的时候先对i进行解析，然后得到随机数i作为解析encText的密钥，然后再解析出d也就是i0x中关于歌曲的信息。 1）在i处断点，追踪i的变化 2）刷新网页，执行脚本直到评论数据出现 3）重新刷新网页截到评论包前一个包后停止 4）单步跳过函数直到i变化 12# i的值i=\"P5rcbOIWOpY8YqGq\" 4）继续调试直到脚本运行到h后观察encSecKey的值 这样，我们就得到了当i=\"P5rcbOIWOpY8YqGq\"时，encSecKey的值 1&gt;encSecKey=\"7b3a12df898a7eaf2f0fc1adf83ddb305f0ee4563c0a7cbdad70ecf9c8118f76a211dba2218339cc28bb9647ea3f0f591dae07051b3956f2af8b15111532ccf94fcd3d106f19594e7bddec1002d695aaf00fdd886519e8df24bb044be1d5b868efc2feba0bc7bb19f1b456e5ee2a6098559c993fc3b45c3a022b660cdb065acf\" 4. 获得h.encText的值 可以看到进行了两次加密，我们用python模拟即可。需要将字典d转换为json，在python中使用json.dumps(i0x)即可。 123456789101112131415161718192021&gt;# AES-CBC加密&gt;def encrypt_aes(text, key, iv): cipher = AES.new(key.encode('utf-8'), AES.MODE_CBC, iv.encode('utf-8')) # 设置密钥和初始化向量 padded_text = pad(text.encode('utf-8'), AES.block_size) # 设置加密文本 ciphertext = cipher.encrypt(padded_text) # 应用加密 return b64encode(ciphertext).decode('utf-8') # 返回字符串&gt;# 网站源码的function b(a,b)加密函数&gt;def b(a, b): c = b d = '0102030405060708' e = a f = encrypt_aes(e, c, d) return f &gt;d_json = json.dumps(d)&gt;encText = b(d_json, g)&gt;encText = b(encText, i) 至此便解析了所有加密函数的内容，将获得的encText和encSecKey填入前面提到的params中和encSecKey中： 123456# 请求评论的url地址及发送的请求数据，空串为我们后面需要破解然后填入的位置url = \"https://music.163.com/weapi/comment/resource/comments/get?csrf_token=\"data = { 'params': encText 'encSecKey': encSecKey} 五、完整代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687import jsonimport randomimport requests# 实现AES加密需要的三个模块from Crypto.Cipher import AES # AES加密from Crypto.Util.Padding import padfrom base64 import b64encode# 网站为随机生成，这里设置成固定值def a(a): b = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\" c = \"\" for d in range(a): e = random.randint(0, len(b) - 1) c += b[e] return c# AES-CBC加密def encrypt_aes(text, key, iv): cipher = AES.new(key.encode('utf-8'), AES.MODE_CBC, iv.encode('utf-8')) # 设置密钥和初始化向量 padded_text = pad(text.encode('utf-8'), AES.block_size) # 设置加密文本 ciphertext = cipher.encrypt(padded_text) # 应用加密 return b64encode(ciphertext).decode('utf-8') # 返回字符串# 网站源码的function b(a,b)加密函数def b(a, b): c = b d = '0102030405060708' e = a f = encrypt_aes(e, c, d) return fif __name__ == '__main__': i = \"P5rcbOIWOpY8YqGq\" # d需要转为json字符串 # i0x d = { \"csrf_token\": \"c5ab7625a12cbf8010af4c1df61b0f6a\", \"cursor\": \"-1\", \"offset\": \"0\", \"orderType\": \"1\", \"pageNo\": \"1\", \"pageSize\": \"20\", \"rid\": \"R_SO_4_34723470\", # 不同歌曲编号 \"threadId\": \"R_SO_4_34723470\", # 不同歌曲编号 } # bse6Y([\"流泪\", \"强\"]) e = \"010001\" # bse6Y(Qu1x.md) f = \"00e0b509f6259df8642dbc35662901477df22677ec152b5ff68ace615bb7b725152b3ab17a876aea8a5aa76d2e417629ec4ee341f56135fccf695280104e0312ecbda92557c93870114af6c9d05c4f7f0c3685b7a46bee255932575cce10b424d813cfe4875d3e82047b97ddef52741d546b8e289dc6935b3ece0462db0a22b8e7\" # bse6Y([\"爱心\", \"女孩\", \"惊恐\", \"大笑\"]) g = \"0CoJUm6Qyw8W8jud\" d_json = json.dumps(d) encText = b(d_json, g) encText = b(encText, i) url = 'https://music.163.com/weapi/comment/resource/comments/get?csrf_token=' encSecKey = \"7b3a12df898a7eaf2f0fc1adf83ddb305f0ee4563c0a7cbdad70ecf9c8118f76a211dba2218339cc28bb9647ea3f0f591dae07051b3956f2af8b15111532ccf94fcd3d106f19594e7bddec1002d695aaf00fdd886519e8df24bb044be1d5b868efc2feba0bc7bb19f1b456e5ee2a6098559c993fc3b45c3a022b660cdb065acf\" header = { \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\" } data = { 'params': encText, 'encSecKey': encSecKey } # print(encText) # print(encSecKey) res = requests.post(url, headers=header, data=data) print(res.text) res_json = res.json() with open('东京不太热评论.json', 'w', encoding='utf-8') as f: json.dump(res.json(), f, ensure_ascii=False, indent=4) comments_list = res_json['data']['comments'] for comment in comments_list: print(comment['content']) 爬取成功 保存为json文件","categories":[{"name":"学习","slug":"学习","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"爬虫","slug":"学习/爬虫","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/%E7%88%AC%E8%99%AB/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://dekelkai.github.io/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://dekelkai.github.io/tags/%E7%88%AC%E8%99%AB/"}],"author":"Dekel"},{"title":"😄win11获取系统管理员权限方法😄","slug":"win11获取系统管理员权限方法","date":"2024-12-30T12:59:04.000Z","updated":"2025-09-17T08:46:49.002Z","comments":true,"path":"2024/12/30/win11获取系统管理员权限方法/","permalink":"https://dekelkai.github.io/2024/12/30/win11%E8%8E%B7%E5%8F%96%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%91%98%E6%9D%83%E9%99%90%E6%96%B9%E6%B3%95/","excerpt":"","text":"Win11获取系统管理员权限 1.win+R 打开运行，输入gpedit.msc然后回车。 2.如果显示没有gpedit.msc，以cmd后缀，管理员权限，运行下面代码脚本，然后执行第一步。 1234567891011@echo offpushd \"%~dp0\"dir /b C:\\Windows\\servicing\\Packages\\Microsoft-Windows-GroupPolicy-ClientExtensions-Package~3*.mum &gt;List.txtdir /b C:\\Windows\\servicing\\Packages\\Microsoft-Windows-GroupPolicy-ClientTools-Package~3*.mum &gt;&gt;List.txtfor /f %%i in ('findstr /i . List.txt 2^&gt;nul') do dism /online /norestart /add-package:\"C:\\Windows\\servicing\\Packages\\%%i\"pause 3.打开gpedit.msc，跳转到本地组策略编辑器。 在组策略编辑器中依次进入“计算机配置—&gt;Windows设置—&gt;安全设置—&gt;本地策略—&gt;安全选项”。 5.进入安全选项后双击右侧的“管理员账户状态”。 6.在管理员账户状态中，勾选“已启用”，再点击下方“确定”保存即可获得管理员权限。 (新增)7.在安全设置 的下面 ，展开 本地策略 --&gt; 安全选项 ，在右边找到 用户帐户控制：以管理员批准模式运行所有管理员 ，双击它，将 本地安全设置 更改为 已禁用 。 成功！","categories":[{"name":"Tips","slug":"Tips","permalink":"https://dekelkai.github.io/categories/Tips/"}],"tags":[{"name":"教程","slug":"教程","permalink":"https://dekelkai.github.io/tags/%E6%95%99%E7%A8%8B/"}],"author":"Dekel"},{"title":"印章识别系统","slug":"印章识别系统","date":"2024-12-28T12:43:53.000Z","updated":"2025-09-17T08:48:35.689Z","comments":true,"path":"2024/12/28/印章识别系统/","permalink":"https://dekelkai.github.io/2024/12/28/%E5%8D%B0%E7%AB%A0%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"印章识别系统demo demo做了一些实验，一些图片不能够识别出来文字，或者由于ORC的原因文字识别效果不好，但是圆形切割的效果还挺可以。 看了RCNN的原始论文。 用MaskRCNN的源码对已有的奖状手动打标训练40个了一下，效果不太好。 这个是用霍夫圆变换截取 用sqlite3实现了可以添加字段功能 下面这个是用MaskRCNN预测的，极少数能检测到，有些检测不出来 能打标的样本太少了，训练和测试效果完全不好 这是用maskRCNN预测的，训练了40个，但是后面又想到应该用下面这种打标","categories":[{"name":"目标检测","slug":"目标检测","permalink":"https://dekelkai.github.io/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"}],"tags":[],"author":"Dekel"},{"title":"各数据结构结构体定义","slug":"各数据结构结构体定义","date":"2024-12-04T14:16:11.000Z","updated":"2025-01-18T07:05:49.356Z","comments":true,"path":"2024/12/04/各数据结构结构体定义/","permalink":"https://dekelkai.github.io/2024/12/04/%E5%90%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%BB%93%E6%9E%84%E4%BD%93%E5%AE%9A%E4%B9%89/","excerpt":"","text":"线性表 123456789101112131415161718192021222324252627//静态顺序表int MaxSize = 10;typedef struct{ ElemType data[MaxSize]; int length; }SqList;//动态顺序表int InitSize;typedef struct{ ElemType* data; int MaxSize; int length; }SeqList;//单链表typedef struct LNode{ ElemType data; struct LNode *next;}LNode, *LinkList;//双向链表typedef struct DNode{ ElemType data; struct DNode *prior, *next;}DNode, *DLinkList; 栈 12345typedef struct { SElemType *base; SElemType *top; int stacksize;}SqStack; 队列 1234567891011#define MAXQSIZE 100typedef struct QNode{ QElemType data; struct QNode *next;}QNode, *QueuePtr;typedef struct{ QueuePtr front; Queueptr rear;}LinkQueue; 串 12345#define MAXLEN 255typedef struct{ char ch[MAXSIZE+1]; int length;}SString; 数组 1234typedef struct { int *data; int length;}Array; 树 1234typedef struct TNode{ int data; struct TNode *left, *right;}TNode; 二叉树 1234typedef struct BiTNode{ int data; struct BiTNode *lchide, *rchild;}BiTNode, *BiTree; 图（邻接表存储） 12345678910111213141516171819#define MaxVertexNum 100//边表结点typedef struct ArcNode{ int adjvex; //该边所指向的顶点 struct ArcNode *nextarc; //下一条边 // InfoType *info;}ArcNode;//定点表结点typedef struct VNode{ VertexType data; //顶点信息 ArcNode *firstarc; //指向第一条边表结点}VNode, AdjList[MaxVertexNum];typedef struct{ AdjList vertices; //邻接表头节点 int vexnum,arcnum;}ALGraph; 图（邻接矩阵）MGraph 12345678910111213141516#define INFINITY INT_MAX#define MAX_VERTEX_NUM 20typedef enum {DG, DN, UDG, UDN} GraphKind; //{有向图,有向网,无向图,无向网}typedef struct ArcCell{ VRType adj; //无权图0，1；带权图 权值 InfoType *info;}ArcCell, AdjMatrix[MAX_VERTEX_NUM][MAX_VERTEX_NUM];typedef struct{ VertexType vex[MAX_VERTEX_NUM]; //顶点集合 AdjMatrix arcs; //邻接矩阵 int vexnum,arcnum; // 图的定点数和边数 GraphKind kind; //图的类型}MGraph;","categories":[],"tags":[],"author":"Dekel"},{"title":"Hexo博客备份和恢复","slug":"Hexo博客备份和恢复","date":"2024-07-23T07:25:31.000Z","updated":"2025-01-18T07:05:49.354Z","comments":true,"path":"2024/07/23/Hexo博客备份和恢复/","permalink":"https://dekelkai.github.io/2024/07/23/Hexo%E5%8D%9A%E5%AE%A2%E5%A4%87%E4%BB%BD%E5%92%8C%E6%81%A2%E5%A4%8D/","excerpt":"","text":"一、备份博客 必须要备份的文件： scaffolds 文章模板，需要备份 source 文章和页面等文件，需要备份 themes 若有主题，需要备份，我是用npm安装的volantis主题，所以这里没有备份themes，而是将node_models里的主题文件备份 _config.yml 用户配置信息文件，需要备份 _config.volantis.config 主题配置信息文件，做了修改并放在了根目录，需要备份 package.json 模块列表，需要备份 package-lock.json 锁定安装时的包的版本号 不必备份的文件和目录： node_modules 安装的模块 public 产生的静态网页文件 db.json 网页文件静态数据，编译时自动生成 备份到GitHub 1、在github或gitee创建一个仓库Hexo存放备份信息 2、在博客根目录下创建文件.gitignore，添加以下内容，表示不备份的文件信息 12345678.DS_StoreThumbs.dbdb.json*.logthemes/node_modules/public/.deploy*/ 3、备份到github上的仓库Hexo 12345git initgit add *git commit -m \"$(date): Hexo backup\"git remote add origin https://github.com/username/Hexo.gitgit push -u origin main 注：若提示error: remote origin already exists.，就先执行git remote rm origin后在执行上述代码。 二、恢复博客 安装对应环境 1、git、nodejs等，可在hexo主题官网查看安装方法和版本信息。 2、pandoc（支持LateX渲染，参考\"使Hexo博客页面能够渲染LaTeX\"） 配置git与github 1、打开gitbash，输入以下命令 12git config --global user.name \"XXXX\" 用户名标识 ---- 实际也可以填写您的github仓库的名称git config --global user.email \"xxxx@xxx.com\" 邮箱标识 -------可以填写github仓库的邮箱 注：git config --global “参数\"，有了这个参数，表示你这台机器上所有的Git仓库都会使用这个配置，当然你也可以对某个仓库指定的不同的用户名和邮箱。 2、创建SSH Key 1ssh-keygen -t rsa //--创建秘钥 在c盘用户目录下找到.ssh，里面有2个文件一个是公钥 一个是私钥，用记事本打开公钥复制里面的内容到github进行配置。 3、测试链接 1ssh -T git@github.com 出现hello表示成功 克隆到本地 创建一个文件存放博客，在文件中使用以下命令克隆文件 1git clone https://github.com/Dekelkai/Hexo.git 恢复博客 123npm install hexo-clinpm installnpm install hexo-deployer-git 注：由于volantis模块改了静态页面的代码，所以要将新加载的主题模块替换为备份的volantis主题模块。 重新启动博客三连 1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d","categories":[],"tags":[{"name":"Blog","slug":"Blog","permalink":"https://dekelkai.github.io/tags/Blog/"}],"author":"Dekel"},{"title":"大数据系统实验课程","slug":"大数据系统实验课程","date":"2024-06-24T02:13:28.000Z","updated":"2025-01-18T07:05:49.356Z","comments":true,"path":"2024/06/24/大数据系统实验课程/","permalink":"https://dekelkai.github.io/2024/06/24/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F%E5%AE%9E%E9%AA%8C%E8%AF%BE%E7%A8%8B/","excerpt":"","text":"一、实验准备 1、导入虚拟机及开启大数据平台 使用提供的ovf导入虚拟机镜像，用mobaXterm连接虚拟机，打开镜像中的大数据平台文件（hadoop-docker-centos7），在docker-compose.yml中添加端口映射“5000:5000”： 执行./start-hadoop-images.sh启动大数据平台，主机名称变更为hbase-master。执行yarn node –list查看其他三个节点（hbase-slave1、hbase-slave2、 hbase-slave3）： 在容器hbase-master中执行jps发现无HMaster进行，然后再执行start-hbase.sh，有则不执行启动hbase的脚本： 退出大数据平台：退出大数据平台主节点，容器hbase-master中执行exit。 关闭大数据平台：关闭大数据平台，虚拟机操作系统中执行./stop-hadoop-images.sh。 关闭虚拟机，虚拟机操作系统中执行shutdown -h now 2、环境检测 大数据平台目前包括的组件有：HDFS、MapRedcue、Yarn、Spark、Scala、HBase、Hive、Zookeeper、Sqoop、 Phoenix、 Python3、 Azkaban、 Kafka、 Sbt、JDK；用于存储元数据数据库为mysql，root账户密码为hadoop。 其中软件版本为：Hadoop: 2.7.2、Spark: 2.1.0、Scala: 2.11.8、HBase: 1.2.5、JDK: openjdk 1.8.0_111、Hive: 2.1.1、Zookeeper: 3.4.10、Sqoop: 1.4.7、Phoenix: 4.14.1-HBase-1.2、Python3: 3.6.0、Azkaban: 3.24.0、Sbt: 1.4.6、Kafka: 2.11-0.10.2.1、MySQL: 5.7。 HDFS 进入大数据平台后再命令行输入jps，出现NameNode和SecondaryNameNode进程。 使用命令hdfs dfsadmin -report查看各个节点的当前状态。 MapReduce 使用一个wordcount程序来进行单词计数，判断MapReduce运行是否正常。 进入/code/tests/mapreduce-test/，创建一个words.txt，输入一些单词： 使用hdfs dfs -put words.txt /tmp/上传至hdfs： 使用hadoop jar wordcount.jar /tmp/words.txt /tmp/wordcount执行程序： 结果被保存在hdfs中，使用hdfs dfs -cat /tmp/wordcount/*查询结果： yarn hive 注意：在执行 hive中表和表之间数据导入导出时，需要调用 MapReduce者 Spark，如果直接退出hive，有可能是设置spark计算引擎问题，请设置计算引擎为 MapReduce：set hive.execution.engine=mr。 Hbase 使用hbase shell： spark 使用spark-shell： zookeeper 查看docker中的所有容器： 进入zoo1节点,命令docker-compose exec zoo1 bash： 查看Zookeeper服务状态，命令zkServer.sh status： ​ 节点是follower角色，正常启动。 启动Zookeeper客户端，命令zkCli.sh： 查询hbase在zookeeper服务中注册的RegionServer服务器信息，命令ls2 /hbase/rs： sbt打包 使用sbt对编译好的scala程序进行打包，直接使用镜像中配置好的sbt进行打包，命令/usr/local/sbt/sbt package： 查看生成的目标文件，在target/scala-&lt;version&gt;中： 使用spark提交jar包，命令spark-submit --class \"SimpleApp\" /root/sparkapp/target/scala-2.11/simple-project_2.11-1.0.jar： Azkaban 启动 进程中没有AzkabanSingleServer，先启动azkaban. 进入/root/azkaban-solo-server/，执行bin/azkaban-solo-start.sh: 在windows中访问azkaban图形化界面，虚拟机ip:8081，用户配置文件在conf/azkaban-users.xml： kafka 启动kafka，创建一个主题test，查看主题信息，利用kafka提供的命令行工具kafka-console-producer.sh，给kafka集群发送消息，利用kafka-console-consumer.sh接收消息。 kafka启动命令位置 启动kafka服务，命令bin/kafka-server-start.sh config/server.properties: hbase-master的kafka进程： 四个节点的kafka的config/server.properties和/tmp/kafka-logs/meta.properties配置文件id： 启动各节点的kafka服务： 创建test主题，命令bin/kafka-topics.sh --zookeeper zoo1:2181 --create --replication-factor 4 --partitions 1 --topic testTxk： 当前实验在4个节点上都打开了，因此factor 数量为 4。 测试发送消息，命令bin/kafka-console-producer.sh --broker-list hbase-master:9092 --topic testTxk： 测试接收消息，命令bin/kafka-console-consumer.sh --bootsrap-server hbase-master:9092 --topic testTxk --from-beginning: Phoenix 集成 HBase 先启动Master，命令start-hbase.sh sqlline.py位置： 到目录下执行sqlline.py： 执行!tables： 3、总结 主要进行了虚拟机的导入安装，对后续需要使用到的工具进行了简单配置，检测和熟悉，为后续实验奠定了基础。 二、大数据批处理系统 0、前言 淘宝双11大数据批处理分析系统，对数据进行分析与预测，涉及数据预处理、存储、查询和可视化分析等数据处理流程及操作，包含Linux、Mysql、Hadoop、Hive、Sqoop、ECharts、Spark等软件的安装和使用方法。 1、数据准备 数据通过MobaXterm上传到原虚拟机 上传到hbase-master中，命令docker cp /tmp/dataset/user_log.csv hbase-master:/home/dbtaobao/dataset；查看前十条数据head -10 user_log.csv： 2、数据预处理 第一行都是字段名称，在导入Hive时不需要，将其删除： 数据集过大，取前20000条数据作为小数据集smalluserlog.csv。建立一个脚本完成截取任务： 导入Hive数据仓库，先在hdfs中创建一个存放数据的dataset文件夹，然后把small_user_log.csv数据上传hdfs。 3、启动并配置MySQL 进入mysql镜像节点测试： 修改mysql配置文件： 先停止docker容器./stop-hadoop-image，然后启动./start-hadoop-image，进入mysqldocker-compose exec mysql bash，重启mysql服务service mysql restart，自动退出mysql，重启mysql容器docker restart mysql。 4、Hive的简单使用 内部表：也叫管理表表⽬录会创建在集群上的{hive.metastore.warehouse.dir}下的相应的库对应的⽬录中。默认创建的表就是内部表。 外部表：外部表需要使⽤关键字\"external\"，外部表会根据创建表时LOCATION指定的路径来创建⽬录， 如果没有指定LOCATION，则位置跟内部表相同,⼀般使⽤的是第三⽅提供的或者公⽤的数据。建表语法（必须指定关键字external） create external table tableName(id int,name string) [location 'path']; 建立dbtaobao数据库： 创建外部表user_log，查询结果： 操作hive 执行如下命令： 结果如下： 利用Hive进行数据分析与处理 简单查询分析： ​ 查询条数统计分析： ​ 不重复数据查询： 5、Hive的数据处理和分析 男女买家交易对比 男女买家各个年龄段交易对比： 获取销量前五的商品类别： 各个省份的的总成交量对比： 6、从hive导入数据到mysql 在mysql中创建5个新表，设置编码为utf-8： 123456789101112131415CREATE TABLE `dbtaobao`.`result1` (`action` varchar(6),`num` varchar(20)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `dbtaobao`.`result2` (`gender` varchar(6),`num` varchar(20)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `dbtaobao`.`result3` (`gender` varchar(6),`age_range` varchar(20),`num` varchar(20)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `dbtaobao`.`result4` (`cat_id` varchar(20),`num` varchar(20)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `dbtaobao`.`result5` (`province` varchar(10),`num` varchar(20)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 进入master节点中使用sqoop将hive中相关数据导入mysql，5条语句分别对应5个表格： 12345678910sqoop export --connect jdbc:mysql://mysql:3306/dbtaobao --username root --password hadoop --table result1 --export-dir '/user/hive/warehouse/dbtaobao.db/result1' --fields-terminated-by ','sqoop export --connect jdbc:mysql://mysql:3306/dbtaobao --username root --password hadoop --table result2 --export-dir '/user/hive/warehouse/dbtaobao.db/result2' --fields-terminated-by ','sqoop export --connect jdbc:mysql://mysql:3306/dbtaobao --username root --password hadoop --table result3 --export-dir '/user/hive/warehouse/dbtaobao.db/result3' --fields-terminated-by ','sqoop export --connect jdbc:mysql://mysql:3306/dbtaobao --username root --password hadoop --table result4 --export-dir '/user/hive/warehouse/dbtaobao.db/result4' --fields-terminated-by ','sqoop export --connect jdbc:mysql://mysql:3306/dbtaobao --username root --password hadoop --table result5 --export-dir '/user/hive/warehouse/dbtaobao.db/result5' --fields-terminated-by ', 7、idea+Tomcat+ECharts展示数据 创建webapp项目然后导入mysql依赖 配置tomcat服务 修改mysql的IP地址，添加相应的jsp，js和css代码 运行效果展示 8、总结 主要是在mysql配置utf8时遇到容器崩溃，mysql节点被破环进入不了，最后将docker全部格式化，重新处理数据和配置其他环境。 hive中，在需要调用MapReduce或spark的任务中，需要设置引擎：set hive.execution.engine=mr； 三、大数据查询分析计算系统 0、前言 NBA 统计大数据查询分析计算系统，涉及虚拟机镜像的导入、linux 系统的使用、hbase 的使用、phoenix 的使用，以及 python 调用 hbase 的 api、scala 调用 spark 的 api，搭建 flask 程序。 1、HBase创建表 进入 hbabse shell 执行create 'team_season','cf1'创建表，设置表名和列族名： 2、编写python脚本批量导入数据至hbase中 退出hbase后，新建文件夹/home/NBA/，在里面新建python文件tohbase.py： 将数据集team_season.csv数据上传到虚拟机中： 传输命令： 数据展示： 执行 hbase-daemon.sh start thrift 让程序能够连接到 hbase，并检查9090端口是否可用： 安装 happybase和pandas： 123456# 由于要用到 happybase，pandas 包。需要安装# 需要安装 happybasepip3 install happybase# 安装 pandaspip3 install pandas 执行之前编写的 python 脚本文件,导入数据，python3 tohbase.py 执行.py 文件： 进入 hbase shell，用 scan 扫描表显示： 3、phoenix 建立与 hbase 相映射的表 执行 sqlline.py 启动 phoenix，使用!tables命令查看表： 在phoenix中创建映射的表，再用!tables查看表： 然后就可以使用sql语句进行，Phoenix 是一个 SQL 层，用于与 HBase 进行交互，提供了 JDBC 驱动程序和兼容 ANSI SQL 的查询接口。它使得开发者可以用熟悉的 SQL 语言来查询 HBase 中的数据： 4、搭建Flask 安装virtualenv，创建一个独立的python环境myapp： 1pip3 install virtualenv 进入虚拟环境，安装flask： 123cd myapp/binsource activatepip install flask 测试flask： 在 myapp 虚拟环境下安装 phoenixdb 1pip install phoenixdb==0.7 启动queryserver服务 在虚拟环境myapp中测试phoenixdb 连接是否正常 1234567import phoenixdbimport phoenixdb.cursordatabase_url = 'http://localhost:8765/'conn = phoenixdb.connect(database_url, autocommit=True)cursor = conn.cursor() cursor.execute('SELECT * FROM \"team_season\" limit 10')print (cursor.fetchall()) 5、编写程序分析和展示数据 使用flask框架展示数据： 创建一个python文件main.py： 在同级目录下创建 templates 文件夹，编写存放 myindex.html： 运行结果： 6、总结 flask版本问题、安装virtualenv超时，HMaster进程 四、 大数据流计算系统 0、前言 涉及数据预处理、消息队列发送和接收消息、数据实时处理、数据实时推送和实时展示等数据 处理全流程所涉及的各种典型操作， 涵盖 Linux 、Spark 、Kafka 、Flask 、Flask-SocketIO 、Highcharts.js、sockert.io.js、PyCharm 等系统和软件的安装和使用方法。 1、数据处理 数据预处理 上传数据到虚拟机中： 安装相应的python库： 编写kafka代码测试生产者和消费者： 测试结果： 2、scala编程实现实时数据处理 下载spark-streaming-kafka的jar包，并配置环境jar的位置： 1wget http://search.maven.org/maven2/org/apache/spark/spark-streaming-kafka-0-8_2.11/2.1.0/spark-streaming-kafka-0-8_2.11-2.1.0.jar 在文件夹 kafka_spark_code中建立文件夹 kafka,进入 kafka 文件夹依次建立 src/main/scala 文件存放目录以及 scala 工程文件，项目工程主文件 KafkaTest.scala，设置日志文件为 StreamingExamples.scala： StreamingExamples.scala代码： KafkaWordCount.scala程序代码 编写打包配置文件simple.sbt： 3、运行kafka项目 编译打包程序： 1/usr/local/sbt/sbt package 编写运行脚本，编写运行脚本，在/usr/local/spark/mycode/kafka 目录下新建 startup.sh 文件，输入以下内容，是一行，并给予脚本执行权限： 1/root/spark/bin/spark-submit --driver-class-path /root/spark/jars/*:/root/spark/jars/kafka/* --class \"org.apache.spark.examples.streaming.KafkaWordCount\" /home/charpter03/kafka_spark_code/kafka/target/scala-2.11/simple-project_2.11-1.0.jar zoo1:2181 1 sex 1 修改获得运行权限： 测试程序 修改consumer.py文件的主题： 启动kafka服务，然后分别运行startup.sh、producer.py、consumer.py文件，查看结果： 4、数据展示处理 利用 Flask 创建 web 程序，利用 Flask-SocketIO 实现实时推送数据，利用 socket.io.js 实现 实时接收数据，hightlights.js 展现数据。 1234环境版本：pip3 install Flask-SocketIO==4.3.1pip3 install python-engineio==3.13.2pip3 install python-socketio==4.6.0 Flask-SocketIO实时推送数据 Spark Streaming 实时接收 Kafka 中 topic 为“sex”发送的日志数据，然后 Spark Streaming 进行实时处理，统计好每秒中男女生购物人数之后，将结果发送至 Kafka，topic 为“result”。下面是项目文件层级： app.py：作为一个简易的服务器，处理连接请求，以 及处理从kafka 接收的数据，并实时推送到浏览器。 background_thread 函数，该函数从 Kafka 接收消息，并进行处理，获得男女生每秒钟人数，然后将结果通过函数 socketio.emit实时推送至浏览器。 浏览器获取数据并展示 在app.py路径下创建templates/index.html，其负责获取数据并展示效果。 该部分就是使用 socket.io.js 库来实时地接收服务端发送过来的消息，并将消息数据实时地设置在 html 标签内，交给 highcharts.js 进行实时获取和展示。如果出现引擎版本不匹配的错误，可以固定下 python 几个包的版本： pip3 install Flask-SocketIO==4.3.1 pip3 install python-engineio==3.13.2 pip3 install python-socketio==4.6.0 js依赖： 123456&gt;&lt;script crossorigin=\"anonymous\" integrity=\"sha512-TFZqlmDYmi29UdRJTJblfxNrsSgtabj2vxvIqAvsAO2I8//OaBTMfxa8ghzuHQ58hViU5k125Cp00vh9GVgWIg==\" src=\"https://lib.baomitu.com/socket.io/2.5.0/socket.io.min.js\"&gt;&lt;/script&gt;&gt;&lt;script src=\"https://cdn.bootcdn.net/ajax/libs/jquery/3.5.1/jquery.js\"&gt;&lt;/script&gt;&gt;&lt;script src=\"https://code.highcharts.com/highcharts.src.js\"&gt;&lt;/script&gt;&gt;&lt;script src=\"http://code.highcharts.com/modules/exporting.js\"&gt;&lt;/script&gt; 代码如下 效果展示 启动步骤: 确保 kafka 开启（jps 观察进程是否启动）； 开启 producer.py 模拟数据流（python3 producer.py）; 启动 Spark Streaming 实时处理数据（scala 版运行 stratup.sh）。 启动 app.py 5、总结 1、主题列表： 2、整个数据的传输过程： 3、socket.io.js，exporting.js版本问题包 4、并发问题 五、大数据图计算系统 0、前言 用 GraphX 分析网络结构，涉及获取数据、解析数据、分析主要主题以及伴生关系、建立伴生网络、理解网络结构、过滤噪声边、计算聚类系数和平均路径长度等数据处理过程，涵盖 Linux、MySQL、Hadoop、HDFS、Spark、Scala、Flask、Python、Echarts 等系统和软件的应用。 1、获取实验数据 注：原始数据量较多，但由于本实验镜像虚拟的分布式集群内存只有 7.5G,启动Hadoop 平台就要占用大量内存资源，该实验最后一部分计算节点之间的平均路径需要消耗非常多的内存资源，不足以计算出结果，考虑到单机现有的内存条件，所以本实验采取相对合适节点数量的数据集，数据量为 480，足以完成整个实验流程及学习内容的要求。 1、先将数据通过MobaXterm上传到虚拟机中，然后通过命令docker cp /tmp/dataset/chapter04/. hbase-master:/home/chapter04/dataset/上传到hbase-master节点上： 2、创建数据库 graph，为后面可视化展示做准备： 3、查看 namenode，datanode 是否正常启动，HRegionServer 跟 hbase 相关，没有的话直接启动： 4、在hdfs创建medline文件夹，并将medsamp2016a.xml加载到该文件夹下： 123hdfs dfs -mkdir /medlinehdfs dfs -put medsamp2016a.xml /medline/hdfs dfs -put ch07-graph-2.0.0-jar-with-dependencies.jar /medline/ 5、spark-shell --jars ch07-graph-2.0.0-jar-with-dependencies.jar启动spark： 6、把 xml 格式的 medline 数据读到 Spark shell 中： 7、用 Scala XML 工具解析 XML 文档，变量elem 是scala.xml.Elem 类的实例，Scala 用scala.xml.Elem 类表示XML 文档中的一个节点，该类内置了查询节点信息和节点内容的函数。Cache函将解析结果缓存起来： 2、分析网络主要主题及其伴生关系 FlatMap 获取数据集标签后，我们需要知道数据集中标签的总体分布情况，为此我们需要使用 SparkSQL 计算一些基本统计量，比如记录条数和主要主题出现频率的直方图，并将统计结果保存到 mysql，用于可视化展示： 记录下登录时的 ip： 上面的数据给出了一个大致的描述，包括一共有多少个主题，最频繁的主题等。可以看到，我们的数据一共有 480 个文档，最频繁出现的 topic（Disease）只占了很少一部分（25/480= 5%）。对此，我们猜测包含某个主题的文档的个数的总体分布可能为长尾形态： 要得到伴生关系，我们要为这些字符串列表生成一个二元组集合。对此我们可以使用 Scala 集合工具包里的 combinations 方法，它返回的是一个 Iterator： 查看一下数据中最常出现的伴生二元组，将数据存入 mysql： 以上并未提供特别有用的信息，最常见的伴生二元组与最常见的topic非常相关。除此之外，也没有提供什么额外的信息。 3、用 GraphX 来建立一个伴生网络 实验的核心在于把伴生网络当作网络来分析：把主题当作图的顶点，把连接两个主题的引用记录看成两个相应顶点之间的边。这样就可以计算以网络为中心的统计量。GraphX 构建与 Spark 之上，它继承了 Spark 在可扩展性方面的所有特性，这就意味着可以利用 GraphX 对规模极其庞大的图进行分析。 在Medline数据上运行该散列函数可以得到一个DataFrame，以它为基础就可以得到伴生关系图的顶点集合： 用前一节中得到的伴生频率计数来生成图的边，方法是使用hash 函数将每个主题映射到相应的顶点ID： 把顶点和边都创建好后，就可以创建Graph 实例了。我们需要将Graph 缓存起来，这样便于后续处理时使用： 4、理解网络结构 1、连通组件 最基本的属性之一就是是否是连通图。如果图是非连通的，那么可以将图划分成一组更小的子图，这样就可以分别对每个子图进行研究。连通性是图的基本属性，通过调用 GraphX 的 connectedComponents 方法获取： 大连通组件的主题名称： 查看最初的主题分布，是否有类似 Visual 的主题： 2、度的分布 为了更多了解图的结构信息，我们需要知道每个顶点的度，也就是每个顶点所属边的条数。GraphX 中我们可以通过在 Graph 对象上调用 degrees 方法得到每个顶点的度。degrees 方法返回一个整数的 VertexRDD，其中每个整数代表一个顶点的度。现在我们计算一下图的度，然后可以查看到度数较高的主题，并将数据存入 mysql： 5、过滤噪声边 在当前的伴生关系中，边的权重是基于一对概念同时出现在一篇论文中的频率来计算的。这种简单的权重机制的问题在于：它并没有对一对概念同时出现的原因加以区分，有时一对概念同时出现是由于它们具有某种值得我们关注的语义关系，但有时一对概念同时出现只是因为都频繁地出现在所有文档中，同时出现只是碰巧而已，因此需要对噪声边进行处理，这里采用卡方准则。 1、处理 EdgeTriplet 计算卡方统计量，需要组合顶点数据（比如每个概念在一个文档中出现的次数）和边数据（比如两个概念同时出现在一个文档中的次数）： 用该方法通过 mapTriplets 算子转换边的值。mapTriplets 算子返回一个新图，这个图的边的属性就是每个伴生对的卡方统计量。于是我们就可以大概知道该统计量在所有边上的分布情况： 使用 19.5 作为阈值，这样过滤后图中就只剩下那些置信度非常高的有意义的伴生关系。我们将在图上利用 subgraph 方法进行过滤，这个方法接受 EdgeTriplet 的一个布尔函数，用以判断子图应该包含哪些边： 2、分析去掉噪声边的子图 在过滤后的子图上运行连通性算法，检查组件个数和组件大小： 发现连通组件总数发生改变，且最大连通组件也被瓦解，说明该数据集有较多的噪声干扰。如果数据量较多，将会对最大连通组件产生较小的影响。检查一下过滤后的度分布： 看到过滤后平均值变小了，主要主题也产生变化，原因是数据集样本的噪声比较多。我们看一下过滤之后概念和度的关系： 结果表明虽说这次卡方过滤准则不太理想，问题在于使用数据集样本太小，如果用原始数据集，将会产生较好的结果；但是它在清楚对应普遍概念的边的同时，保留了代表概念之间有意义并且有值得注意的关系的那些边。 6、系和聚类系数 如果每个顶点都存在一条边与其他任何节点都相连，那这个图就是个完全图。给定一个图，可能有多个子图是完全图，我们可以将这些子图称为系，如果途中存在这种许多大型的系，表示这个图具有某种局部稠密结构。 三角形是一个完成图，顶点 V 的三角计数就是包含该顶点的三角形个数。三角计数度量了 V 有多少个邻接点是相互连接的。Watts 和 Strogatz 定义了一个新的指标，称为局部聚类系数，它是一个顶点的实际三角计数与其邻接点可能的三角级数的比率。对无向图来说，有 k 个邻接点和 t 个三角计数的顶点，其局部聚类系数 C 为： 用GraphX 来计算过滤后的概念图的每个节点的局部聚类系数。GraphX 有个内置方法triangleCount，它返回一个Graph 对象，其中VertexRDD 包含了每个顶点的三角计数。然后对所有顶点局部聚类系数取平均值，就得到网络平均聚类系数： 7、平均路径长度 用Pregel求两个节点之间的最短路径，这里我们会计算过滤之后的概念图中的大型连通组件节点的平均路径长度。计算图中顶点之间的路径长度是一个迭代过程，和我们之前寻找连通组件的迭代过程类似：每个阶段，每个顶点将保留它所接触过的顶点列表并记录到这些顶点的距离。接着每个顶点都向其邻接点查询它对应的节点列表，如果发现该列表中有新的顶点，就用新节点更新自己的节点列表；查询邻接点并更新自己节点列表的过程一直继续下去，直到所有节点都没有发现有新节点需要添加为止。 确定了顶点状态和消息内容的数据结构后，我们可以实现两个函数。第一个函数是 mergeMaps，用于将新消息中的信息合并到顶点状态之中。对我们讨论的问题来说，顶点状态和消息都是 Map[VertexId, Int] 类型的，因此需要把两个 map 中的内容合并在一起并将每个 VertexId 关联到两个 map 中该 VertexId 对应两个条目的最小值。 最后编写代码来构建发送给每个顶点的消息，依据是每次迭代是每个顶点从邻接点收到的消息： 在每个Pregel迭代过程中，对EdgeTriplet内部的src和dst顶点执行消息更新： 如果一次迭代中有任何顶点没收到消息，pregel’算法认为该顶点的运算已经完成并不再把它放在后续处理中。计算任意两个顶点之间的路径长度，使用 RDD 的sample 方法对所有 Vertexid 进行 2%的不重复采样，随机数生成器的随机种子采用 1729L： 计算样本路径长度直方图： 看到，样本的平均路径长度为 15.7，聚类系数为 0.625。 8、Echarts可视化展示 1、登录MySQL，查看mysql中是否有相关数据库和表： 2、数据可视化展示 结果展示： 使用flask框架搭建前端展示页面，文件目录结构： app.py： mysql.py： echarts.html代码： 9、总结","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://dekelkai.github.io/categories/bigdata/"}],"tags":[{"name":"bigdata","slug":"bigdata","permalink":"https://dekelkai.github.io/tags/bigdata/"}],"author":"Dekel"},{"title":"🙃Volantis主题配置评论区遇到的问题🙃","slug":"Volantis主题配置评论区遇到的问题","date":"2024-05-06T03:44:23.000Z","updated":"2025-01-18T07:05:49.355Z","comments":true,"path":"2024/05/06/Volantis主题配置评论区遇到的问题/","permalink":"https://dekelkai.github.io/2024/05/06/Volantis%E4%B8%BB%E9%A2%98%E9%85%8D%E7%BD%AE%E8%AF%84%E8%AE%BA%E5%8C%BA%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"In The Front 更换评论系统功能遇到问题了...先是看了网上对giscus的描述：借用GitHub来搭建评论区（免费啊hhh）。也是图方便，就照着网上各种教程在Volantis各个位置加东西。结果发现如果要评论还必须登录GitHub才行，虽然也能用，但是就感觉不舒服，后面发现了别家不用强制登陆的评论系统Twikoo。在我配置好twikoo后 问题就接踵而至了.... 官网提供的配置信息： 刷新页面出现了两个评论区（我写这篇博客的时候已经修好了。。。） 页面一直转圈圈加载中（，我也不需要请求他的服务了。。。） 1 检查Volantis配置文件 第一反应就是检查了Volantis的配置文件_config.volantis.yml中的Comments块，已经将服务调整为了twikoo。（甚至将下面giscus的配置信息部分全部注释了。。。） 并没有效果。 2 使用查找命令 使用命令findstr /s /i \"giscus\" *.*查找整个目录出现giscus的地方（可以看到这里已经被我注释掉了hhh）. 每个提交到github上的页面都有giscus.app/clint.js，我们在前端控制台看一下. 3 检查模板配置文件 在hexo-theme-volantis\\layout中发现post.ejs，page.ejs等文件，里面都引用了_partial/article. 打开该文件，发现又引用了../_plugins/comments/index.（到这里我感觉就很接近答案了hhh） 打开该index.ejs，找到了这串配置文件，把他注释掉即可. 弯路😅 在配置giscus时候官网也没有给出应该放到哪个位置，就在网上到处找，各个地方乱放。然而就是没仔细看_config.volantis.yml中的配置和giscus官网给的是对应的。","categories":[{"name":"博客搭建","slug":"博客搭建","permalink":"https://dekelkai.github.io/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"Twikoo","slug":"Twikoo","permalink":"https://dekelkai.github.io/tags/Twikoo/"},{"name":"评论功能","slug":"评论功能","permalink":"https://dekelkai.github.io/tags/%E8%AF%84%E8%AE%BA%E5%8A%9F%E8%83%BD/"},{"name":"Giscus","slug":"Giscus","permalink":"https://dekelkai.github.io/tags/Giscus/"}],"author":"Dekel"},{"title":"🐼Blog搭建-评论功能(使用MongoDB+netlify部署twikoo)🐼","slug":"Blog搭建-评论功能-使用MongoDB-netlify部署twikoo","date":"2024-04-30T12:20:13.000Z","updated":"2025-01-18T07:05:49.354Z","comments":true,"path":"2024/04/30/Blog搭建-评论功能-使用MongoDB-netlify部署twikoo/","permalink":"https://dekelkai.github.io/2024/04/30/Blog%E6%90%AD%E5%BB%BA-%E8%AF%84%E8%AE%BA%E5%8A%9F%E8%83%BD-%E4%BD%BF%E7%94%A8MongoDB-netlify%E9%83%A8%E7%BD%B2twikoo/","excerpt":"","text":"教育不是灌输，而是点燃火焰-----苏格拉底 In The Front 这里的博客是指的静态博客（Hexo、Hugo等） Netlify 免费等级（Functions Level 0）支持每月 125,000 请求次数和 100 小时函数计算时长 主要配置：MongoDB（数据库），Netlify （Deploy平台），博客网页（客户端/前端）。数据库负责储存数据，deploy平台来执行代码、将其变为app，最后连接到博客，从而在网页显示出来。所以必须按顺序操作，每一步都需要前一步得到的信息从而连接到一起。 1 为什么使用Twikoo？ 开源，免费，轻量无广告（吊打Disqus等一众评论服务） 匿名性好，不需要强制社交账号登录（重要‼️） 有新评论时可收到邮箱/即时消息通知 游客若留下邮箱，评论被回复时可收到邮件提醒（cusdis不支持） 数据支持导入导出 twikoo官网 2 MongoDB配置 申请MongoDB账号，然后登陆. 创建免费 MongoDB 数据库，区域推荐选择 AWS / N. Virginia (us-east-1). 在 Database Access 页面点击 Add New Database User 创建数据库用户，Authentication Method 选 Password，在 Password Authentication 下设置数据库用户名和密码，用户名和密码可包含数字和大小写字母，请勿包含特殊符号。点击 Database User Privileges 下方的 Add Built In Role，Select Role 选择 Atlas Admin，最后点击 Add User. 在 Network Access 页面点击 Add IP Address，Access List Entry 输入 0.0.0.0/0（允许所有 IP 地址的连接），点击 Confirm. 在 Database 页面点击 Connect，连接方式选择 Drivers，并记录数据库连接字符串，请将连接字符串中的 &lt;username&gt;:&lt;password&gt; 修改为刚刚创建的数据库 用户名:密码. 3 Netlify配置 创建netlify账号并申请一个Team. 打开twikoo项目： twikoojs/twikoo-netlify，点击 fork 将仓库 fork 到自己的账号下. 回到 Netlify，点击 Add new site - Import an existing project. 点击 Deploy with GitHub，如果未授权 GitHub 账号，先授权，然后选择前面 fork 的 twikoo-netlify 项目. 点击 Add environment variables - New variable，Key 输入 MONGODB_URI，Value 输入前面记录的数据库连接字符串，点击 Deploy twikoo-netlify，等待项目部署. 部署完成后，点击 Domain settings 可以看到云函数。 浏览器访问云函数链接，出现以下界面. 云函数地址（包含 https:// 前缀和 /.netlify/functions/twikoo 后缀，例如 https://xxx.netlify.app/.netlify/functions/twikoo）即为您的环境 id. 4 修改博客配置文件 打开Volantis主题的配置文件_config.volantis.yml，找到Comments模块. 修改service为twikoo. 找到下方twikoo部分，将刚才的云函数地址填写在envId处. 配置完成，hexo clean &amp;&amp; hexo g &amp;&amp; hexo s看看效果😄! Twikoo还拥有评论管理系统，在评论框的右下角齿轮，后面再探索吧。。。 参考文章 twikoo文档:云函数部署","categories":[{"name":"博客搭建","slug":"博客搭建","permalink":"https://dekelkai.github.io/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"Twikoo","slug":"Twikoo","permalink":"https://dekelkai.github.io/tags/Twikoo/"},{"name":"评论功能","slug":"评论功能","permalink":"https://dekelkai.github.io/tags/%E8%AF%84%E8%AE%BA%E5%8A%9F%E8%83%BD/"}],"author":"Dekel"},{"title":"➕使Hexo博客页面能够渲染LaTeX➕","slug":"使Hexo渲染LaTeX","date":"2024-04-30T11:43:03.000Z","updated":"2025-09-30T11:08:17.028Z","comments":true,"path":"2024/04/30/使Hexo渲染LaTeX/","permalink":"https://dekelkai.github.io/2024/04/30/%E4%BD%BFHexo%E6%B8%B2%E6%9F%93LaTeX/","excerpt":"","text":"一元二次方程：的两根为： 前言 Hexo没有自带LaTeX渲染，我们通过更换markdown渲染器使其能够渲染LaTeX。 注：需要本地安装好Pandoc。 卸载Marked渲染器 1npm un hexo-renderer-marked 安装 Pandoc 和 MathJax 12npm i hexo-renderer-pandocnpm i hexo-filter-mathjax 配置 Pandoc 和 MathJax 打开根目录下 _config.yml，添加如下配置： 1234567891011121314151617181920212223pandoc: extra: - no-highlight: extensions: - +abbreviations - +autolink_bare_uris - +emoji - +hard_line_breaks - -implicit_figures - +mark - +short_subsuperscriptsmathjax: tags: none # or 'ams' or 'all' single_dollars: true # enable single dollar signs as in-line math delimiters cjk_width: 0.9 # relative CJK char width normal_width: 0.6 # relative normal (monospace) width append_css: true # add CSS to pages rendered by MathJax every_page: true # if true, every page will be rendered by MathJax regardless the `mathjax` setting in Front-matter extension_options: {} # you can put your extension options here # see http://docs.mathjax.org/en/latest/options/input/tex.html#tex-extension-options for more detail ​ 配置好后就可以正常使用Latex了。 参考文章 Hexo 博客使用 LaTeX 使用 pandoc 正确渲染多行 MathJax 公式","categories":[{"name":"博客搭建","slug":"博客搭建","permalink":"https://dekelkai.github.io/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"LaTeX","slug":"LaTeX","permalink":"https://dekelkai.github.io/tags/LaTeX/"},{"name":"功能","slug":"功能","permalink":"https://dekelkai.github.io/tags/%E5%8A%9F%E8%83%BD/"}],"author":"Dekel"},{"title":"✔️LaTeX公式✔️","slug":"LaTeX公式","date":"2024-04-29T14:00:04.000Z","updated":"2025-01-18T07:05:49.354Z","comments":true,"path":"2024/04/29/LaTeX公式/","permalink":"https://dekelkai.github.io/2024/04/29/LaTeX%E5%85%AC%E5%BC%8F/","excerpt":"","text":"希腊字母表 绝对值符号 12% 使用\\lvert 和 \\rvert\\lvert C_{2} \\rvert 大小于符号 12345&gt;：\\textgreater&lt;： \\textless下面的后面要加空格，否则会识别错误&gt;=：\\geq 或 \\ge&lt;=：\\leq 或 \\le 属于符号 12属于：\\in不属于：\\notin 换行符 12...Typora中好像只有 \"\\\\\" 和 \"\\newline\" 这是第一行文本\\\\ 这是第二行文本，通过双反斜杠换行，但没有缩进。\\newline www 这是第一行文本这是第二行文本，通过双反斜杠换行，但没有缩进。 只是用换行符渲染到网页没有生效，使用\\begin{array}{}和\\end{array}嵌套可以让其生效。（字体会变小...参考下一条来进行调整） 字体大小 1234567891011121314151. 使用{\\huge [内容]}2. 使用 begin 和 end 如: \\begin{small} This part should be smaller then the rest of the document. \\end{small}3. 直接使用，在直接使用时，只能后面的文字有效。如 text1 \\huge text2，只对 text2 及其后面的内容有效.常用的命令： \\tiny：这是最小的字体大小，通常不建议在正文中使用。 \\scriptsize：比\\tiny稍大一些的字体大小。 \\footnotesize：这是默认的字体大小，适合大多数正文内容。 \\small：比默认字体小一些的字体大小。 \\normalsize：正常的字体大小，也是LaTeX的默认设置。 \\large：比正常字体大一些的字体大小。 \\Large：更大的字体大小，通常用于标题或重要信息。 \\LARGE：比\\Large更大的字体大小。 \\huge和\\Huge：这是最大的字体大小，非常适合用于强调或标题。","categories":[{"name":"学习","slug":"学习","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"LaTeX","slug":"LaTeX","permalink":"https://dekelkai.github.io/tags/LaTeX/"}],"author":"Dekel"},{"title":"🏳️‍🌈Volantis主题字体修改🏳️‍🌈","slug":"volantis主题字体修改","date":"2024-04-26T04:46:10.000Z","updated":"2025-01-18T07:05:49.355Z","comments":true,"path":"2024/04/26/volantis主题字体修改/","permalink":"https://dekelkai.github.io/2024/04/26/volantis%E4%B8%BB%E9%A2%98%E5%AD%97%E4%BD%93%E4%BF%AE%E6%94%B9/","excerpt":"","text":"只有流过血的手指，才能弹出世间的绝唱。-----泰戈尔 写在前面 volantis主题自带的字体看得疲倦了，记录下如何更改字体 ·本文以修改logo字体为例，以下是修改之前的字体。 0 找到配置文件_config.volantis.yml中字体配置的位置。 可以看到logo对应的字体配置为logofont，主要更改fontfamily、name和url字段。 fontfamily：定义了一组字体集合，按照从左到右的顺序尝试应用这些字体。如果无法加载第一 个会尝试后面的字体。 name:字体的名称，与 fontfamily 中的第一个字体对应。 url:字体文件的URL路径。这里使用GitHub+jsDelivr来创建字体链接。 1 字体下载 在网上下载自己心仪的字体文件，这里的格式为.ttf（不知道其他格式是否可以用）。 GitHub上找的一个英文字体：Pacifico。 2 上传GitHub仓库 将下载好的.ttf文件上传到自己的GitHub仓库中。 3 配置_config.volantis.yml文件 在配置文件中修改上文提到的3个属性。 注意url格式：https://cdn.jsdelivr.net/gh/github用户名/仓库名@分支名/字体路径。 4 成品展示 修改成了我们想要的字体。 参考资料 自定义字体“EB Garamond”配置不生效 Volantis文档 主题配置","categories":[{"name":"小技巧","slug":"小技巧","permalink":"https://dekelkai.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"字体","slug":"字体","permalink":"https://dekelkai.github.io/tags/%E5%AD%97%E4%BD%93/"},{"name":"主题","slug":"主题","permalink":"https://dekelkai.github.io/tags/%E4%B8%BB%E9%A2%98/"}],"author":"Dekel"},{"title":"🥸使用PicGo+Typora+Github+jsDelivr搭建图床，提高写作效率🥸","slug":"使用PicGo-Typora-Github-jsDelivr搭建图床-提高写作效率","date":"2024-04-25T12:42:06.000Z","updated":"2025-01-18T07:05:49.355Z","comments":true,"path":"2024/04/25/使用PicGo-Typora-Github-jsDelivr搭建图床-提高写作效率/","permalink":"https://dekelkai.github.io/2024/04/25/%E4%BD%BF%E7%94%A8PicGo-Typora-Github-jsDelivr%E6%90%AD%E5%BB%BA%E5%9B%BE%E5%BA%8A-%E6%8F%90%E9%AB%98%E5%86%99%E4%BD%9C%E6%95%88%E7%8E%87/","excerpt":"","text":"0 写在前面 当前大部分博客都采用Markdown来书写，写文章的时候又会引入一些图片，如果直接将图片复制粘贴进Typora的话只能保存在本地目录中，在其他地方打开文件无法看到里面的图片。Typora通过集成第三方工具，完成了自动上传图片至图床的功能，极大提升了写作效率。 什么是图床？ =&gt; 互联网中存储图片的空间,可以上传个人图片，并直接进行分享。 1 PicGo介绍 项目地址 一款能够在本地上传图片，能够自动转换成链接的工具，目前支持以下图床： 七牛图床 v1.0 腾讯云 COS v4\\v5 版本 v1.1 &amp; v1.5.0 又拍云 v1.2.0 GitHub v1.5.0 SM.MS V2 v2.3.0-beta.0 阿里云 OSS v1.6.0 Imgur v1.6.0 2 GitHub设置 2.1 创建仓库 设置你的仓库名称，都可以，然后选择Public，点击Create repository 。 2.2 获取token 进入右上角个人setting（不是仓库的setting）,左栏进入最下方的Developer settings，进入如图所界面，找到tokens(classic)，创建新token，记住这个token。 3 PicGo 配置 在前文介绍项目链接中下载PicGo，安装好后打开在主页面找到github配置。 如果下载缓慢，可以使用镜像网站：山东大学镜像站 将前面创建好的token填入，仓库名称、分支、存储路径如下图所示： 4 jsDelivr介绍 A free CDN for open source projects--用于开源项目的免费 CDN 刚好解决github图片访问过慢的问题，使用十分简单。 项目地址：https://www.jsdelivr.com/? 在这里我们用自己的github信息按照如下格式填入PicGo中即可： https://cdn.jsdelivr.net/gh/用户名/仓库名@分支名称 其他域名配置方式： 1234567891011121314151617181920212223// 加载任何Github发布、提交或分支https://cdn.jsdelivr.net/gh/user/repo@version/file// 加载 jQuery v3.6.4https://cdn.jsdelivr.net/gh/jquery/jquery@3.6.4/dist/jquery.min.js// 使用版本范围而不是特定版本https://cdn.jsdelivr.net/gh/jquery/jquery@3.6/dist/jquery.min.jshttps://cdn.jsdelivr.net/gh/jquery/jquery@3/dist/jquery.min.js// 完全省略版本或分支以获得最新版本 ，不应该在生产中使用它https://cdn.jsdelivr.net/gh/jquery/jquery/dist/jquery.min.js// 将“.min”添加到任何JS/CSS文件中以获取缩小版本，如果不存在，将为会自动生成https://cdn.jsdelivr.net/gh/jquery/jquery@3.6.4/src/core.min.js// 在末尾添加\"/\"以获取资源目录列表https://cdn.jsdelivr.net/gh/jquery/jquery/ 5 配置Typora 打开Typora左上角文件，进入偏好设置，左栏选择图像按照如下。 上传测试 在Typora中直接粘贴一张本地照片，上传成功，进入PicGo主页面相册查看到照片，在github仓库中 也找到照片。 参考资料 体验PicGo+GitHub搭建图床，使用jsDelivr或Github raw免费加速 PicGo + Gitee 配置图床","categories":[{"name":"博客搭建","slug":"博客搭建","permalink":"https://dekelkai.github.io/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"教程","slug":"教程","permalink":"https://dekelkai.github.io/tags/%E6%95%99%E7%A8%8B/"},{"name":"工具","slug":"工具","permalink":"https://dekelkai.github.io/tags/%E5%B7%A5%E5%85%B7/"},{"name":"Typora","slug":"Typora","permalink":"https://dekelkai.github.io/tags/Typora/"},{"name":"PicGo","slug":"PicGo","permalink":"https://dekelkai.github.io/tags/PicGo/"}]}],"categories":[{"name":"mars","slug":"mars","permalink":"https://dekelkai.github.io/categories/mars/"},{"name":"学习","slug":"学习","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"前端","slug":"学习/前端","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/%E5%89%8D%E7%AB%AF/"},{"name":"论文","slug":"论文","permalink":"https://dekelkai.github.io/categories/%E8%AE%BA%E6%96%87/"},{"name":"reinforce learning","slug":"reinforce-learning","permalink":"https://dekelkai.github.io/categories/reinforce-learning/"},{"name":"RL","slug":"RL","permalink":"https://dekelkai.github.io/categories/RL/"},{"name":"实时追踪","slug":"实时追踪","permalink":"https://dekelkai.github.io/categories/%E5%AE%9E%E6%97%B6%E8%BF%BD%E8%B8%AA/"},{"name":"Tips","slug":"Tips","permalink":"https://dekelkai.github.io/categories/Tips/"},{"name":"机器学习","slug":"Tips/机器学习","permalink":"https://dekelkai.github.io/categories/Tips/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"Transformer","slug":"学习/Transformer","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/Transformer/"},{"name":"爬虫","slug":"学习/爬虫","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/%E7%88%AC%E8%99%AB/"},{"name":"目标检测","slug":"目标检测","permalink":"https://dekelkai.github.io/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"},{"name":"bigdata","slug":"bigdata","permalink":"https://dekelkai.github.io/categories/bigdata/"},{"name":"博客搭建","slug":"博客搭建","permalink":"https://dekelkai.github.io/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"},{"name":"小技巧","slug":"小技巧","permalink":"https://dekelkai.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"Mars","slug":"Mars","permalink":"https://dekelkai.github.io/tags/Mars/"},{"name":"CV","slug":"CV","permalink":"https://dekelkai.github.io/tags/CV/"},{"name":"算法","slug":"算法","permalink":"https://dekelkai.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"React","slug":"React","permalink":"https://dekelkai.github.io/tags/React/"},{"name":"学习","slug":"学习","permalink":"https://dekelkai.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"目标跟踪","slug":"目标跟踪","permalink":"https://dekelkai.github.io/tags/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/"},{"name":"无人机","slug":"无人机","permalink":"https://dekelkai.github.io/tags/%E6%97%A0%E4%BA%BA%E6%9C%BA/"},{"name":"YOLO","slug":"YOLO","permalink":"https://dekelkai.github.io/tags/YOLO/"},{"name":"RL","slug":"RL","permalink":"https://dekelkai.github.io/tags/RL/"},{"name":"reinforce learning","slug":"reinforce-learning","permalink":"https://dekelkai.github.io/tags/reinforce-learning/"},{"name":"大学","slug":"大学","permalink":"https://dekelkai.github.io/tags/%E5%A4%A7%E5%AD%A6/"},{"name":"Vision Transformer","slug":"Vision-Transformer","permalink":"https://dekelkai.github.io/tags/Vision-Transformer/"},{"name":"Transformer","slug":"Transformer","permalink":"https://dekelkai.github.io/tags/Transformer/"},{"name":"Python","slug":"Python","permalink":"https://dekelkai.github.io/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://dekelkai.github.io/tags/%E7%88%AC%E8%99%AB/"},{"name":"教程","slug":"教程","permalink":"https://dekelkai.github.io/tags/%E6%95%99%E7%A8%8B/"},{"name":"Blog","slug":"Blog","permalink":"https://dekelkai.github.io/tags/Blog/"},{"name":"bigdata","slug":"bigdata","permalink":"https://dekelkai.github.io/tags/bigdata/"},{"name":"Twikoo","slug":"Twikoo","permalink":"https://dekelkai.github.io/tags/Twikoo/"},{"name":"评论功能","slug":"评论功能","permalink":"https://dekelkai.github.io/tags/%E8%AF%84%E8%AE%BA%E5%8A%9F%E8%83%BD/"},{"name":"Giscus","slug":"Giscus","permalink":"https://dekelkai.github.io/tags/Giscus/"},{"name":"LaTeX","slug":"LaTeX","permalink":"https://dekelkai.github.io/tags/LaTeX/"},{"name":"功能","slug":"功能","permalink":"https://dekelkai.github.io/tags/%E5%8A%9F%E8%83%BD/"},{"name":"字体","slug":"字体","permalink":"https://dekelkai.github.io/tags/%E5%AD%97%E4%BD%93/"},{"name":"主题","slug":"主题","permalink":"https://dekelkai.github.io/tags/%E4%B8%BB%E9%A2%98/"},{"name":"工具","slug":"工具","permalink":"https://dekelkai.github.io/tags/%E5%B7%A5%E5%85%B7/"},{"name":"Typora","slug":"Typora","permalink":"https://dekelkai.github.io/tags/Typora/"},{"name":"PicGo","slug":"PicGo","permalink":"https://dekelkai.github.io/tags/PicGo/"}]}