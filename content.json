{"meta":{"title":"Dekel'Blog","subtitle":"用脚步丈量世界，用心感受多元文化","description":"一个关于如何在快节奏的现代生活中，通过微小的改变和持续的自我探索，实现内心平静与个人成长的空间。","author":"Dekel","url":"https://Dekelkai.github.io","root":"/"},"pages":[{"title":"友链","date":"2025-09-30T11:23:30.000Z","updated":"2025-10-02T06:32:30.950Z","comments":true,"path":"link/index.html","permalink":"https://dekelkai.github.io/link/index.html","excerpt":"","text":""},{"title":"about","date":"2025-10-02T06:11:59.000Z","updated":"2025-10-02T06:13:58.077Z","comments":true,"path":"about/index.html","permalink":"https://dekelkai.github.io/about/index.html","excerpt":"","text":""},{"title":"说说","date":"2025-10-01T09:19:33.000Z","updated":"2025-10-02T06:20:57.283Z","comments":true,"path":"shuoshuo/index.html","permalink":"https://dekelkai.github.io/shuoshuo/index.html","excerpt":"","text":""},{"title":"tags","date":"2025-09-30T11:14:37.000Z","updated":"2025-09-30T11:22:57.751Z","comments":true,"path":"tags/index.html","permalink":"https://dekelkai.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"前端框架的路由组件（router）的作用","slug":"前端框架的路由组件（router）的作用","date":"2025-09-30T09:47:57.000Z","updated":"2025-10-02T08:50:46.687Z","comments":true,"path":"2025/09/30/前端框架的路由组件（router）的作用/","permalink":"https://dekelkai.github.io/2025/09/30/%E5%89%8D%E7%AB%AF%E6%A1%86%E6%9E%B6%E7%9A%84%E8%B7%AF%E7%94%B1%E7%BB%84%E4%BB%B6%EF%BC%88router%EF%BC%89%E7%9A%84%E4%BD%9C%E7%94%A8/","excerpt":"","text":"这段代码是一个典型的基于 Backbone.js 框架的前端路由（Routing）示例。它定义了应用程序如何根据浏览器地址栏中的 URL 片段（Hash） 来执行不同的功能，而无需重新加载整个页面。 123456789101112131415161718192021222324252627282930313233343536373839404142434445// backbone.js代码：(function() {window.App = { Models: {}, Collections: {}, Views: {}, Router: {}};App.Router = Backbone.Router.extend({ routes: { '': 'index', 'show/:id': 'show', 'download/*random': 'download', 'search/:query': 'search', '*other': 'default' }, index: function() { $(document.body).append(\"调用了 Index 路由&lt;br&gt;\"); }, show: function(id) { $(document.body).append(\"调用了 Show 路由，id 等于 \" + id + \"&lt;br&gt;\"); }, download: function(random) { $(document.body).append(\"调用了 Download 路由，参数等于 \" + random + \"&lt;br&gt;\"); }, search: function(query) { $(document.body).append(\"调用了 Search 路由，参数等于 \" + query + \"&lt;br&gt;\"); }, default: function(other) { $(document.body).append(\"你访问的 \" + other + \" 路由未定义&lt;br&gt;\"); }});new App.Router();Backbone.history.start();})(); 1️⃣ 自执行函数包装 (function() { ... })(); 123(function() { // 代码块})(); 这是一个自执行匿名函数，避免全局变量污染。 所有变量都在这个函数作用域里，不会直接挂在 window 上（除了明确放进去的，如 App）。 2️⃣ 创建全局 App 命名空间 123456window.App = { Models: {}, Collections: {}, Views: {}, Router: {}}; Backbone 的经典做法：把模型、集合、视图和路由器都集中在一个对象下。 避免全局污染，同时清晰组织代码结构。 3️⃣ 定义路由器 App.Router 12345678910App.Router = Backbone.Router.extend({ routes: { '': 'index', 'show/:id': 'show', 'download/*random': 'download', 'search/:query': 'search', '*other': 'default' }, ...}); 路由定义规则： '' → 空路径时调用 index 方法（首页）。 show/:id → URL 形如 #show/123 时，id 是 123。 download/*random → * 捕获剩余路径，例如 #download/path/to/file，random = path/to/file。 search/:query → 例如 #search/abc，query = abc。 *other → 捕获所有未定义路由，作为“404”处理。 4️⃣ 路由对应的函数 123456789101112131415index: function() { $(document.body).append(\"调用了 Index 路由&lt;br&gt;\");},show: function(id) { $(document.body).append(\"调用了 Show 路由，id 等于 \" + id + \"&lt;br&gt;\");},download: function(random) { $(document.body).append(\"调用了 Download 路由，参数等于 \" + random + \"&lt;br&gt;\");},search: function(query) { $(document.body).append(\"调用了 Search 路由，参数等于 \" + query + \"&lt;br&gt;\");},default: function(other) { $(document.body).append(\"你访问的 \" + other + \" 路由未定义&lt;br&gt;\");} 这些方法会在 URL 哈希改变时被调用。 比如你访问 http://localhost/#show/5： 路由器匹配 show/:id 调用 show(5) 方法 页面会追加 \"调用了 Show 路由，id 等于 5&lt;br&gt;\" 5️⃣ 启动路由 12new App.Router();Backbone.history.start(); new App.Router() → 创建路由器实例。 Backbone.history.start() → 启动 Backbone 的哈希监听： 监听 URL 哈希变化（#xxx） URL 变化时调用对应路由函数 支持浏览器前进后退 6️⃣ 整体流程 页面加载 → 创建路由器。 用户访问 URL（如 #search/hello）或点击链接。 Backbone 解析哈希 → 找到匹配路由。 调用对应方法 → 页面上追加提示。 💡 补充说明 :param 是单个占位符，*param 可以匹配路径中的 /。 这是一个前端单页面路由（SPA），不刷新页面。 $(document.body).append(...) 是为了演示，实际项目通常用视图更新 DOM。","categories":[{"name":"学习","slug":"学习","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"前端","slug":"学习/前端","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"React","slug":"React","permalink":"https://dekelkai.github.io/tags/React/"}],"author":"Tang Xiangkai"},{"title":"论文-Strong Baseline: Multi-UAV Tracking via YOLOv12 with BoT-SORT-ReID","slug":"论文-Strong-Baseline-Multi-UAV-Tracking-via-YOLOv12-with-BoT-SORT-ReID","date":"2025-09-17T08:51:13.000Z","updated":"2025-09-17T10:27:39.811Z","comments":true,"path":"2025/09/17/论文-Strong-Baseline-Multi-UAV-Tracking-via-YOLOv12-with-BoT-SORT-ReID/","permalink":"https://dekelkai.github.io/2025/09/17/%E8%AE%BA%E6%96%87-Strong-Baseline-Multi-UAV-Tracking-via-YOLOv12-with-BoT-SORT-ReID/","excerpt":"","text":"提出的方法以及数据集的缺陷 基于热红外视频的多无人机跟踪任务 该论文方法与 YOLOv5[18]和 DeepSORT[40]管道进行对比。使用了YOLOv12探测器和BoT-SORT-ReID pipline。此外还采用了一些方法提高了多无人机的跟踪性能。 图 (a)显示了来自 MOT 训练集的不同背景的热红外帧，而图 1 (b)突出了一些小缺陷，如注释错误、冗余、缺失标签和低质量帧，这些缺陷在数据集中占的比例可以忽略不计，在训练过程中可以安全地忽略。(反无人机比赛数据集) 普遍采用的提升方法 现有改进主要集中在 时间建模、实时优化、统一框架、检测后处理 上述四个方面，而作者的工作在此基础上结合最先进的检测器与跟踪器，在热红外多无人机跟踪上创造了新 benchmark，并指引后续研究。 详细方法 1、问题陈述 尽可能准确地跟踪无人机，评价指标： 提供初始位置的MOT任务。 2、数据 track3 YOLOv12 + BoT-SORT YOLOv12 简单在线实时多目标跟踪技巧优化 BoT-SORT：卡尔曼滤波+运动相机补偿 稳定动态条件下的跟踪 https://github.com/NirAharon/BoT-SORT","categories":[{"name":"论文","slug":"论文","permalink":"https://dekelkai.github.io/categories/%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"学习","slug":"学习","permalink":"https://dekelkai.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"目标跟踪","slug":"目标跟踪","permalink":"https://dekelkai.github.io/tags/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/"},{"name":"无人机","slug":"无人机","permalink":"https://dekelkai.github.io/tags/%E6%97%A0%E4%BA%BA%E6%9C%BA/"},{"name":"YOLO","slug":"YOLO","permalink":"https://dekelkai.github.io/tags/YOLO/"}],"author":"Tang Xiangkai"},{"title":"强化学习（三.1）贝尔曼最优策略和公式推导","slug":"强化学习（三-1）贝尔曼最优策略和公式推导","date":"2025-09-10T14:55:37.000Z","updated":"2025-09-10T15:14:32.589Z","comments":true,"path":"2025/09/10/强化学习（三-1）贝尔曼最优策略和公式推导/","permalink":"https://dekelkai.github.io/2025/09/10/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%89-1%EF%BC%89%E8%B4%9D%E5%B0%94%E6%9B%BC%E6%9C%80%E4%BC%98%E7%AD%96%E7%95%A5%E5%92%8C%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/","excerpt":"","text":"强化学习中的策略优化推导 在强化学习（Reinforcement Learning, RL）中，状态值函数的定义经常涉及一个关于策略 的最优化问题。本文将结合数学推导，解释如何从 Bellman 方程推导出最优策略的形式，并说明为什么最优策略是 贪心策略（greedy policy）。 1. 从 Bellman 方程出发 我们考虑状态值函数（假设已知一个固定的下一步值函数 ）： 其中： ：策略，在状态 下选择动作 的概率； ：奖励的条件分布； ：环境转移概率。 约束条件是： 2. 引入动作值函数 将括号内的部分记作动作值函数 ： 于是值函数可以写成更简洁的形式： 3. 问题转化为线性优化 到这里，我们得到的优化问题是： 约束条件： 这其实就是一个经典的线性规划问题：在概率分布（simplex 单纯形）上对线性目标函数取最大值。 4. 极值的几何直观 线性函数在单纯形上的最优解一定出现在某个极点（vertex）。单纯形的极点就是“所有概率质量集中在一个动作上”，亦即： 对某个 因此，最优解就是选择使 达到最大值的动作。 5. 得出最终结果 于是可以直接得到： 最优策略的形式为： 如果存在多个并列最大的动作，则在这些动作之间任意分配概率（例如平均分配）也能获得相同的最优值。 6. 小结 策略优化问题本质上是一个线性优化问题； 线性目标在概率单纯形上的最优解落在极点； 因此，给定 的情况下，最优策略是在最大 对应的动作上取 1 的确定性贪心策略。","categories":[{"name":"学习","slug":"学习","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"RL","slug":"RL","permalink":"https://dekelkai.github.io/tags/RL/"},{"name":"reinforce learning","slug":"reinforce-learning","permalink":"https://dekelkai.github.io/tags/reinforce-learning/"}],"author":"Tang Xiangkai"},{"title":"强化学习（二）状态值与贝尔曼方程","slug":"强化学习（二）状态值与贝尔曼方程","date":"2025-09-09T07:59:00.000Z","updated":"2025-09-30T09:43:50.439Z","comments":true,"path":"2025/09/09/强化学习（二）状态值与贝尔曼方程/","permalink":"https://dekelkai.github.io/2025/09/09/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%BA%8C%EF%BC%89%E7%8A%B6%E6%80%81%E5%80%BC%E4%B8%8E%E8%B4%9D%E5%B0%94%E6%9B%BC%E6%96%B9%E7%A8%8B/","excerpt":"","text":"1. 回报（Return） 在 RL 中，智能体和环境交互，每一步都会得到一个奖励 。智能体追求的目标并不是单个奖励，而是从某个时刻开始累积到未来的回报(Return)： 这里 是折扣因子(discounted rate)，用来平衡「眼前奖励」和「长期奖励」。 由于环境具有不确定性， 是一个随机变量，我们通常关心的是它的期望值。 2. 状态值函数 (State Value Function) 在策略下，状态值函数定义为： 表示从状态 出发，按照策略 行动，未来累积的回报期望值。 3. 动作值函数 (Action Value Function) 类似地，动作值函数定义为： 表示在状态 ，执行动作 ，然后遵循策略 后能获得的期望回报。与状态值不同，动作值额外考虑了动作的选择，因此信息更细致。 状态值函数与动作值函数的关系： 即：状态值等于动作值的加权平均。 4. 贝尔曼期望方程 状态值满足一个递推关系： 其中： ：在状态 下的期望奖励 ：在策略 下从状态 转移到 的概率 换句话说，状态值 = 即时奖励 + 折扣后的未来价值。 同样，动作值也有贝尔曼形式： 其中： 第一项是执行动作 后获得的期望奖励； 第二项是未来可能到达的状态价值的加权平均； 因此，动作值体现了即时奖励与未来状态值的结合。 5. 矩阵向量形式 如果我们把所有状态的值函数写成向量，就能得到： 其中： ：所有状态值组成的向量 ：期望奖励向量 ：状态转移矩阵 解析解： 但在大规模环境中，直接求逆不可行，所以需要数值解法。 6. 数值解：迭代方法 数值解最常见的是迭代策略评估： 迭代步骤： 初始化 不断迭代更新直到收敛 这种方法的直观解释是：逐步逼近真实价值，每一步都让估计更接近真实的回报。 7. 状态值与动作值的关系总结 状态值：评价「处于某状态的好坏」 动作值：评价「在某状态执行某动作的好坏」 状态值是动作值的加权平均，而动作值又依赖于奖励与未来状态值 贝尔曼方程就是这种递推关系的数学形式","categories":[{"name":"reinforce learning","slug":"reinforce-learning","permalink":"https://dekelkai.github.io/categories/reinforce-learning/"}],"tags":[{"name":"reinforce learning","slug":"reinforce-learning","permalink":"https://dekelkai.github.io/tags/reinforce-learning/"}],"author":"Dekel"},{"title":"强化学习（一）Basic Concepts","slug":"强化学习（一）Basic Concepts","date":"2025-09-04T16:07:41.000Z","updated":"2025-09-30T05:36:41.796Z","comments":true,"path":"2025/09/05/强化学习（一）Basic Concepts/","permalink":"https://dekelkai.github.io/2025/09/05/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89Basic%20Concepts/","excerpt":"","text":"Set • State: the set of states S • Action: the set of actions A(s) is associated for state s ∈ S. • Reward: the set of rewards R(s, a). Probability distribution • State transition probability ​ at state s, taking action a, the probability to transit s to state s' : • Reward probability: ​ at state s, taking action a, the probability to get reward r : Policy at state s, the probability to choose action a is Markov property(memoryless property)","categories":[{"name":"RL","slug":"RL","permalink":"https://dekelkai.github.io/categories/RL/"}],"tags":[{"name":"RL","slug":"RL","permalink":"https://dekelkai.github.io/tags/RL/"}],"author":"Dekel"},{"title":"毕业设计-自适应和互信息最大化无人机实时追踪蒸馏模型","slug":"毕业设计-自适应和互信息最大化无人机实时追踪蒸馏模型","date":"2025-02-20T11:31:12.000Z","updated":"2025-09-17T08:35:45.770Z","comments":true,"path":"2025/02/20/毕业设计-自适应和互信息最大化无人机实时追踪蒸馏模型/","permalink":"https://dekelkai.github.io/2025/02/20/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1-%E8%87%AA%E9%80%82%E5%BA%94%E5%92%8C%E4%BA%92%E4%BF%A1%E6%81%AF%E6%9C%80%E5%A4%A7%E5%8C%96%E6%97%A0%E4%BA%BA%E6%9C%BA%E5%AE%9E%E6%97%B6%E8%BF%BD%E8%B8%AA%E8%92%B8%E9%A6%8F%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"1. 输入处理 输入： 模板图像 ，通常是初始帧或前一帧，尺寸较小，聚焦于目标物体。 搜索图像 ，当前帧中需要搜索的区域，尺寸较大，覆盖目标可能的移动范围。 分块： 和 分为 大小的块，数量分别为： 线性投影： 每个小图像块通过线性层映射为维度 的嵌入向量。 位置编码： 使用可学习的位置编码，保留空间信息。 2. 激活模块 (AM) 2.1 基本定义 考虑第 层 ，tokens 的总数记为 ，嵌入向量的维度记为 。 第 层输出的 tokens 记为 。 第 层 Transformer 块输出的标记切片表示为： 其中 是标准单位向量。 线性层标记为 。 2.2 激活模块公式 激活模块（Activation Module, AM）表示为： 其中： 表示第 层 Transformer 块的激活概率。 为 sigmoid 激活函数：。 2.3 激活规则 设 为激活概率阈值。 若 ，则第 层 Transformer 块被激活。 否则，跳过第 层，直接将第 层的输出 tokens 传递给第 层。 2.4 强制激活与稀疏性 强制激活： 若所有 个 Transformer 块都未被激活，则无法计算模板图像和搜索图像之间的相关性。 因此，设定前 层始终保持激活状态，以确保基础信息的传递。 区块稀疏性损失 ： 若所有输入经过 AM 都使 Transformer 模块激活，会导致效率降低。 引入区块稀疏性损失，鼓励在平均情况下停用更多的 Transformer 块： 其中 为常数，与 共同控制模块的稀疏性。 3. 通过互信息 (MI) 最大化表征视图不变性 (VIR) 3.1 互信息 (MI) 定义 给定两个随机变量 和 ，它们之间的 MI 为： 其中： 是联合概率分布。 是边缘概率分布。 是库尔贝克-莱布勒散度。 3.2 基于 JSD 的 MI 估计 由于现实中无法直接估计 MI，采用基于詹森-香农散度 (JSD) 的 Deep InfoMax MI 估计器： 其中： 是一个神经网络，将输入空间映射到实数空间。 是 softplus 函数。 3.3 视图不变性损失 真实目标定位 token 表示为： 其中 。 给定目标在搜索图像中的真实定位 ，通过线性插值获得对应的 token： 视图不变性损失函数为： 4. 基于知识最大化的多教师知识蒸馏 (MD) 4.1 教师模型与学生模型 教师模型：使用 3 种已有的跟踪模型（AVTrack-DeiT、AVTrack-ViT 和 AVTrack-EVA），提供多样化且高质量的教师模型。 学生模型：选择自相似结构，使用较小的 ViT 主干网（一半 ViT 块），具有模块化和可扩展特性。 4.2 教师输出处理 平均所有教师的预测结果，得到聚合特征表示： 使用温度 对模型输出进行软化处理： 其中 。 4.3 互信息最大化 目标函数为： 在蒸馏训练中，使用 和教师模型的总损失函数的加权和来训练学生模型。 5. 预测头和训练目标 5.1 拐角检测头 对搜索图像的特征进行处理，直接估计目标物体的边界框。 生成 3 个输出： 目标分类分数 ，表示每个位置是目标中心的概率。 局部偏移 ，用于微调目标位置的偏移量。 归一化边界框大小 ，表示边界框的宽度和高度。 根据分类分数的最大值确定目标的粗略位置： 结合局部偏移和边界框大小，最终确定目标的边界框： 5.2 总损失函数 总损失函数为加权焦点损失： 其中： ，。 ，。 在蒸馏阶段，总损失为： 其中 。 核心 动态激活模块：通过稀疏性损失实现按需计算，效率提升约30%。 视图不变性学习：基于MI最大化，增强模型对视角变化的鲁棒性。 多教师蒸馏：轻量化学生模型性能接近教师，计算量减少50%。","categories":[{"name":"实时追踪","slug":"实时追踪","permalink":"https://dekelkai.github.io/categories/%E5%AE%9E%E6%97%B6%E8%BF%BD%E8%B8%AA/"}],"tags":[{"name":"大学","slug":"大学","permalink":"https://dekelkai.github.io/tags/%E5%A4%A7%E5%AD%A6/"}],"author":"Dekel"},{"title":"🥸反向传播中梯度消失和梯度爆炸的原因🥸","slug":"反向传播中梯度消失和梯度爆炸的原因","date":"2025-02-06T15:36:11.000Z","updated":"2025-09-17T08:43:38.805Z","comments":true,"path":"2025/02/06/反向传播中梯度消失和梯度爆炸的原因/","permalink":"https://dekelkai.github.io/2025/02/06/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E4%B8%AD%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E5%92%8C%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E7%9A%84%E5%8E%9F%E5%9B%A0/","excerpt":"","text":"在深度学习中，梯度消失和梯度爆炸是训练深层神经网络时常见的挑战。要真正理解这些问题，必须深入理解反向传播的机制，尤其是梯度是如何通过链式法则逐层传播的。本文通过手推反向传播的数学推导，帮助理解梯度消失和梯度爆炸的根本原因。 在深度学习中，梯度消失和梯度爆炸是训练深层神经网络时常见的挑战。要真正理解这些问题，必须深入理解反向传播的机制，尤其是梯度是如何通过链式法则逐层传播的。本文通过手推反向传播的数学推导，帮助读者理解梯度消失和梯度爆炸的根本原因。 准备工作 在开始反向传播的推导之前，我们需要明确网络的结构和损失函数的定义。假设我们有一个简单的神经网络，包含两个输入、两个隐藏层神经元和两个输出神经元。每个神经元的输出通过sigmoid函数进行激活，损失函数为均方误差。 每个神经元： 其中为sigmoid函数。 损失函数： 反向传播 反向传播是神经网络训练的核心算法，它通过链式法则计算每一层的梯度，并根据梯度更新网络参数。为了理解梯度消失和梯度爆炸问题，我们需要详细推导反向传播的过程。首先，我们从输出层的参数w5开始，逐步推导每一层的梯度。 对参数反向传播: 其中： 故对的偏导为： 对参数进行反向传播 对于加号左部分各偏导： 故： 左部 同理计算可得加号右边部分： 右部 最终得到对的反向传播： 分析 通过手推反向传播的数学推导，我们可以清晰地看到梯度是如何通过链式法则逐层传播的。接下来，我们将分析这些推导结果，探讨梯度消失和梯度爆炸问题的根本原因。 经过手推反向传播的数学推导，我们得到了一个较为复杂的表达式。尽管这只是针对一个简单的网络结构（仅包含一个隐藏层的两个神经元和两个输出神经元）中某个参数更新的计算过程，但其复杂性已经显而易见。为了简化式子，我们将看作，将看作，则上式子结果为： 对于我们只有一个隐藏层两个神经元的网络，就已经得到了如此复杂的式子，且其中的乘法运算比较多，然而我们普遍的神经网络结构为如下图所示： 其中的计算复杂度不敢想象。。。 梯度消失问题 梯度消失问题是深层神经网络训练中的常见挑战之一。它主要表现为在反向传播过程中，梯度随着层数的增加而逐渐变小，最终导致参数更新缓慢甚至停止。为了理解梯度消失问题的根源，我们从激活函数的导数sigmoid入手，分析梯度是如何在传播过程中衰减的。 梯度消失问题的主要原因在于激活函数的导数。以sigmoid函数为例，如下图其导数的最大值为0.25，这意味着在反向传播过程中，梯度会随着层数的增加而不断衰减。具体来说，每一层的梯度都会乘以一个小于1的值，导致梯度在传播过程中逐渐变小，最终接近于零。这种情况下，网络的参数更新会变得非常缓慢，甚至停止更新，导致模型无法有效学习。 为了更直观地理解梯度消失问题，我们可以考虑一个深度神经网络。假设网络有L层，每一层的梯度都会乘以sigmoid函数的导数。由于sigmoid函数的导数小于，经过L次乘法后，梯度会变得非常小。例如，如果每一层的梯度都乘以0.25，那么经过10层后，梯度会变为原来的，几乎可以忽略不计。 梯度爆炸问题 在反向传播过程中，梯度是通过链式法则逐层传播的。每一层的梯度都会乘以该层的权重矩阵。如果这些权重的初始值过大，梯度在传播过程中会不断放大。具体来说，假设某一层的权重矩阵为 W，其值较大，那么在反向传播时，梯度会乘以 W，导致梯度值迅速增大。随着网络层数的增加，这种放大效应会累积，最终导致梯度爆炸。 例如，假设每一层的梯度都乘以一个大于1的因子α，那么在经过 L 层后，梯度会变为原来的 倍。如果 α=2，经过10层后，梯度会放大到 倍。这种指数级的增长会导致梯度值过大，使得参数更新步长过大，模型无法收敛。 解决方案 梯度消失和梯度爆炸问题不仅仅是由于激活函数的导数或权重初始值过大引起的，还与网络的结构、层数以及优化算法的选择密切相关。为了缓解这些问题，可以采用ReLU激活函数、合适的权重初始化方法、梯度裁剪等技术。","categories":[{"name":"Tips","slug":"Tips","permalink":"https://dekelkai.github.io/categories/Tips/"},{"name":"机器学习","slug":"Tips/机器学习","permalink":"https://dekelkai.github.io/categories/Tips/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"学习","slug":"学习","permalink":"https://dekelkai.github.io/tags/%E5%AD%A6%E4%B9%A0/"}],"author":"Dekel"},{"title":"Vision Transformer","slug":"Vision Transformer","date":"2025-01-29T14:14:48.000Z","updated":"2025-09-17T08:44:50.879Z","comments":true,"path":"2025/01/29/Vision Transformer/","permalink":"https://dekelkai.github.io/2025/01/29/Vision%20Transformer/","excerpt":"","text":"VIT模型整体框架✨✨✨ 从整体上来看，VIT模型的结构是很少的，事实上确实如此。如果你明白了我上一篇讲解的Transformer的话，那这篇文章真的就特别简单了，可以说没什么难点。这篇文章作者企图不改变Transformer的结构来实现物体分类任务，我们可以来看一下VIT中的Transformer Encoder 结构，基本是和Transformer中是一样的。注意我这里说的是基本喔，你对比两篇论文中Encoder的结构你会发现，Norm这个结构的位置是有所变化的，至于为什么这样做，作者也没有提及，个人感觉这个改变对结构影响不会很大，感兴趣的可以改变这个结构尝试尝试效果。另外一点是在VIT中没有使用Decoder结构，这里大家需要注意一下。 VIT细节梳理✨✨✨ 首先，想想NLP中的Transformer和CV中的VIT这两个结构输入有什么区别？从变量的类型来看，两者都是一个tensor张量；而从变量的维度来看，NLP中的输入往往是二维的tensor，而CV中往往是一个三维的RGB图像。【都忽略Batch维度】 这种维度的不统一会导致我们不能直接将图片数据喂入到Transformer结构中去，而是需要进行一定的维度转换，即将三维的tensor转换成二维的tensor，这个过程被称为patch_embedding。 那论文中是如何将三维的tensor转化为二维的tensor的呢？如下图所示： 对原图进行卷积，卷积核大小为16163 ,步长为16，padding=0，卷积核个数为768，卷积后，我们会得到特征图，其尺寸为1414768，接着将前两个维度展平，就得到了维度为196*798的tensor。其大致过程如下。 我认为这步使用卷积真的很巧妙，我们得到的196x798的二维向量，其实每一行即1x798都包含了原图中16x16x3大小的patch，这就是卷积的提取特征的功能嘛。【我这样介绍不知道大家会不会有这样的思路——我先用一些CNN模型来对图片提取特征，只要使CNN最后的输出维度为196*768，最后再送入Transformer模型中。其实这就将CNN和Transformer很好的结合在一起了，这种方法是可行的，大家可以自己尝试尝试喔】 现在我们已经得到了196x768维的tensor，我们假设其为x。接下来我们会使用一个维度为1x768维的Class token来和x进行Concat操作，输出结果为197*768维的tensor。这里肯定有人有疑问了，为什么这里会加一个Class token，在上篇讲述的Transformer中可没有这个操作。--小傻瓜--因为这篇文章我们要用来对物体进行分类啊！！！说不定你现在有点怀疑自己了，因为是分类任务所以要加上Class token？这两个还有因果关系不成？一个个问号从你脑海中冒出，百思不得其解。其实啊，这可没什么啥因果关系，只是我们在分类任务中加上Class token可能会效果更好。🌵🌵🌵 如果我们不加Class token，直接将196x768维的tensor输入Encode中，我们的输出同样是196x768，即196个1x768维的向量，这时候我们应该拿哪个向量来当作最后的输出向量进而进行物体分类任务呢？这我们是很难确定的。所以我们干脆在输入Encode前就加上一个1x768维的向量（这个1维向量放在196x768维向量前面），这样在输出时向量的维度就会是197x768，然后我们只需要通过切片的方式获得第一个1x768维向量并将其送入分类头进行分类即可。在代码中这个Class token是一个可学习的向量，初始为全0的1x768维向量。🌱🌱🌱 Class token和x拼接后，输出尺寸变成了197x768，此时我们会加上一个位置编码向量position Embedding，其维度为197x768。关于这部分我在上一篇介绍Transformer中已经很详细的介绍过了，这里不再过多阐述原理。但我们可以看一下如果我们不使用位置编码，那么下面两幅图输出的结果将是一致的，这显然是有违我们直觉的。 接下来我们将经过位置编码的输入喂入encoder网络中，并重复L次encoder结构，encoder的结构如下： 经过L个encoder结构后，输入维度没有发生变换，仍为197x768维，此时我们会通过切片的方式提取出Class token的信息，其维度为1x768。接着会拿这个1x768维的Class token经过MLP Head层。MLP Head层的结构如下： 其中Pre-Logits这部分是可选的，其就是一个全连接层加上一个tanh激活函数，具体我们会在下一篇代码实战部分进行讲解。Linear就用于分类了，输出节点个数为我们任务的类别数。","categories":[{"name":"学习","slug":"学习","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Vision Transformer","slug":"Vision-Transformer","permalink":"https://dekelkai.github.io/tags/Vision-Transformer/"}],"author":"Dekel"},{"title":"Transformer","slug":"Transformer","date":"2025-01-27T14:11:34.000Z","updated":"2025-09-17T08:45:49.800Z","comments":true,"path":"2025/01/27/Transformer/","permalink":"https://dekelkai.github.io/2025/01/27/Transformer/","excerpt":"","text":"编码器层（Encoder Layer） 编码器层的输入首先进入自注意力子层（Self-Attention），该子层的作用在于帮助编码器关注句子中的其他词汇，以便更好地编码某个特定词汇。 随后，自注意力子层的输出将传递给一个前馈神经网络（Feed-Forward Neural Network）。结构完全相同的前馈网络被独立地应用于每个位置。 输入输出对理解数据流非常重要。编码器层的输入形状为 S x D（请参见下面的图表），其中 S 是源句子长度（例如，英语句子），而 D 是嵌入的维度（也是模型维度，论文中取值为 512）。 编码器的输入和输出形状相同。由于编码器层是相互叠加的，因此，我们希望其输出具有与输入相同的维度，以便它可以轻松地流入下一个编码器层。因此，输出也是 S x D 形状。 解码器层（Decoder Layer） 解码器层（decoder layer）也包含前面编码器中提到的两个层，不过区别在于这两个层之间还夹了一个注意力层（Encoder-Decoder Attention）。这个额外的注意力层的作用在于让解码器能够注意到输入句子中与解码任务相关的部分。 在一个已经训练好的Transformer模型中，输入是怎么变为输出的呢？首先我们要知道各种各样的张量（向量）是如何在这些组件之间变化的。 与其他的NLP项目一样，我们首先需要把输入的每个单词通过词嵌入（embedding）转化为对应的向量。 所有编码器层接收一组向量作为输入（论文中的输入向量的维度是512）。最底下的那个编码器层接收的是嵌入向量，之后的编码器层接收的是前一个编码器层的输出。 向量列表的长度这个超参数是我们可以设置的，一般来说是我们训练集中最长的那个句子的长度。 当我们的输入序列经过词嵌入之后得到的向量会依次通过编码器层中的两个层。 注意力机制（Attention） 注意力机制是论文的核心，它在编码器和解码器部分的处理稍有差异。让我们先以编码器部分的注意力层机制为例进行介绍。 上边提到，每个编码器层接受一组向量作为输入。在其内部，输入向量先通过一个自注意力层，再经过一个前馈神经网络层，最后将其将输出给下一个编码器层。 不同位置上的单词都要经过自注意力层的处理，之后都会经过一个完全相同的前馈神经网络。 在这里，我们开始看到 Transformer 的一个关键特点，即每个位置上的单词在编码器层中有各自的流通方向。 在自注意力层中，这些路径之间存在依赖关系。单词和单词之间会有关联，假设一个句子有 50 个单词，那么可以粗略想象成自注意力计算过程中，会构造一个 50 x 50 的关联矩阵。 前馈神经网络（Feed Forward）层中没有这些依赖关系。每个单词独立通过前馈神经网络，单词和单词之间没有关联，因此各种路径可以在流过前馈网络层的时候并行计算。 自注意力（Self-Attention） 现在让我们看一下自注意力机制。 假设我们要翻译下边这句话： ”The animal didn't cross the street because it was too tired” 这里it指的是什么？是street还是animal？人理解起来很容易，但是对算法来讲就不那么容易了。 当模型处理it这个词的时候，自注意力会让it和animal关联起来。 当模型编码每个位置上的单词的时候，自注意力的作用就是：看一看输入句子中其他位置的单词，试图寻找一种对当前单词更好的编码方式。 如果熟悉 RNNs 模型，回想一下 RNN 如何处理当前时间步的隐藏状态：将之前的隐藏状态与当前位置的输入结合起来。在 Transformer 中，自注意力机制也可以将其他相关单词的“理解”融入到我们当前处理的单词中。 当我们在最后一个encoder组建中对it进行编码的时候，注意力机制会更关注The animal，并将其融入到it的编码中。 自注意力的计算（单个） 先画图用向量解释一下自注意力是怎么算的，之后再看一下实际实现中是怎么用矩阵算的。 第一步 对于编码器的每个输入向量x，都会计算三个向量，即query、key和value向量。 这些向量的计算方法是将输入的词嵌入向量与三个权重矩阵相乘。这些权重矩阵是在模型训练阶段通过训练得到的。 什么是 “query”、“key”、“value” 向量？这三个向量是计算注意力时的抽象概念，请继续往下看注意力计算过程。 第二步 计算注意力得分。 假设我们现在在计算输入中第一个单词 Thinking 的自注意力。我们需要使用自注意力给输入句子中的每个单词打分，这个分数决定当我们编码某个位置的单词的时候，应该对其他位置上的单词给予多少关注度。 这个得分是query和key的点乘积得出来的。例如，如果我们处理位置#1的单词的自我注意，第一个分数将是q1和k1的点积。第二个分数是q1和k2的点积。（备注：在使用矩阵处理时，是用 Q 和 K 的转置相乘得到，详见后）。 第三步 将计算获得的注意力分数除以 8。 为什么选 8？是因为key向量的维度是 64，取其平方根，这样让梯度计算的时候更稳定。默认是这么设置的，当然也可以用其他值。 第四步 除 8 之后将结果扔进 softmax 计算，使结果归一化，softmax 之后注意力分数相加等于 1，并且都是正数。 这个 softmax 之后的注意力分数表示 在计算当前位置的时候，其他单词受到的关注度的大小。显然在当前位置的单词肯定有一个高分，但是有时候也会注意到与当前单词相关的其他词汇。 第五步 将每个 value 向量乘以注意力分数。这是为了强化我们想要关注的单词的 value，并尽量抑制其他不相关的单词（通过乘以一个接近于零的数，如 0.001）。这个过程被称为“缩放”或者“加权”，可以使得我们更加关注与目标单词相关的单词。 第六步 将上一步的结果相加，输出本位置的注意力结果。 这就是自注意力的计算。计算得到的向量直接传递给前馈神经网络。但是为了处理的更迅速，实际是用矩阵进行计算的。接下来我们看一下怎么用矩阵计算。 自注意力的计算（矩阵） 第一步是计算 Query、Key 和 Value 矩阵。我们通过将嵌入打包到矩阵 X 中，并将其乘以我们训练的权重矩阵、、来实现这一点。 ​ X矩阵中的每一行对应于输入句子中的一个单词。 ​可再次看到嵌入向量维度（512，图中的 4 个框）和 q/k/v 向量维度（64，图中的 3 个框）的差异 最后，由于我们使用矩阵计算，因此可以将步骤 2 到 6 合并为一个公式，以计算自注意力层的输出。 通过将输入向量 x 与注意力头的权重矩阵相乘，可以得到对应的 query、key 和 value 向量。单个头获取的这三个向量维度是64，比嵌入向量的维度小，8个头的输出连接后变为 512。因此嵌入向量、编码器层的输入输出维度都是512。 对于上图的解释： 假定输入的英文句子是“The quick brown fox“，句子长度 S 为4，参考“编码器层”章节的解释，注意力子层的输入形状为（4 x 512）。 自注意力层使用三个权重矩阵进行初始化——Query（Wq）、Key（Wk）和Value（Wv）。这些权重矩阵的尺寸都是 D x d，在论文中d取值为64，即权重矩阵的尺寸为 512 x 64。在训练模型时，我们将训练这些矩阵的权重。 在第一次计算（图中的Calc 1）中，我们通过将输入（注意：代码实现中是三个不同的输入，编码器层都是X，解码器层不同，见代码中的解释）与各自的Query、Key和Value权重矩阵相乘，计算出Q、K和V矩阵（尺寸为 S x d，示例中为 4 x 64）。 在第二次计算中，参考Attention计算公式，首先将Q和Kᵀ矩阵相乘，得到一个尺寸为 S x S（示例中为 4 x 4）的矩阵，然后将其除以√d的标量。然后对矩阵进行softmax运算，使得每一行的和都为1。这个矩阵可以理解为句子中每个词之间的关联度。 上面 S x S 的矩阵再和V矩阵相乘，得到尺寸为 S x d（示例中为 4 x 64）的矩阵。经过后续的连接操作后，传入下一层。 多头注意力 论文进一步改进了自注意力层，增加了一个机制，也就是多头注意力机制。这样做有两个好处： 第一个好处，它扩展了模型专注于不同位置的能力。 在上面例子里只计算一个自注意力的的例子中，编码“Thinking”的时候，虽然最后 Z1 或多或少包含了其他位置单词的信息，但是它实际编码中还是被“Thinking”单词本身所支配。 如果我们翻译一个句子，比如“The animal didn’t cross the street because it was too tired”，我们会想知道“it”指的是哪个词，这时模型的“多头”注意力机制会起到作用。 第二个好处，它给了注意层多个“表示子空间”。 就是在多头注意力中同时用多个不同的 WV*W**V* 权重矩阵（Transformer 使用8个头部，因此我们最终会得到8个计算结果)，每个权重都是随机初始化的。经过训练每个 WV*W**V* 都能将输入的矩阵投影到不同的表示子空间。 如果我们做和上面相同的自注意力计算，只不过八次使用不同的权重矩阵，我们最后得到八个不同的Z矩阵。 但是这会存在一点问题，多头注意力出来的结果会进入一个前馈神经网络，这个前馈神经网络可不能一下接收8个注意力矩阵，它的输入需要是单个矩阵（矩阵中每个行向量对应一个单词），所以我们需要一种方法把这8个压缩成一个矩阵。 怎么做呢？我们将这些矩阵连接起来，然后将乘以一个附加的权重矩阵 以上就是多头自注意力的全部内容。让我们把多头注意力上述内容 放到一张图里看一下子： 现在我们已经看过什么是多头注意力了，让我们回顾一下之前的一个例子，再看一下编码“it”的时候每个头的关注点都在哪里： 如果我们把所有的头的注意力都可视化一下，就是下图这样，但是看起来事情好像突然又复杂了。 编码器（Encoder） 使用位置编码表示序列的位置 到现在我们还没提到过如何表示输入序列中词汇的位置。 Transformer 在每个输入的嵌入向量中添加了位置向量。这些位置向量遵循某些特定的模式，这有助于模型确定每个单词的位置或不同单词之间的距离。将这些值添加到嵌入矩阵中，一旦它们被投射到Q、K、V中，就可以在计算点积注意力时提供有意义的距离信息。 位置编码向量和嵌入向量的维度是一样的，比如下边都是四个格子： 举个例子，当嵌入向量的长度为4的时候，位置编码长度也是4 一直说位置向量遵循某个模式，这个模式到底是什么。 参考论文：Convolutional Sequence to Sequence Learning 在下面的图中，每一行对应一个位置编码。所以第一行就是我们输入序列中第一个单词的位置编码，之后我们要把它加到词嵌入向量上。 看个可视化的图,这里表示的是一个句子有20个词，词嵌入向量的长度为512。可以看到图像从中间一分为二，因为左半部分是由正弦函数生成的。右半部分由余弦函数生成。然后将它们二者拼接起来，形成了每个位置的位置编码。： 但是需要注意注意一点，上图的可视化是官方Tensor2Tensor库中的实现方法，将sin和cos拼接起来。但是和论文原文写的不一样，论文原文的3.5节写了位置编码的公式，论文不是将两个函数concat起来，而是将sin和cos交替使用。论文中公式的写法可以看这个代码：transformer_positional_encoding_graph，其可视化结果如下： 全连接的前馈网络（Feed-Forward Networks） 除了注意力子层外，我们的编码器和解码器中的每一层都包含一个全连接的前馈网络，该网络被单独且相同地应用于每个位置。这包括两个线性变换，它们之间有ReLU激活函数。 虽然FFN的网络架构在各个位置上都是相同的，但它们在每个位置使用的是不同的权重参数。这可能就是论文作者为了强调这个，加上PositionWise的原因。 另一种描述方法是，这是两个具有1内核大小的卷积。输入和输出的维度是dmodel=512，而内部层的维度是 dff=2048。 子层之间的连接（残差和层归一化） 原始论文 在继续往下讲之前，我们还需再提一下编码器层中的一个细节：每个编码器层中的每个子层（自注意力层、前馈神经网络）都有一个残差连接（图中的Add），之后是做了一个层归一化（layer-normalization）（图中的Normalize）。 将过程中的向量相加和layer-norm可视化如下所示： 当然在解码器子层中也是这样的。 我们现在画一个有两个编码器和解码器的Transformer，那就是下图这样的： 解码器（Decoder） 现在我们已经介绍了编码器的大部分概念，因为Encoder的Decoder差不多，我们基本上也知道了解码器是如何工作的。那让我们直接看看二者是如何协同工作的。 解码器首先处理输入序列，将最后一个编码器层的输出转换为一组注意向量K和V。注意：参考实现中为直接用，见EncoderDecoder.forward，DecoderLayer.forward。 每个解码器层将在“encoder-decoder attention”层中使用编码器传过来的K和V，这有助于解码器将注意力集中在输入序列中的适当位置： 输出步骤会一直重复，直到遇到句子结束符 表明transformer的解码器已完成输出。 每一步的输出都会在下一个时间步喂给给底部解码器，解码器会像编码器一样运算并输出结果（每次往外蹦一个词）。 跟编码器一样，在解码器中我们也为其添加位置编码，以指示每个单词的位置。 解码器中的自注意力层和编码器中的不太一样： 在解码器中，自注意力层只允许关注已输出位置的信息。实现方法是在自注意力层的softmax之前进行mask，将未输出位置的信息设为极小值。 “encoder-decoder attention”层的工作原理和前边的多头自注意力差不多，但是Q、K、V的来源不用，Q是从下层创建的（比如解码器的输入和下层decoder组件的输出），但是其K和V是来自编码器最后一个组件的输出结果。 最后的线性层和softmax层 Decoder输出的是一个浮点型向量（512维），如何把它变成一个词？ 这就是最后一个线性层和softmax要做的事情。 线性层就是一个简单的全连接神经网络，它将解码器生成的向量映射到logits向量中。假设我们的模型词汇表是10000个英语单词，它们是从训练数据集中学习的。那logits向量维数也是10000，每一维对应一个单词的分数。 然后，softmax层将这些分数转化为概率（全部为正值，加起来等于1.0），选择其中概率最大的位置的词汇作为当前时间步的输出。","categories":[{"name":"学习","slug":"学习","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Transformer","slug":"学习/Transformer","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/Transformer/"}],"tags":[{"name":"学习","slug":"学习","permalink":"https://dekelkai.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"Transformer","slug":"Transformer","permalink":"https://dekelkai.github.io/tags/Transformer/"}],"author":"Dekel"},{"title":"爬虫-网页网易云音乐评论抓取","slug":"爬虫学习-网页网易云音乐评论抓取","date":"2025-01-14T16:10:19.000Z","updated":"2025-09-17T08:46:10.761Z","comments":true,"path":"2025/01/15/爬虫学习-网页网易云音乐评论抓取/","permalink":"https://dekelkai.github.io/2025/01/15/%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0-%E7%BD%91%E9%A1%B5%E7%BD%91%E6%98%93%E4%BA%91%E9%9F%B3%E4%B9%90%E8%AF%84%E8%AE%BA%E6%8A%93%E5%8F%96/","excerpt":"","text":"傍晚时分，坐在屋檐下，看着天慢慢地黑下去，心里寂寞而凄凉，感到自己的生命被剥夺了。当时我是个年轻人，但我害怕这样生活下去，衰老下去。在我看来，这是比死亡更可怕的事。 一、准备工作 1. 导入所需的库 1234567import jsonimport randomimport requests# 实现AES加密需要的三个模块from Crypto.Cipher import AES # AES加密from Crypto.Util.Padding import padfrom base64 import b64encode 2. 捕获评论数据包 网站的评论区数据是通过js动态加载的，在XHR中捕获所有数据包，找到评论区数据包。 3. 分析数据包 在标头可以看到是通过post请求发送的数据，载荷中的表单数据能看出params和encSecKey的值是被加密过的。使用正常方式带上者两个发送post请求是肯定得不到评论数据的，因此必须破解加密。 123456# 请求评论的url地址及发送的请求数据，空串为我们后面需要破解然后填入的位置url = \"https://music.163.com/weapi/comment/resource/comments/get?csrf_token=\"data = { 'params': ' ' 'encSecKey': ' ' } 二、逆向评论数据包 1.堆栈分析 在数据包中，数据的加密过程：明文-&gt;加密-&gt;密文，在上面看到的就是密文。于是我们在启动器中跟踪调用栈查找何时是明文何时被加密为密文 2. 首先在栈顶处的代码打上断点 3.观察网页 刷新网页并观察，发现歌词和评论都消失了，说明都是在这之后加载的，而我们的断点是下在一个函数里面的；可以判断该函数会被多次调用，因此我们要让网页继续运行直到是评论包调用了这个函数 4. 继续执行 执行两到三次后出现歌词 5. 继续执行到评论出现 说明在歌词出现后再次调用这个函数评论出现，因此我们要找的评论数据就在歌词出来后的这个断点里；刷新网页重新运行直到歌词出现前 可以看到一个params=XXXXX参数，结合前面载荷中的参数，判断出这很可能是加密后的内容，因此在调用堆栈中向下寻找，看看能不能找到加密前的内容 6. 堆栈向下查找并分析 到下面的地方时，参数进入了e0x中，可以看到还是加密的内容，继续寻找 到这里时看到data的内容发生了明显的变化，可以隐约看到一些信息；在上面t0x.be0x中是加密的状态，由此判定数据是在t0x.be0x中被加密 7. 找到加密函数 在本地堆栈信息中找到data所处的位置 发现里面的信息又来自bVi6c中，找到上面的bVi6c 1234567891011// 加密函数var bVi6c = window.asrsea(JSON.stringify(i0x), bse6Y([\"流泪\", \"强\"]), bse6Y(Qu1x.md), bse6Y([\"爱心\", \"女孩\", \"惊恐\", \"大笑\"]));/*构成：windows.asrsea() 自定义的加密函数JSON.stringify() 将字典转换为json字符串类型bse6Y([\"流泪\", \"强\"]) 自定义的函数对象 bse6Y(Qu1x.md) 自定义的函数对象 bse6Y([\"爱心\", \"女孩\", \"惊恐\", \"大笑\"]) 自定义的函数对象 */ 三、解析加密函数的参数 1. 后三个参数 可以看到在代码中是写死的 我们在控制台尝试执行这三个参数内容 可以看到生成了固定的字符串 123bse6Y([\"流泪\", \"强\"]='010001'bse6Y(Qu1x.md)='00e0b509f6259df8642dbc35662901477df22677ec152b5ff68ace615bb7b725152b3ab17a876aea8a5aa76d2e417629ec4ee341f56135fccf695280104e0312ecbda92557c93870114af6c9d05c4f7f0c3685b7a46bee255932575cce10b424d813cfe4875d3e82047b97ddef52741d546b8e289dc6935b3ece0462db0a22b8e'bse6Y([\"爱心\", \"女孩\", \"惊恐\", \"大笑\"])='0CoJUm6Qyw8W8jud' 2. 解析JSON.stringify中的i0x参数 在加密函数处打上断点，追踪i0x的值 在网络捕获数据包，直到评论区数据包出现 评论数据包出现说明数据已经加密过了，重新执行到评论区数据包出现的前一次执行 可以找到i0x的数据内容 12345678910i0x = { \"csrf_token\": \"c5ab7625a12cbf8010af4c1df61b0f6a\", \"cursor\": \"-1\", \"offset\": \"0\", \"orderType\": \"1\", \"pageNo\": \"1\", \"pageSize\": \"20\", \"rid\": \"R_SO_4_1392772737\", # 每首歌不同的歌曲id \"threadId\": \"R_SO_4_1392772737\", # 每首歌不同进程id } 四、解析加密函数 1var bVi6c = window.asrsea(JSON.stringify(i0x), bse6Y([\"流泪\", \"强\"]), bse6Y(Qu1x.md), bse6Y([\"爱心\", \"女孩\", \"惊恐\", \"大笑\"])); 1. 在代码中搜索加密函数，找到加密函数的位置 2. 分析加密函数 可以看到，d()函数就是加密的主体函数，它分别调用a()、b()、c()函数，最后返回h，而h中就含有encText和encSecKey 123456789101112131415161718# d需要转为json字符串# i0xd = { \"csrf_token\": \"c5ab7625a12cbf8010af4c1df61b0f6a\", \"cursor\": \"-1\", \"offset\": \"0\", \"orderType\": \"1\", \"pageNo\": \"1\", \"pageSize\": \"20\", \"rid\": \"R_SO_4_34723470\", # 不同歌曲id \"threadId\": \"R_SO_4_34723470\", # 不同歌曲id}# bse6Y([\"流泪\", \"强\"])e=\"010001\"# bse6Y(Qu1x.md)f=\"00e0b509f6259df8642dbc35662901477df22677ec152b5ff68ace615bb7b725152b3ab17a876aea8a5aa76d2e417629ec4ee341f56135fccf695280104e0312ecbda92557c93870114af6c9d05c4f7f0c3685b7a46bee255932575cce10b424d813cfe4875d3e82047b97ddef52741d546b8e289dc6935b3ece0462db0a22b8e7\"# bse6Y([\"爱心\", \"女孩\", \"惊恐\", \"大笑\"])g=\"0CoJUm6Qyw8W8jud\" 3. 逐个分析加密函数内的调用 a()函数:用于生成16位随机字符串 12345678# 网站为随机生成，后面我们设置成固定值def a(a): b = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\" c = \"\" for d in range(a): e = random.randint(0, len(b) - 1) c += b[e] return c b()函数:AES加密函数，对a进行加密，密钥为b，初始化向量为0102030405060708，，采用的是CBC模式；用python按照上面的样子直接构建一个相同的AES加密函数 12345678910111213141516# AES-CBC加密def encrypt_aes(text, key, iv): cipher = AES.new(key.encode('utf-8'), AES.MODE_CBC, iv.encode('utf-8')) # 设置密钥和初始化向量 padded_text = pad(text.encode('utf-8'), AES.block_size) # 设置加密文本 ciphertext = cipher.encrypt(padded_text) # 应用加密 return b64encode(ciphertext).decode('utf-8') # 返回字符串# 网站源码的function b(a,b)加密函数def b(a, b): c = b d = '0102030405060708' e = a f = encrypt_aes(e, c, d) return f c()函数:RSA加密，b、c分别最为公钥的指数部分和模数部分，中间的私钥为空。d为创建的密钥对对象，用来对i进行加密。 由于e，f的值都是固定的，c里的设置也是固定的，那么我们其实可以将i也设置为固定的值。 i是个16位随机数，它的作用就是为了让每次加密的结果不同，起混淆的作用，如果我们将它给固定住了也不会影响。 实际流程：c()函数对随机数i进行RSA加密，发送到服务器的时候先对i进行解析，然后得到随机数i作为解析encText的密钥，然后再解析出d也就是i0x中关于歌曲的信息。 1）在i处断点，追踪i的变化 2）刷新网页，执行脚本直到评论数据出现 3）重新刷新网页截到评论包前一个包后停止 4）单步跳过函数直到i变化 12# i的值i=\"P5rcbOIWOpY8YqGq\" 4）继续调试直到脚本运行到h后观察encSecKey的值 这样，我们就得到了当i=\"P5rcbOIWOpY8YqGq\"时，encSecKey的值 1&gt;encSecKey=\"7b3a12df898a7eaf2f0fc1adf83ddb305f0ee4563c0a7cbdad70ecf9c8118f76a211dba2218339cc28bb9647ea3f0f591dae07051b3956f2af8b15111532ccf94fcd3d106f19594e7bddec1002d695aaf00fdd886519e8df24bb044be1d5b868efc2feba0bc7bb19f1b456e5ee2a6098559c993fc3b45c3a022b660cdb065acf\" 4. 获得h.encText的值 可以看到进行了两次加密，我们用python模拟即可。需要将字典d转换为json，在python中使用json.dumps(i0x)即可。 123456789101112131415161718192021&gt;# AES-CBC加密&gt;def encrypt_aes(text, key, iv): cipher = AES.new(key.encode('utf-8'), AES.MODE_CBC, iv.encode('utf-8')) # 设置密钥和初始化向量 padded_text = pad(text.encode('utf-8'), AES.block_size) # 设置加密文本 ciphertext = cipher.encrypt(padded_text) # 应用加密 return b64encode(ciphertext).decode('utf-8') # 返回字符串&gt;# 网站源码的function b(a,b)加密函数&gt;def b(a, b): c = b d = '0102030405060708' e = a f = encrypt_aes(e, c, d) return f &gt;d_json = json.dumps(d)&gt;encText = b(d_json, g)&gt;encText = b(encText, i) 至此便解析了所有加密函数的内容，将获得的encText和encSecKey填入前面提到的params中和encSecKey中： 123456# 请求评论的url地址及发送的请求数据，空串为我们后面需要破解然后填入的位置url = \"https://music.163.com/weapi/comment/resource/comments/get?csrf_token=\"data = { 'params': encText 'encSecKey': encSecKey} 五、完整代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687import jsonimport randomimport requests# 实现AES加密需要的三个模块from Crypto.Cipher import AES # AES加密from Crypto.Util.Padding import padfrom base64 import b64encode# 网站为随机生成，这里设置成固定值def a(a): b = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\" c = \"\" for d in range(a): e = random.randint(0, len(b) - 1) c += b[e] return c# AES-CBC加密def encrypt_aes(text, key, iv): cipher = AES.new(key.encode('utf-8'), AES.MODE_CBC, iv.encode('utf-8')) # 设置密钥和初始化向量 padded_text = pad(text.encode('utf-8'), AES.block_size) # 设置加密文本 ciphertext = cipher.encrypt(padded_text) # 应用加密 return b64encode(ciphertext).decode('utf-8') # 返回字符串# 网站源码的function b(a,b)加密函数def b(a, b): c = b d = '0102030405060708' e = a f = encrypt_aes(e, c, d) return fif __name__ == '__main__': i = \"P5rcbOIWOpY8YqGq\" # d需要转为json字符串 # i0x d = { \"csrf_token\": \"c5ab7625a12cbf8010af4c1df61b0f6a\", \"cursor\": \"-1\", \"offset\": \"0\", \"orderType\": \"1\", \"pageNo\": \"1\", \"pageSize\": \"20\", \"rid\": \"R_SO_4_34723470\", # 不同歌曲编号 \"threadId\": \"R_SO_4_34723470\", # 不同歌曲编号 } # bse6Y([\"流泪\", \"强\"]) e = \"010001\" # bse6Y(Qu1x.md) f = \"00e0b509f6259df8642dbc35662901477df22677ec152b5ff68ace615bb7b725152b3ab17a876aea8a5aa76d2e417629ec4ee341f56135fccf695280104e0312ecbda92557c93870114af6c9d05c4f7f0c3685b7a46bee255932575cce10b424d813cfe4875d3e82047b97ddef52741d546b8e289dc6935b3ece0462db0a22b8e7\" # bse6Y([\"爱心\", \"女孩\", \"惊恐\", \"大笑\"]) g = \"0CoJUm6Qyw8W8jud\" d_json = json.dumps(d) encText = b(d_json, g) encText = b(encText, i) url = 'https://music.163.com/weapi/comment/resource/comments/get?csrf_token=' encSecKey = \"7b3a12df898a7eaf2f0fc1adf83ddb305f0ee4563c0a7cbdad70ecf9c8118f76a211dba2218339cc28bb9647ea3f0f591dae07051b3956f2af8b15111532ccf94fcd3d106f19594e7bddec1002d695aaf00fdd886519e8df24bb044be1d5b868efc2feba0bc7bb19f1b456e5ee2a6098559c993fc3b45c3a022b660cdb065acf\" header = { \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\" } data = { 'params': encText, 'encSecKey': encSecKey } # print(encText) # print(encSecKey) res = requests.post(url, headers=header, data=data) print(res.text) res_json = res.json() with open('东京不太热评论.json', 'w', encoding='utf-8') as f: json.dump(res.json(), f, ensure_ascii=False, indent=4) comments_list = res_json['data']['comments'] for comment in comments_list: print(comment['content']) 爬取成功 保存为json文件","categories":[{"name":"学习","slug":"学习","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"爬虫","slug":"学习/爬虫","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/%E7%88%AC%E8%99%AB/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://dekelkai.github.io/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://dekelkai.github.io/tags/%E7%88%AC%E8%99%AB/"}],"author":"Dekel"},{"title":"😄win11获取系统管理员权限方法😄","slug":"win11获取系统管理员权限方法","date":"2024-12-30T12:59:04.000Z","updated":"2025-09-17T08:46:49.002Z","comments":true,"path":"2024/12/30/win11获取系统管理员权限方法/","permalink":"https://dekelkai.github.io/2024/12/30/win11%E8%8E%B7%E5%8F%96%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%91%98%E6%9D%83%E9%99%90%E6%96%B9%E6%B3%95/","excerpt":"","text":"Win11获取系统管理员权限 1.win+R 打开运行，输入gpedit.msc然后回车。 2.如果显示没有gpedit.msc，以cmd后缀，管理员权限，运行下面代码脚本，然后执行第一步。 1234567891011@echo offpushd \"%~dp0\"dir /b C:\\Windows\\servicing\\Packages\\Microsoft-Windows-GroupPolicy-ClientExtensions-Package~3*.mum &gt;List.txtdir /b C:\\Windows\\servicing\\Packages\\Microsoft-Windows-GroupPolicy-ClientTools-Package~3*.mum &gt;&gt;List.txtfor /f %%i in ('findstr /i . List.txt 2^&gt;nul') do dism /online /norestart /add-package:\"C:\\Windows\\servicing\\Packages\\%%i\"pause 3.打开gpedit.msc，跳转到本地组策略编辑器。 在组策略编辑器中依次进入“计算机配置—&gt;Windows设置—&gt;安全设置—&gt;本地策略—&gt;安全选项”。 5.进入安全选项后双击右侧的“管理员账户状态”。 6.在管理员账户状态中，勾选“已启用”，再点击下方“确定”保存即可获得管理员权限。 (新增)7.在安全设置 的下面 ，展开 本地策略 --&gt; 安全选项 ，在右边找到 用户帐户控制：以管理员批准模式运行所有管理员 ，双击它，将 本地安全设置 更改为 已禁用 。 成功！","categories":[{"name":"Tips","slug":"Tips","permalink":"https://dekelkai.github.io/categories/Tips/"}],"tags":[{"name":"教程","slug":"教程","permalink":"https://dekelkai.github.io/tags/%E6%95%99%E7%A8%8B/"}],"author":"Dekel"},{"title":"印章识别系统","slug":"印章识别系统","date":"2024-12-28T12:43:53.000Z","updated":"2025-09-17T08:48:35.689Z","comments":true,"path":"2024/12/28/印章识别系统/","permalink":"https://dekelkai.github.io/2024/12/28/%E5%8D%B0%E7%AB%A0%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"印章识别系统demo demo做了一些实验，一些图片不能够识别出来文字，或者由于ORC的原因文字识别效果不好，但是圆形切割的效果还挺可以。 看了RCNN的原始论文。 用MaskRCNN的源码对已有的奖状手动打标训练40个了一下，效果不太好。 这个是用霍夫圆变换截取 用sqlite3实现了可以添加字段功能 下面这个是用MaskRCNN预测的，极少数能检测到，有些检测不出来 能打标的样本太少了，训练和测试效果完全不好 这是用maskRCNN预测的，训练了40个，但是后面又想到应该用下面这种打标","categories":[{"name":"目标检测","slug":"目标检测","permalink":"https://dekelkai.github.io/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"}],"tags":[],"author":"Dekel"},{"title":"各数据结构结构体定义","slug":"各数据结构结构体定义","date":"2024-12-04T14:16:11.000Z","updated":"2025-01-18T07:05:49.356Z","comments":true,"path":"2024/12/04/各数据结构结构体定义/","permalink":"https://dekelkai.github.io/2024/12/04/%E5%90%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%BB%93%E6%9E%84%E4%BD%93%E5%AE%9A%E4%B9%89/","excerpt":"","text":"线性表 123456789101112131415161718192021222324252627//静态顺序表int MaxSize = 10;typedef struct{ ElemType data[MaxSize]; int length; }SqList;//动态顺序表int InitSize;typedef struct{ ElemType* data; int MaxSize; int length; }SeqList;//单链表typedef struct LNode{ ElemType data; struct LNode *next;}LNode, *LinkList;//双向链表typedef struct DNode{ ElemType data; struct DNode *prior, *next;}DNode, *DLinkList; 栈 12345typedef struct { SElemType *base; SElemType *top; int stacksize;}SqStack; 队列 1234567891011#define MAXQSIZE 100typedef struct QNode{ QElemType data; struct QNode *next;}QNode, *QueuePtr;typedef struct{ QueuePtr front; Queueptr rear;}LinkQueue; 串 12345#define MAXLEN 255typedef struct{ char ch[MAXSIZE+1]; int length;}SString; 数组 1234typedef struct { int *data; int length;}Array; 树 1234typedef struct TNode{ int data; struct TNode *left, *right;}TNode; 二叉树 1234typedef struct BiTNode{ int data; struct BiTNode *lchide, *rchild;}BiTNode, *BiTree; 图（邻接表存储） 12345678910111213141516171819#define MaxVertexNum 100//边表结点typedef struct ArcNode{ int adjvex; //该边所指向的顶点 struct ArcNode *nextarc; //下一条边 // InfoType *info;}ArcNode;//定点表结点typedef struct VNode{ VertexType data; //顶点信息 ArcNode *firstarc; //指向第一条边表结点}VNode, AdjList[MaxVertexNum];typedef struct{ AdjList vertices; //邻接表头节点 int vexnum,arcnum;}ALGraph; 图（邻接矩阵）MGraph 12345678910111213141516#define INFINITY INT_MAX#define MAX_VERTEX_NUM 20typedef enum {DG, DN, UDG, UDN} GraphKind; //{有向图,有向网,无向图,无向网}typedef struct ArcCell{ VRType adj; //无权图0，1；带权图 权值 InfoType *info;}ArcCell, AdjMatrix[MAX_VERTEX_NUM][MAX_VERTEX_NUM];typedef struct{ VertexType vex[MAX_VERTEX_NUM]; //顶点集合 AdjMatrix arcs; //邻接矩阵 int vexnum,arcnum; // 图的定点数和边数 GraphKind kind; //图的类型}MGraph;","categories":[],"tags":[],"author":"Dekel"},{"title":"Hexo博客备份和恢复","slug":"Hexo博客备份和恢复","date":"2024-07-23T07:25:31.000Z","updated":"2025-01-18T07:05:49.354Z","comments":true,"path":"2024/07/23/Hexo博客备份和恢复/","permalink":"https://dekelkai.github.io/2024/07/23/Hexo%E5%8D%9A%E5%AE%A2%E5%A4%87%E4%BB%BD%E5%92%8C%E6%81%A2%E5%A4%8D/","excerpt":"","text":"一、备份博客 必须要备份的文件： scaffolds 文章模板，需要备份 source 文章和页面等文件，需要备份 themes 若有主题，需要备份，我是用npm安装的volantis主题，所以这里没有备份themes，而是将node_models里的主题文件备份 _config.yml 用户配置信息文件，需要备份 _config.volantis.config 主题配置信息文件，做了修改并放在了根目录，需要备份 package.json 模块列表，需要备份 package-lock.json 锁定安装时的包的版本号 不必备份的文件和目录： node_modules 安装的模块 public 产生的静态网页文件 db.json 网页文件静态数据，编译时自动生成 备份到GitHub 1、在github或gitee创建一个仓库Hexo存放备份信息 2、在博客根目录下创建文件.gitignore，添加以下内容，表示不备份的文件信息 12345678.DS_StoreThumbs.dbdb.json*.logthemes/node_modules/public/.deploy*/ 3、备份到github上的仓库Hexo 12345git initgit add *git commit -m \"$(date): Hexo backup\"git remote add origin https://github.com/username/Hexo.gitgit push -u origin main 注：若提示error: remote origin already exists.，就先执行git remote rm origin后在执行上述代码。 二、恢复博客 安装对应环境 1、git、nodejs等，可在hexo主题官网查看安装方法和版本信息。 2、pandoc（支持LateX渲染，参考\"使Hexo博客页面能够渲染LaTeX\"） 配置git与github 1、打开gitbash，输入以下命令 12git config --global user.name \"XXXX\" 用户名标识 ---- 实际也可以填写您的github仓库的名称git config --global user.email \"xxxx@xxx.com\" 邮箱标识 -------可以填写github仓库的邮箱 注：git config --global “参数\"，有了这个参数，表示你这台机器上所有的Git仓库都会使用这个配置，当然你也可以对某个仓库指定的不同的用户名和邮箱。 2、创建SSH Key 1ssh-keygen -t rsa //--创建秘钥 在c盘用户目录下找到.ssh，里面有2个文件一个是公钥 一个是私钥，用记事本打开公钥复制里面的内容到github进行配置。 3、测试链接 1ssh -T git@github.com 出现hello表示成功 克隆到本地 创建一个文件存放博客，在文件中使用以下命令克隆文件 1git clone https://github.com/Dekelkai/Hexo.git 恢复博客 123npm install hexo-clinpm installnpm install hexo-deployer-git 注：由于volantis模块改了静态页面的代码，所以要将新加载的主题模块替换为备份的volantis主题模块。 重新启动博客三连 1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d","categories":[],"tags":[{"name":"Blog","slug":"Blog","permalink":"https://dekelkai.github.io/tags/Blog/"}],"author":"Dekel"},{"title":"大数据系统实验课程","slug":"大数据系统实验课程","date":"2024-06-24T02:13:28.000Z","updated":"2025-01-18T07:05:49.356Z","comments":true,"path":"2024/06/24/大数据系统实验课程/","permalink":"https://dekelkai.github.io/2024/06/24/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F%E5%AE%9E%E9%AA%8C%E8%AF%BE%E7%A8%8B/","excerpt":"","text":"一、实验准备 1、导入虚拟机及开启大数据平台 使用提供的ovf导入虚拟机镜像，用mobaXterm连接虚拟机，打开镜像中的大数据平台文件（hadoop-docker-centos7），在docker-compose.yml中添加端口映射“5000:5000”： 执行./start-hadoop-images.sh启动大数据平台，主机名称变更为hbase-master。执行yarn node –list查看其他三个节点（hbase-slave1、hbase-slave2、 hbase-slave3）： 在容器hbase-master中执行jps发现无HMaster进行，然后再执行start-hbase.sh，有则不执行启动hbase的脚本： 退出大数据平台：退出大数据平台主节点，容器hbase-master中执行exit。 关闭大数据平台：关闭大数据平台，虚拟机操作系统中执行./stop-hadoop-images.sh。 关闭虚拟机，虚拟机操作系统中执行shutdown -h now 2、环境检测 大数据平台目前包括的组件有：HDFS、MapRedcue、Yarn、Spark、Scala、HBase、Hive、Zookeeper、Sqoop、 Phoenix、 Python3、 Azkaban、 Kafka、 Sbt、JDK；用于存储元数据数据库为mysql，root账户密码为hadoop。 其中软件版本为：Hadoop: 2.7.2、Spark: 2.1.0、Scala: 2.11.8、HBase: 1.2.5、JDK: openjdk 1.8.0_111、Hive: 2.1.1、Zookeeper: 3.4.10、Sqoop: 1.4.7、Phoenix: 4.14.1-HBase-1.2、Python3: 3.6.0、Azkaban: 3.24.0、Sbt: 1.4.6、Kafka: 2.11-0.10.2.1、MySQL: 5.7。 HDFS 进入大数据平台后再命令行输入jps，出现NameNode和SecondaryNameNode进程。 使用命令hdfs dfsadmin -report查看各个节点的当前状态。 MapReduce 使用一个wordcount程序来进行单词计数，判断MapReduce运行是否正常。 进入/code/tests/mapreduce-test/，创建一个words.txt，输入一些单词： 使用hdfs dfs -put words.txt /tmp/上传至hdfs： 使用hadoop jar wordcount.jar /tmp/words.txt /tmp/wordcount执行程序： 结果被保存在hdfs中，使用hdfs dfs -cat /tmp/wordcount/*查询结果： yarn hive 注意：在执行 hive中表和表之间数据导入导出时，需要调用 MapReduce者 Spark，如果直接退出hive，有可能是设置spark计算引擎问题，请设置计算引擎为 MapReduce：set hive.execution.engine=mr。 Hbase 使用hbase shell： spark 使用spark-shell： zookeeper 查看docker中的所有容器： 进入zoo1节点,命令docker-compose exec zoo1 bash： 查看Zookeeper服务状态，命令zkServer.sh status： ​ 节点是follower角色，正常启动。 启动Zookeeper客户端，命令zkCli.sh： 查询hbase在zookeeper服务中注册的RegionServer服务器信息，命令ls2 /hbase/rs： sbt打包 使用sbt对编译好的scala程序进行打包，直接使用镜像中配置好的sbt进行打包，命令/usr/local/sbt/sbt package： 查看生成的目标文件，在target/scala-&lt;version&gt;中： 使用spark提交jar包，命令spark-submit --class \"SimpleApp\" /root/sparkapp/target/scala-2.11/simple-project_2.11-1.0.jar： Azkaban 启动 进程中没有AzkabanSingleServer，先启动azkaban. 进入/root/azkaban-solo-server/，执行bin/azkaban-solo-start.sh: 在windows中访问azkaban图形化界面，虚拟机ip:8081，用户配置文件在conf/azkaban-users.xml： kafka 启动kafka，创建一个主题test，查看主题信息，利用kafka提供的命令行工具kafka-console-producer.sh，给kafka集群发送消息，利用kafka-console-consumer.sh接收消息。 kafka启动命令位置 启动kafka服务，命令bin/kafka-server-start.sh config/server.properties: hbase-master的kafka进程： 四个节点的kafka的config/server.properties和/tmp/kafka-logs/meta.properties配置文件id： 启动各节点的kafka服务： 创建test主题，命令bin/kafka-topics.sh --zookeeper zoo1:2181 --create --replication-factor 4 --partitions 1 --topic testTxk： 当前实验在4个节点上都打开了，因此factor 数量为 4。 测试发送消息，命令bin/kafka-console-producer.sh --broker-list hbase-master:9092 --topic testTxk： 测试接收消息，命令bin/kafka-console-consumer.sh --bootsrap-server hbase-master:9092 --topic testTxk --from-beginning: Phoenix 集成 HBase 先启动Master，命令start-hbase.sh sqlline.py位置： 到目录下执行sqlline.py： 执行!tables： 3、总结 主要进行了虚拟机的导入安装，对后续需要使用到的工具进行了简单配置，检测和熟悉，为后续实验奠定了基础。 二、大数据批处理系统 0、前言 淘宝双11大数据批处理分析系统，对数据进行分析与预测，涉及数据预处理、存储、查询和可视化分析等数据处理流程及操作，包含Linux、Mysql、Hadoop、Hive、Sqoop、ECharts、Spark等软件的安装和使用方法。 1、数据准备 数据通过MobaXterm上传到原虚拟机 上传到hbase-master中，命令docker cp /tmp/dataset/user_log.csv hbase-master:/home/dbtaobao/dataset；查看前十条数据head -10 user_log.csv： 2、数据预处理 第一行都是字段名称，在导入Hive时不需要，将其删除： 数据集过大，取前20000条数据作为小数据集smalluserlog.csv。建立一个脚本完成截取任务： 导入Hive数据仓库，先在hdfs中创建一个存放数据的dataset文件夹，然后把small_user_log.csv数据上传hdfs。 3、启动并配置MySQL 进入mysql镜像节点测试： 修改mysql配置文件： 先停止docker容器./stop-hadoop-image，然后启动./start-hadoop-image，进入mysqldocker-compose exec mysql bash，重启mysql服务service mysql restart，自动退出mysql，重启mysql容器docker restart mysql。 4、Hive的简单使用 内部表：也叫管理表表⽬录会创建在集群上的{hive.metastore.warehouse.dir}下的相应的库对应的⽬录中。默认创建的表就是内部表。 外部表：外部表需要使⽤关键字\"external\"，外部表会根据创建表时LOCATION指定的路径来创建⽬录， 如果没有指定LOCATION，则位置跟内部表相同,⼀般使⽤的是第三⽅提供的或者公⽤的数据。建表语法（必须指定关键字external） create external table tableName(id int,name string) [location 'path']; 建立dbtaobao数据库： 创建外部表user_log，查询结果： 操作hive 执行如下命令： 结果如下： 利用Hive进行数据分析与处理 简单查询分析： ​ 查询条数统计分析： ​ 不重复数据查询： 5、Hive的数据处理和分析 男女买家交易对比 男女买家各个年龄段交易对比： 获取销量前五的商品类别： 各个省份的的总成交量对比： 6、从hive导入数据到mysql 在mysql中创建5个新表，设置编码为utf-8： 123456789101112131415CREATE TABLE `dbtaobao`.`result1` (`action` varchar(6),`num` varchar(20)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `dbtaobao`.`result2` (`gender` varchar(6),`num` varchar(20)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `dbtaobao`.`result3` (`gender` varchar(6),`age_range` varchar(20),`num` varchar(20)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `dbtaobao`.`result4` (`cat_id` varchar(20),`num` varchar(20)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `dbtaobao`.`result5` (`province` varchar(10),`num` varchar(20)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 进入master节点中使用sqoop将hive中相关数据导入mysql，5条语句分别对应5个表格： 12345678910sqoop export --connect jdbc:mysql://mysql:3306/dbtaobao --username root --password hadoop --table result1 --export-dir '/user/hive/warehouse/dbtaobao.db/result1' --fields-terminated-by ','sqoop export --connect jdbc:mysql://mysql:3306/dbtaobao --username root --password hadoop --table result2 --export-dir '/user/hive/warehouse/dbtaobao.db/result2' --fields-terminated-by ','sqoop export --connect jdbc:mysql://mysql:3306/dbtaobao --username root --password hadoop --table result3 --export-dir '/user/hive/warehouse/dbtaobao.db/result3' --fields-terminated-by ','sqoop export --connect jdbc:mysql://mysql:3306/dbtaobao --username root --password hadoop --table result4 --export-dir '/user/hive/warehouse/dbtaobao.db/result4' --fields-terminated-by ','sqoop export --connect jdbc:mysql://mysql:3306/dbtaobao --username root --password hadoop --table result5 --export-dir '/user/hive/warehouse/dbtaobao.db/result5' --fields-terminated-by ', 7、idea+Tomcat+ECharts展示数据 创建webapp项目然后导入mysql依赖 配置tomcat服务 修改mysql的IP地址，添加相应的jsp，js和css代码 运行效果展示 8、总结 主要是在mysql配置utf8时遇到容器崩溃，mysql节点被破环进入不了，最后将docker全部格式化，重新处理数据和配置其他环境。 hive中，在需要调用MapReduce或spark的任务中，需要设置引擎：set hive.execution.engine=mr； 三、大数据查询分析计算系统 0、前言 NBA 统计大数据查询分析计算系统，涉及虚拟机镜像的导入、linux 系统的使用、hbase 的使用、phoenix 的使用，以及 python 调用 hbase 的 api、scala 调用 spark 的 api，搭建 flask 程序。 1、HBase创建表 进入 hbabse shell 执行create 'team_season','cf1'创建表，设置表名和列族名： 2、编写python脚本批量导入数据至hbase中 退出hbase后，新建文件夹/home/NBA/，在里面新建python文件tohbase.py： 将数据集team_season.csv数据上传到虚拟机中： 传输命令： 数据展示： 执行 hbase-daemon.sh start thrift 让程序能够连接到 hbase，并检查9090端口是否可用： 安装 happybase和pandas： 123456# 由于要用到 happybase，pandas 包。需要安装# 需要安装 happybasepip3 install happybase# 安装 pandaspip3 install pandas 执行之前编写的 python 脚本文件,导入数据，python3 tohbase.py 执行.py 文件： 进入 hbase shell，用 scan 扫描表显示： 3、phoenix 建立与 hbase 相映射的表 执行 sqlline.py 启动 phoenix，使用!tables命令查看表： 在phoenix中创建映射的表，再用!tables查看表： 然后就可以使用sql语句进行，Phoenix 是一个 SQL 层，用于与 HBase 进行交互，提供了 JDBC 驱动程序和兼容 ANSI SQL 的查询接口。它使得开发者可以用熟悉的 SQL 语言来查询 HBase 中的数据： 4、搭建Flask 安装virtualenv，创建一个独立的python环境myapp： 1pip3 install virtualenv 进入虚拟环境，安装flask： 123cd myapp/binsource activatepip install flask 测试flask： 在 myapp 虚拟环境下安装 phoenixdb 1pip install phoenixdb==0.7 启动queryserver服务 在虚拟环境myapp中测试phoenixdb 连接是否正常 1234567import phoenixdbimport phoenixdb.cursordatabase_url = 'http://localhost:8765/'conn = phoenixdb.connect(database_url, autocommit=True)cursor = conn.cursor() cursor.execute('SELECT * FROM \"team_season\" limit 10')print (cursor.fetchall()) 5、编写程序分析和展示数据 使用flask框架展示数据： 创建一个python文件main.py： 在同级目录下创建 templates 文件夹，编写存放 myindex.html： 运行结果： 6、总结 flask版本问题、安装virtualenv超时，HMaster进程 四、 大数据流计算系统 0、前言 涉及数据预处理、消息队列发送和接收消息、数据实时处理、数据实时推送和实时展示等数据 处理全流程所涉及的各种典型操作， 涵盖 Linux 、Spark 、Kafka 、Flask 、Flask-SocketIO 、Highcharts.js、sockert.io.js、PyCharm 等系统和软件的安装和使用方法。 1、数据处理 数据预处理 上传数据到虚拟机中： 安装相应的python库： 编写kafka代码测试生产者和消费者： 测试结果： 2、scala编程实现实时数据处理 下载spark-streaming-kafka的jar包，并配置环境jar的位置： 1wget http://search.maven.org/maven2/org/apache/spark/spark-streaming-kafka-0-8_2.11/2.1.0/spark-streaming-kafka-0-8_2.11-2.1.0.jar 在文件夹 kafka_spark_code中建立文件夹 kafka,进入 kafka 文件夹依次建立 src/main/scala 文件存放目录以及 scala 工程文件，项目工程主文件 KafkaTest.scala，设置日志文件为 StreamingExamples.scala： StreamingExamples.scala代码： KafkaWordCount.scala程序代码 编写打包配置文件simple.sbt： 3、运行kafka项目 编译打包程序： 1/usr/local/sbt/sbt package 编写运行脚本，编写运行脚本，在/usr/local/spark/mycode/kafka 目录下新建 startup.sh 文件，输入以下内容，是一行，并给予脚本执行权限： 1/root/spark/bin/spark-submit --driver-class-path /root/spark/jars/*:/root/spark/jars/kafka/* --class \"org.apache.spark.examples.streaming.KafkaWordCount\" /home/charpter03/kafka_spark_code/kafka/target/scala-2.11/simple-project_2.11-1.0.jar zoo1:2181 1 sex 1 修改获得运行权限： 测试程序 修改consumer.py文件的主题： 启动kafka服务，然后分别运行startup.sh、producer.py、consumer.py文件，查看结果： 4、数据展示处理 利用 Flask 创建 web 程序，利用 Flask-SocketIO 实现实时推送数据，利用 socket.io.js 实现 实时接收数据，hightlights.js 展现数据。 1234环境版本：pip3 install Flask-SocketIO==4.3.1pip3 install python-engineio==3.13.2pip3 install python-socketio==4.6.0 Flask-SocketIO实时推送数据 Spark Streaming 实时接收 Kafka 中 topic 为“sex”发送的日志数据，然后 Spark Streaming 进行实时处理，统计好每秒中男女生购物人数之后，将结果发送至 Kafka，topic 为“result”。下面是项目文件层级： app.py：作为一个简易的服务器，处理连接请求，以 及处理从kafka 接收的数据，并实时推送到浏览器。 background_thread 函数，该函数从 Kafka 接收消息，并进行处理，获得男女生每秒钟人数，然后将结果通过函数 socketio.emit实时推送至浏览器。 浏览器获取数据并展示 在app.py路径下创建templates/index.html，其负责获取数据并展示效果。 该部分就是使用 socket.io.js 库来实时地接收服务端发送过来的消息，并将消息数据实时地设置在 html 标签内，交给 highcharts.js 进行实时获取和展示。如果出现引擎版本不匹配的错误，可以固定下 python 几个包的版本： pip3 install Flask-SocketIO==4.3.1 pip3 install python-engineio==3.13.2 pip3 install python-socketio==4.6.0 js依赖： 123456&gt;&lt;script crossorigin=\"anonymous\" integrity=\"sha512-TFZqlmDYmi29UdRJTJblfxNrsSgtabj2vxvIqAvsAO2I8//OaBTMfxa8ghzuHQ58hViU5k125Cp00vh9GVgWIg==\" src=\"https://lib.baomitu.com/socket.io/2.5.0/socket.io.min.js\"&gt;&lt;/script&gt;&gt;&lt;script src=\"https://cdn.bootcdn.net/ajax/libs/jquery/3.5.1/jquery.js\"&gt;&lt;/script&gt;&gt;&lt;script src=\"https://code.highcharts.com/highcharts.src.js\"&gt;&lt;/script&gt;&gt;&lt;script src=\"http://code.highcharts.com/modules/exporting.js\"&gt;&lt;/script&gt; 代码如下 效果展示 启动步骤: 确保 kafka 开启（jps 观察进程是否启动）； 开启 producer.py 模拟数据流（python3 producer.py）; 启动 Spark Streaming 实时处理数据（scala 版运行 stratup.sh）。 启动 app.py 5、总结 1、主题列表： 2、整个数据的传输过程： 3、socket.io.js，exporting.js版本问题包 4、并发问题 五、大数据图计算系统 0、前言 用 GraphX 分析网络结构，涉及获取数据、解析数据、分析主要主题以及伴生关系、建立伴生网络、理解网络结构、过滤噪声边、计算聚类系数和平均路径长度等数据处理过程，涵盖 Linux、MySQL、Hadoop、HDFS、Spark、Scala、Flask、Python、Echarts 等系统和软件的应用。 1、获取实验数据 注：原始数据量较多，但由于本实验镜像虚拟的分布式集群内存只有 7.5G,启动Hadoop 平台就要占用大量内存资源，该实验最后一部分计算节点之间的平均路径需要消耗非常多的内存资源，不足以计算出结果，考虑到单机现有的内存条件，所以本实验采取相对合适节点数量的数据集，数据量为 480，足以完成整个实验流程及学习内容的要求。 1、先将数据通过MobaXterm上传到虚拟机中，然后通过命令docker cp /tmp/dataset/chapter04/. hbase-master:/home/chapter04/dataset/上传到hbase-master节点上： 2、创建数据库 graph，为后面可视化展示做准备： 3、查看 namenode，datanode 是否正常启动，HRegionServer 跟 hbase 相关，没有的话直接启动： 4、在hdfs创建medline文件夹，并将medsamp2016a.xml加载到该文件夹下： 123hdfs dfs -mkdir /medlinehdfs dfs -put medsamp2016a.xml /medline/hdfs dfs -put ch07-graph-2.0.0-jar-with-dependencies.jar /medline/ 5、spark-shell --jars ch07-graph-2.0.0-jar-with-dependencies.jar启动spark： 6、把 xml 格式的 medline 数据读到 Spark shell 中： 7、用 Scala XML 工具解析 XML 文档，变量elem 是scala.xml.Elem 类的实例，Scala 用scala.xml.Elem 类表示XML 文档中的一个节点，该类内置了查询节点信息和节点内容的函数。Cache函将解析结果缓存起来： 2、分析网络主要主题及其伴生关系 FlatMap 获取数据集标签后，我们需要知道数据集中标签的总体分布情况，为此我们需要使用 SparkSQL 计算一些基本统计量，比如记录条数和主要主题出现频率的直方图，并将统计结果保存到 mysql，用于可视化展示： 记录下登录时的 ip： 上面的数据给出了一个大致的描述，包括一共有多少个主题，最频繁的主题等。可以看到，我们的数据一共有 480 个文档，最频繁出现的 topic（Disease）只占了很少一部分（25/480= 5%）。对此，我们猜测包含某个主题的文档的个数的总体分布可能为长尾形态： 要得到伴生关系，我们要为这些字符串列表生成一个二元组集合。对此我们可以使用 Scala 集合工具包里的 combinations 方法，它返回的是一个 Iterator： 查看一下数据中最常出现的伴生二元组，将数据存入 mysql： 以上并未提供特别有用的信息，最常见的伴生二元组与最常见的topic非常相关。除此之外，也没有提供什么额外的信息。 3、用 GraphX 来建立一个伴生网络 实验的核心在于把伴生网络当作网络来分析：把主题当作图的顶点，把连接两个主题的引用记录看成两个相应顶点之间的边。这样就可以计算以网络为中心的统计量。GraphX 构建与 Spark 之上，它继承了 Spark 在可扩展性方面的所有特性，这就意味着可以利用 GraphX 对规模极其庞大的图进行分析。 在Medline数据上运行该散列函数可以得到一个DataFrame，以它为基础就可以得到伴生关系图的顶点集合： 用前一节中得到的伴生频率计数来生成图的边，方法是使用hash 函数将每个主题映射到相应的顶点ID： 把顶点和边都创建好后，就可以创建Graph 实例了。我们需要将Graph 缓存起来，这样便于后续处理时使用： 4、理解网络结构 1、连通组件 最基本的属性之一就是是否是连通图。如果图是非连通的，那么可以将图划分成一组更小的子图，这样就可以分别对每个子图进行研究。连通性是图的基本属性，通过调用 GraphX 的 connectedComponents 方法获取： 大连通组件的主题名称： 查看最初的主题分布，是否有类似 Visual 的主题： 2、度的分布 为了更多了解图的结构信息，我们需要知道每个顶点的度，也就是每个顶点所属边的条数。GraphX 中我们可以通过在 Graph 对象上调用 degrees 方法得到每个顶点的度。degrees 方法返回一个整数的 VertexRDD，其中每个整数代表一个顶点的度。现在我们计算一下图的度，然后可以查看到度数较高的主题，并将数据存入 mysql： 5、过滤噪声边 在当前的伴生关系中，边的权重是基于一对概念同时出现在一篇论文中的频率来计算的。这种简单的权重机制的问题在于：它并没有对一对概念同时出现的原因加以区分，有时一对概念同时出现是由于它们具有某种值得我们关注的语义关系，但有时一对概念同时出现只是因为都频繁地出现在所有文档中，同时出现只是碰巧而已，因此需要对噪声边进行处理，这里采用卡方准则。 1、处理 EdgeTriplet 计算卡方统计量，需要组合顶点数据（比如每个概念在一个文档中出现的次数）和边数据（比如两个概念同时出现在一个文档中的次数）： 用该方法通过 mapTriplets 算子转换边的值。mapTriplets 算子返回一个新图，这个图的边的属性就是每个伴生对的卡方统计量。于是我们就可以大概知道该统计量在所有边上的分布情况： 使用 19.5 作为阈值，这样过滤后图中就只剩下那些置信度非常高的有意义的伴生关系。我们将在图上利用 subgraph 方法进行过滤，这个方法接受 EdgeTriplet 的一个布尔函数，用以判断子图应该包含哪些边： 2、分析去掉噪声边的子图 在过滤后的子图上运行连通性算法，检查组件个数和组件大小： 发现连通组件总数发生改变，且最大连通组件也被瓦解，说明该数据集有较多的噪声干扰。如果数据量较多，将会对最大连通组件产生较小的影响。检查一下过滤后的度分布： 看到过滤后平均值变小了，主要主题也产生变化，原因是数据集样本的噪声比较多。我们看一下过滤之后概念和度的关系： 结果表明虽说这次卡方过滤准则不太理想，问题在于使用数据集样本太小，如果用原始数据集，将会产生较好的结果；但是它在清楚对应普遍概念的边的同时，保留了代表概念之间有意义并且有值得注意的关系的那些边。 6、系和聚类系数 如果每个顶点都存在一条边与其他任何节点都相连，那这个图就是个完全图。给定一个图，可能有多个子图是完全图，我们可以将这些子图称为系，如果途中存在这种许多大型的系，表示这个图具有某种局部稠密结构。 三角形是一个完成图，顶点 V 的三角计数就是包含该顶点的三角形个数。三角计数度量了 V 有多少个邻接点是相互连接的。Watts 和 Strogatz 定义了一个新的指标，称为局部聚类系数，它是一个顶点的实际三角计数与其邻接点可能的三角级数的比率。对无向图来说，有 k 个邻接点和 t 个三角计数的顶点，其局部聚类系数 C 为： 用GraphX 来计算过滤后的概念图的每个节点的局部聚类系数。GraphX 有个内置方法triangleCount，它返回一个Graph 对象，其中VertexRDD 包含了每个顶点的三角计数。然后对所有顶点局部聚类系数取平均值，就得到网络平均聚类系数： 7、平均路径长度 用Pregel求两个节点之间的最短路径，这里我们会计算过滤之后的概念图中的大型连通组件节点的平均路径长度。计算图中顶点之间的路径长度是一个迭代过程，和我们之前寻找连通组件的迭代过程类似：每个阶段，每个顶点将保留它所接触过的顶点列表并记录到这些顶点的距离。接着每个顶点都向其邻接点查询它对应的节点列表，如果发现该列表中有新的顶点，就用新节点更新自己的节点列表；查询邻接点并更新自己节点列表的过程一直继续下去，直到所有节点都没有发现有新节点需要添加为止。 确定了顶点状态和消息内容的数据结构后，我们可以实现两个函数。第一个函数是 mergeMaps，用于将新消息中的信息合并到顶点状态之中。对我们讨论的问题来说，顶点状态和消息都是 Map[VertexId, Int] 类型的，因此需要把两个 map 中的内容合并在一起并将每个 VertexId 关联到两个 map 中该 VertexId 对应两个条目的最小值。 最后编写代码来构建发送给每个顶点的消息，依据是每次迭代是每个顶点从邻接点收到的消息： 在每个Pregel迭代过程中，对EdgeTriplet内部的src和dst顶点执行消息更新： 如果一次迭代中有任何顶点没收到消息，pregel’算法认为该顶点的运算已经完成并不再把它放在后续处理中。计算任意两个顶点之间的路径长度，使用 RDD 的sample 方法对所有 Vertexid 进行 2%的不重复采样，随机数生成器的随机种子采用 1729L： 计算样本路径长度直方图： 看到，样本的平均路径长度为 15.7，聚类系数为 0.625。 8、Echarts可视化展示 1、登录MySQL，查看mysql中是否有相关数据库和表： 2、数据可视化展示 结果展示： 使用flask框架搭建前端展示页面，文件目录结构： app.py： mysql.py： echarts.html代码： 9、总结","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://dekelkai.github.io/categories/bigdata/"}],"tags":[{"name":"bigdata","slug":"bigdata","permalink":"https://dekelkai.github.io/tags/bigdata/"}],"author":"Dekel"},{"title":"🙃Volantis主题配置评论区遇到的问题🙃","slug":"Volantis主题配置评论区遇到的问题","date":"2024-05-06T03:44:23.000Z","updated":"2025-01-18T07:05:49.355Z","comments":true,"path":"2024/05/06/Volantis主题配置评论区遇到的问题/","permalink":"https://dekelkai.github.io/2024/05/06/Volantis%E4%B8%BB%E9%A2%98%E9%85%8D%E7%BD%AE%E8%AF%84%E8%AE%BA%E5%8C%BA%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"In The Front 更换评论系统功能遇到问题了...先是看了网上对giscus的描述：借用GitHub来搭建评论区（免费啊hhh）。也是图方便，就照着网上各种教程在Volantis各个位置加东西。结果发现如果要评论还必须登录GitHub才行，虽然也能用，但是就感觉不舒服，后面发现了别家不用强制登陆的评论系统Twikoo。在我配置好twikoo后 问题就接踵而至了.... 官网提供的配置信息： 刷新页面出现了两个评论区（我写这篇博客的时候已经修好了。。。） 页面一直转圈圈加载中（，我也不需要请求他的服务了。。。） 1 检查Volantis配置文件 第一反应就是检查了Volantis的配置文件_config.volantis.yml中的Comments块，已经将服务调整为了twikoo。（甚至将下面giscus的配置信息部分全部注释了。。。） 并没有效果。 2 使用查找命令 使用命令findstr /s /i \"giscus\" *.*查找整个目录出现giscus的地方（可以看到这里已经被我注释掉了hhh）. 每个提交到github上的页面都有giscus.app/clint.js，我们在前端控制台看一下. 3 检查模板配置文件 在hexo-theme-volantis\\layout中发现post.ejs，page.ejs等文件，里面都引用了_partial/article. 打开该文件，发现又引用了../_plugins/comments/index.（到这里我感觉就很接近答案了hhh） 打开该index.ejs，找到了这串配置文件，把他注释掉即可. 弯路😅 在配置giscus时候官网也没有给出应该放到哪个位置，就在网上到处找，各个地方乱放。然而就是没仔细看_config.volantis.yml中的配置和giscus官网给的是对应的。","categories":[{"name":"博客搭建","slug":"博客搭建","permalink":"https://dekelkai.github.io/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"Twikoo","slug":"Twikoo","permalink":"https://dekelkai.github.io/tags/Twikoo/"},{"name":"评论功能","slug":"评论功能","permalink":"https://dekelkai.github.io/tags/%E8%AF%84%E8%AE%BA%E5%8A%9F%E8%83%BD/"},{"name":"Giscus","slug":"Giscus","permalink":"https://dekelkai.github.io/tags/Giscus/"}],"author":"Dekel"},{"title":"🐼Blog搭建-评论功能(使用MongoDB+netlify部署twikoo)🐼","slug":"Blog搭建-评论功能-使用MongoDB-netlify部署twikoo","date":"2024-04-30T12:20:13.000Z","updated":"2025-01-18T07:05:49.354Z","comments":true,"path":"2024/04/30/Blog搭建-评论功能-使用MongoDB-netlify部署twikoo/","permalink":"https://dekelkai.github.io/2024/04/30/Blog%E6%90%AD%E5%BB%BA-%E8%AF%84%E8%AE%BA%E5%8A%9F%E8%83%BD-%E4%BD%BF%E7%94%A8MongoDB-netlify%E9%83%A8%E7%BD%B2twikoo/","excerpt":"","text":"教育不是灌输，而是点燃火焰-----苏格拉底 In The Front 这里的博客是指的静态博客（Hexo、Hugo等） Netlify 免费等级（Functions Level 0）支持每月 125,000 请求次数和 100 小时函数计算时长 主要配置：MongoDB（数据库），Netlify （Deploy平台），博客网页（客户端/前端）。数据库负责储存数据，deploy平台来执行代码、将其变为app，最后连接到博客，从而在网页显示出来。所以必须按顺序操作，每一步都需要前一步得到的信息从而连接到一起。 1 为什么使用Twikoo？ 开源，免费，轻量无广告（吊打Disqus等一众评论服务） 匿名性好，不需要强制社交账号登录（重要‼️） 有新评论时可收到邮箱/即时消息通知 游客若留下邮箱，评论被回复时可收到邮件提醒（cusdis不支持） 数据支持导入导出 twikoo官网 2 MongoDB配置 申请MongoDB账号，然后登陆. 创建免费 MongoDB 数据库，区域推荐选择 AWS / N. Virginia (us-east-1). 在 Database Access 页面点击 Add New Database User 创建数据库用户，Authentication Method 选 Password，在 Password Authentication 下设置数据库用户名和密码，用户名和密码可包含数字和大小写字母，请勿包含特殊符号。点击 Database User Privileges 下方的 Add Built In Role，Select Role 选择 Atlas Admin，最后点击 Add User. 在 Network Access 页面点击 Add IP Address，Access List Entry 输入 0.0.0.0/0（允许所有 IP 地址的连接），点击 Confirm. 在 Database 页面点击 Connect，连接方式选择 Drivers，并记录数据库连接字符串，请将连接字符串中的 &lt;username&gt;:&lt;password&gt; 修改为刚刚创建的数据库 用户名:密码. 3 Netlify配置 创建netlify账号并申请一个Team. 打开twikoo项目： twikoojs/twikoo-netlify，点击 fork 将仓库 fork 到自己的账号下. 回到 Netlify，点击 Add new site - Import an existing project. 点击 Deploy with GitHub，如果未授权 GitHub 账号，先授权，然后选择前面 fork 的 twikoo-netlify 项目. 点击 Add environment variables - New variable，Key 输入 MONGODB_URI，Value 输入前面记录的数据库连接字符串，点击 Deploy twikoo-netlify，等待项目部署. 部署完成后，点击 Domain settings 可以看到云函数。 浏览器访问云函数链接，出现以下界面. 云函数地址（包含 https:// 前缀和 /.netlify/functions/twikoo 后缀，例如 https://xxx.netlify.app/.netlify/functions/twikoo）即为您的环境 id. 4 修改博客配置文件 打开Volantis主题的配置文件_config.volantis.yml，找到Comments模块. 修改service为twikoo. 找到下方twikoo部分，将刚才的云函数地址填写在envId处. 配置完成，hexo clean &amp;&amp; hexo g &amp;&amp; hexo s看看效果😄! Twikoo还拥有评论管理系统，在评论框的右下角齿轮，后面再探索吧。。。 参考文章 twikoo文档:云函数部署","categories":[{"name":"博客搭建","slug":"博客搭建","permalink":"https://dekelkai.github.io/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"Twikoo","slug":"Twikoo","permalink":"https://dekelkai.github.io/tags/Twikoo/"},{"name":"评论功能","slug":"评论功能","permalink":"https://dekelkai.github.io/tags/%E8%AF%84%E8%AE%BA%E5%8A%9F%E8%83%BD/"}],"author":"Dekel"},{"title":"➕使Hexo博客页面能够渲染LaTeX➕","slug":"使Hexo渲染LaTeX","date":"2024-04-30T11:43:03.000Z","updated":"2025-09-30T11:08:17.028Z","comments":true,"path":"2024/04/30/使Hexo渲染LaTeX/","permalink":"https://dekelkai.github.io/2024/04/30/%E4%BD%BFHexo%E6%B8%B2%E6%9F%93LaTeX/","excerpt":"","text":"一元二次方程：的两根为： 前言 Hexo没有自带LaTeX渲染，我们通过更换markdown渲染器使其能够渲染LaTeX。 注：需要本地安装好Pandoc。 卸载Marked渲染器 1npm un hexo-renderer-marked 安装 Pandoc 和 MathJax 12npm i hexo-renderer-pandocnpm i hexo-filter-mathjax 配置 Pandoc 和 MathJax 打开根目录下 _config.yml，添加如下配置： 1234567891011121314151617181920212223pandoc: extra: - no-highlight: extensions: - +abbreviations - +autolink_bare_uris - +emoji - +hard_line_breaks - -implicit_figures - +mark - +short_subsuperscriptsmathjax: tags: none # or 'ams' or 'all' single_dollars: true # enable single dollar signs as in-line math delimiters cjk_width: 0.9 # relative CJK char width normal_width: 0.6 # relative normal (monospace) width append_css: true # add CSS to pages rendered by MathJax every_page: true # if true, every page will be rendered by MathJax regardless the `mathjax` setting in Front-matter extension_options: {} # you can put your extension options here # see http://docs.mathjax.org/en/latest/options/input/tex.html#tex-extension-options for more detail ​ 配置好后就可以正常使用Latex了。 参考文章 Hexo 博客使用 LaTeX 使用 pandoc 正确渲染多行 MathJax 公式","categories":[{"name":"博客搭建","slug":"博客搭建","permalink":"https://dekelkai.github.io/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"LaTeX","slug":"LaTeX","permalink":"https://dekelkai.github.io/tags/LaTeX/"},{"name":"功能","slug":"功能","permalink":"https://dekelkai.github.io/tags/%E5%8A%9F%E8%83%BD/"}],"author":"Dekel"},{"title":"✔️LaTeX公式✔️","slug":"LaTeX公式","date":"2024-04-29T14:00:04.000Z","updated":"2025-01-18T07:05:49.354Z","comments":true,"path":"2024/04/29/LaTeX公式/","permalink":"https://dekelkai.github.io/2024/04/29/LaTeX%E5%85%AC%E5%BC%8F/","excerpt":"","text":"希腊字母表 绝对值符号 12% 使用\\lvert 和 \\rvert\\lvert C_{2} \\rvert 大小于符号 12345&gt;：\\textgreater&lt;： \\textless下面的后面要加空格，否则会识别错误&gt;=：\\geq 或 \\ge&lt;=：\\leq 或 \\le 属于符号 12属于：\\in不属于：\\notin 换行符 12...Typora中好像只有 \"\\\\\" 和 \"\\newline\" 这是第一行文本\\\\ 这是第二行文本，通过双反斜杠换行，但没有缩进。\\newline www 这是第一行文本这是第二行文本，通过双反斜杠换行，但没有缩进。 只是用换行符渲染到网页没有生效，使用\\begin{array}{}和\\end{array}嵌套可以让其生效。（字体会变小...参考下一条来进行调整） 字体大小 1234567891011121314151. 使用{\\huge [内容]}2. 使用 begin 和 end 如: \\begin{small} This part should be smaller then the rest of the document. \\end{small}3. 直接使用，在直接使用时，只能后面的文字有效。如 text1 \\huge text2，只对 text2 及其后面的内容有效.常用的命令： \\tiny：这是最小的字体大小，通常不建议在正文中使用。 \\scriptsize：比\\tiny稍大一些的字体大小。 \\footnotesize：这是默认的字体大小，适合大多数正文内容。 \\small：比默认字体小一些的字体大小。 \\normalsize：正常的字体大小，也是LaTeX的默认设置。 \\large：比正常字体大一些的字体大小。 \\Large：更大的字体大小，通常用于标题或重要信息。 \\LARGE：比\\Large更大的字体大小。 \\huge和\\Huge：这是最大的字体大小，非常适合用于强调或标题。","categories":[{"name":"学习","slug":"学习","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"LaTeX","slug":"LaTeX","permalink":"https://dekelkai.github.io/tags/LaTeX/"}],"author":"Dekel"},{"title":"🏳️‍🌈Volantis主题字体修改🏳️‍🌈","slug":"volantis主题字体修改","date":"2024-04-26T04:46:10.000Z","updated":"2025-01-18T07:05:49.355Z","comments":true,"path":"2024/04/26/volantis主题字体修改/","permalink":"https://dekelkai.github.io/2024/04/26/volantis%E4%B8%BB%E9%A2%98%E5%AD%97%E4%BD%93%E4%BF%AE%E6%94%B9/","excerpt":"","text":"只有流过血的手指，才能弹出世间的绝唱。-----泰戈尔 写在前面 volantis主题自带的字体看得疲倦了，记录下如何更改字体 ·本文以修改logo字体为例，以下是修改之前的字体。 0 找到配置文件_config.volantis.yml中字体配置的位置。 可以看到logo对应的字体配置为logofont，主要更改fontfamily、name和url字段。 fontfamily：定义了一组字体集合，按照从左到右的顺序尝试应用这些字体。如果无法加载第一 个会尝试后面的字体。 name:字体的名称，与 fontfamily 中的第一个字体对应。 url:字体文件的URL路径。这里使用GitHub+jsDelivr来创建字体链接。 1 字体下载 在网上下载自己心仪的字体文件，这里的格式为.ttf（不知道其他格式是否可以用）。 GitHub上找的一个英文字体：Pacifico。 2 上传GitHub仓库 将下载好的.ttf文件上传到自己的GitHub仓库中。 3 配置_config.volantis.yml文件 在配置文件中修改上文提到的3个属性。 注意url格式：https://cdn.jsdelivr.net/gh/github用户名/仓库名@分支名/字体路径。 4 成品展示 修改成了我们想要的字体。 参考资料 自定义字体“EB Garamond”配置不生效 Volantis文档 主题配置","categories":[{"name":"小技巧","slug":"小技巧","permalink":"https://dekelkai.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"字体","slug":"字体","permalink":"https://dekelkai.github.io/tags/%E5%AD%97%E4%BD%93/"},{"name":"主题","slug":"主题","permalink":"https://dekelkai.github.io/tags/%E4%B8%BB%E9%A2%98/"}],"author":"Dekel"},{"title":"🥸使用PicGo+Typora+Github+jsDelivr搭建图床，提高写作效率🥸","slug":"使用PicGo-Typora-Github-jsDelivr搭建图床-提高写作效率","date":"2024-04-25T12:42:06.000Z","updated":"2025-01-18T07:05:49.355Z","comments":true,"path":"2024/04/25/使用PicGo-Typora-Github-jsDelivr搭建图床-提高写作效率/","permalink":"https://dekelkai.github.io/2024/04/25/%E4%BD%BF%E7%94%A8PicGo-Typora-Github-jsDelivr%E6%90%AD%E5%BB%BA%E5%9B%BE%E5%BA%8A-%E6%8F%90%E9%AB%98%E5%86%99%E4%BD%9C%E6%95%88%E7%8E%87/","excerpt":"","text":"0 写在前面 当前大部分博客都采用Markdown来书写，写文章的时候又会引入一些图片，如果直接将图片复制粘贴进Typora的话只能保存在本地目录中，在其他地方打开文件无法看到里面的图片。Typora通过集成第三方工具，完成了自动上传图片至图床的功能，极大提升了写作效率。 什么是图床？ =&gt; 互联网中存储图片的空间,可以上传个人图片，并直接进行分享。 1 PicGo介绍 项目地址 一款能够在本地上传图片，能够自动转换成链接的工具，目前支持以下图床： 七牛图床 v1.0 腾讯云 COS v4\\v5 版本 v1.1 &amp; v1.5.0 又拍云 v1.2.0 GitHub v1.5.0 SM.MS V2 v2.3.0-beta.0 阿里云 OSS v1.6.0 Imgur v1.6.0 2 GitHub设置 2.1 创建仓库 设置你的仓库名称，都可以，然后选择Public，点击Create repository 。 2.2 获取token 进入右上角个人setting（不是仓库的setting）,左栏进入最下方的Developer settings，进入如图所界面，找到tokens(classic)，创建新token，记住这个token。 3 PicGo 配置 在前文介绍项目链接中下载PicGo，安装好后打开在主页面找到github配置。 如果下载缓慢，可以使用镜像网站：山东大学镜像站 将前面创建好的token填入，仓库名称、分支、存储路径如下图所示： 4 jsDelivr介绍 A free CDN for open source projects--用于开源项目的免费 CDN 刚好解决github图片访问过慢的问题，使用十分简单。 项目地址：https://www.jsdelivr.com/? 在这里我们用自己的github信息按照如下格式填入PicGo中即可： https://cdn.jsdelivr.net/gh/用户名/仓库名@分支名称 其他域名配置方式： 1234567891011121314151617181920212223// 加载任何Github发布、提交或分支https://cdn.jsdelivr.net/gh/user/repo@version/file// 加载 jQuery v3.6.4https://cdn.jsdelivr.net/gh/jquery/jquery@3.6.4/dist/jquery.min.js// 使用版本范围而不是特定版本https://cdn.jsdelivr.net/gh/jquery/jquery@3.6/dist/jquery.min.jshttps://cdn.jsdelivr.net/gh/jquery/jquery@3/dist/jquery.min.js// 完全省略版本或分支以获得最新版本 ，不应该在生产中使用它https://cdn.jsdelivr.net/gh/jquery/jquery/dist/jquery.min.js// 将“.min”添加到任何JS/CSS文件中以获取缩小版本，如果不存在，将为会自动生成https://cdn.jsdelivr.net/gh/jquery/jquery@3.6.4/src/core.min.js// 在末尾添加\"/\"以获取资源目录列表https://cdn.jsdelivr.net/gh/jquery/jquery/ 5 配置Typora 打开Typora左上角文件，进入偏好设置，左栏选择图像按照如下。 上传测试 在Typora中直接粘贴一张本地照片，上传成功，进入PicGo主页面相册查看到照片，在github仓库中 也找到照片。 参考资料 体验PicGo+GitHub搭建图床，使用jsDelivr或Github raw免费加速 PicGo + Gitee 配置图床","categories":[{"name":"博客搭建","slug":"博客搭建","permalink":"https://dekelkai.github.io/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"教程","slug":"教程","permalink":"https://dekelkai.github.io/tags/%E6%95%99%E7%A8%8B/"},{"name":"工具","slug":"工具","permalink":"https://dekelkai.github.io/tags/%E5%B7%A5%E5%85%B7/"},{"name":"Typora","slug":"Typora","permalink":"https://dekelkai.github.io/tags/Typora/"},{"name":"PicGo","slug":"PicGo","permalink":"https://dekelkai.github.io/tags/PicGo/"}]}],"categories":[{"name":"学习","slug":"学习","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"前端","slug":"学习/前端","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/%E5%89%8D%E7%AB%AF/"},{"name":"论文","slug":"论文","permalink":"https://dekelkai.github.io/categories/%E8%AE%BA%E6%96%87/"},{"name":"reinforce learning","slug":"reinforce-learning","permalink":"https://dekelkai.github.io/categories/reinforce-learning/"},{"name":"RL","slug":"RL","permalink":"https://dekelkai.github.io/categories/RL/"},{"name":"实时追踪","slug":"实时追踪","permalink":"https://dekelkai.github.io/categories/%E5%AE%9E%E6%97%B6%E8%BF%BD%E8%B8%AA/"},{"name":"Tips","slug":"Tips","permalink":"https://dekelkai.github.io/categories/Tips/"},{"name":"机器学习","slug":"Tips/机器学习","permalink":"https://dekelkai.github.io/categories/Tips/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"Transformer","slug":"学习/Transformer","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/Transformer/"},{"name":"爬虫","slug":"学习/爬虫","permalink":"https://dekelkai.github.io/categories/%E5%AD%A6%E4%B9%A0/%E7%88%AC%E8%99%AB/"},{"name":"目标检测","slug":"目标检测","permalink":"https://dekelkai.github.io/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"},{"name":"bigdata","slug":"bigdata","permalink":"https://dekelkai.github.io/categories/bigdata/"},{"name":"博客搭建","slug":"博客搭建","permalink":"https://dekelkai.github.io/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"},{"name":"小技巧","slug":"小技巧","permalink":"https://dekelkai.github.io/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"React","slug":"React","permalink":"https://dekelkai.github.io/tags/React/"},{"name":"学习","slug":"学习","permalink":"https://dekelkai.github.io/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"目标跟踪","slug":"目标跟踪","permalink":"https://dekelkai.github.io/tags/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/"},{"name":"无人机","slug":"无人机","permalink":"https://dekelkai.github.io/tags/%E6%97%A0%E4%BA%BA%E6%9C%BA/"},{"name":"YOLO","slug":"YOLO","permalink":"https://dekelkai.github.io/tags/YOLO/"},{"name":"RL","slug":"RL","permalink":"https://dekelkai.github.io/tags/RL/"},{"name":"reinforce learning","slug":"reinforce-learning","permalink":"https://dekelkai.github.io/tags/reinforce-learning/"},{"name":"大学","slug":"大学","permalink":"https://dekelkai.github.io/tags/%E5%A4%A7%E5%AD%A6/"},{"name":"Vision Transformer","slug":"Vision-Transformer","permalink":"https://dekelkai.github.io/tags/Vision-Transformer/"},{"name":"Transformer","slug":"Transformer","permalink":"https://dekelkai.github.io/tags/Transformer/"},{"name":"Python","slug":"Python","permalink":"https://dekelkai.github.io/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://dekelkai.github.io/tags/%E7%88%AC%E8%99%AB/"},{"name":"教程","slug":"教程","permalink":"https://dekelkai.github.io/tags/%E6%95%99%E7%A8%8B/"},{"name":"Blog","slug":"Blog","permalink":"https://dekelkai.github.io/tags/Blog/"},{"name":"bigdata","slug":"bigdata","permalink":"https://dekelkai.github.io/tags/bigdata/"},{"name":"Twikoo","slug":"Twikoo","permalink":"https://dekelkai.github.io/tags/Twikoo/"},{"name":"评论功能","slug":"评论功能","permalink":"https://dekelkai.github.io/tags/%E8%AF%84%E8%AE%BA%E5%8A%9F%E8%83%BD/"},{"name":"Giscus","slug":"Giscus","permalink":"https://dekelkai.github.io/tags/Giscus/"},{"name":"LaTeX","slug":"LaTeX","permalink":"https://dekelkai.github.io/tags/LaTeX/"},{"name":"功能","slug":"功能","permalink":"https://dekelkai.github.io/tags/%E5%8A%9F%E8%83%BD/"},{"name":"字体","slug":"字体","permalink":"https://dekelkai.github.io/tags/%E5%AD%97%E4%BD%93/"},{"name":"主题","slug":"主题","permalink":"https://dekelkai.github.io/tags/%E4%B8%BB%E9%A2%98/"},{"name":"工具","slug":"工具","permalink":"https://dekelkai.github.io/tags/%E5%B7%A5%E5%85%B7/"},{"name":"Typora","slug":"Typora","permalink":"https://dekelkai.github.io/tags/Typora/"},{"name":"PicGo","slug":"PicGo","permalink":"https://dekelkai.github.io/tags/PicGo/"}]}